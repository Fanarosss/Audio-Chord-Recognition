{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Chord Estimation</h1>\n",
    "<br>\n",
    "In this Notebook we are going to explore a different representation for the chords, similarly as used in a paper from mirex\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# do this only once\n",
    "sys.path.append('./src/audio_processing/')\n",
    "sys.path.append('./src/data_processing/')\n",
    "sys.path.append('./src/chord_parser/')\n",
    "sys.path.append('./src/metrics/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#python input/output and regex\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "#chord info\n",
    "import pychord as pc\n",
    "\n",
    "#signal processing libraries\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "\n",
    "#sklearn for normalization\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "#tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "#librosa\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "#mirex\n",
    "import mir_eval\n",
    "\n",
    "#import custom modules\n",
    "import filters\n",
    "import spectrograms\n",
    "import audiofiles\n",
    "from annotation_processing import chords_to_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CQT\n",
    "- number of bins = 192\n",
    "- bins per octave = 24\n",
    "- sample rate = 22050 Hz\n",
    "- min frequency = C1 (~31Hz)\n",
    "- hop_length = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins=192\n",
    "bins_per_octave=24\n",
    "hop_length=2048\n",
    "audiofiles_path = 'Audiofiles/The Beatles/original'\n",
    "input_features = nbins\n",
    "Artist = 'The Beatles'\n",
    "\n",
    "Timeseries = {'The Beatles': {}}\n",
    "Timestamps = {'The Beatles': {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cqt on isophonics\n",
    "for filename in Path(audiofiles_path).glob('**/*.wav'):\n",
    "\n",
    "    path, track = os.path.split(filename)\n",
    "    path, album = os.path.split(path)\n",
    "\n",
    "    track_no = re.search('([0-9].).', track).group(1)\n",
    "\n",
    "    # read wav and create spectrogram\n",
    "    track, sample_rate = librosa.load(filename, sr = 22050)\n",
    "    track_time = librosa.get_duration(y=track, sr=sample_rate)\n",
    "#     n_fft = int(track_time // (hop_length / sample_rate))\n",
    "    \n",
    "    spectrogram = librosa.cqt(track, sr=sample_rate, n_bins=nbins, bins_per_octave=bins_per_octave, hop_length=hop_length)\n",
    "\n",
    "    frames = list(range(0, spectrogram.shape[1]))\n",
    "    times = librosa.frames_to_time(frames, sr=sample_rate, hop_length=hop_length)\n",
    "\n",
    "    if album not in Timeseries[Artist]:\n",
    "        Timeseries[Artist][album] = {}\n",
    "        Timestamps[Artist][album] = {}\n",
    "\n",
    "    Timeseries[Artist][album][track_no] = librosa.amplitude_to_db(abs(spectrogram), ref=np.max).T\n",
    "    Timestamps[Artist][album][track_no] = times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale Spectrogram Data\n",
    "for album in Timeseries[Artist].keys():\n",
    "    for track_no in Timeseries[Artist][album]:\n",
    "        Timeseries[Artist][album][track_no] += 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only if in possesion of billboard **GLOBAL z-normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OPTIONAL !!\n",
    "\n",
    "global_Scaler = StandardScaler()\n",
    "\n",
    "for artist in Timeseries.keys():\n",
    "    for album in Timeseries[artist].keys():\n",
    "        for track_no, track_data in Timeseries[artist][album].items():\n",
    "            global_Scaler.fit(track_data)\n",
    "            \n",
    "for track_no, track_data in Timeseries_Billboard.items():\n",
    "    global_Scaler.fit(track_data)\n",
    "            \n",
    "for artist in Timeseries.keys():\n",
    "    for album in Timeseries[artist].keys():\n",
    "        for track_no, track_data in Timeseries[artist][album].items():\n",
    "            Timeseries[artist][album][track_no] = global_Scaler.transform(track_data)\n",
    "            \n",
    "for track_no, track_data in Timeseries_Billboard.items():\n",
    "    Timeseries_Billboard[track_no] = global_Scaler.transform(track_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Isophonics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get all chordlab files\n",
    "Chordlab = {'The Beatles': {}}\n",
    "for filename in Path('Big-Dataset/The Beatles').glob('**/scratch/**/*.lab'):\n",
    "    \n",
    "    path, track = os.path.split(filename)\n",
    "    path, album = os.path.split(path)\n",
    "    track_no = re.search('([0-9].)_-_',track).group(1)\n",
    "    \n",
    "    if (album not in Chordlab['The Beatles']): \n",
    "        Chordlab['The Beatles'][album] = {}\n",
    "        \n",
    "    Chordlab['The Beatles'][album][track_no] = pd.read_csv(filename, names=['Starts', 'Ends', 'Chord'], sep=' ', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cqt on isophonics\n",
    "for nshift, shift in [(1, 'up1'), (-1, 'down1'), (2, 'up2'), (-2, 'down2'),(3, 'up3'), (-3, 'down3'), (4, 'up4'), (-4, 'down4'), (5, 'up5'), (-5, 'down5'), (6, 'up6')]:\n",
    "    for filename in Path(audiofiles_path).glob('**/*.wav'):\n",
    "\n",
    "        path, track = os.path.split(filename)\n",
    "        path, album = os.path.split(path)\n",
    "\n",
    "        track_no = re.search('([0-9].).', track).group(1)\n",
    "\n",
    "        # read wav\n",
    "        track, sample_rate = librosa.load(filename, sr = 22050)\n",
    "        # create gaussian noise\n",
    "        mean = np.mean(track)\n",
    "        var = np.var(track)\n",
    "        noise = np.random.normal(mean, var, track.shape)\n",
    "        # add noise\n",
    "        track += noise\n",
    "        # pitch shift\n",
    "        y_shifted = librosa.effects.pitch_shift(track, sample_rate, n_steps=nshift)\n",
    "        # create cqt\n",
    "        spectrogram = librosa.cqt(y_shifted, sr=sample_rate, n_bins=nbins, bins_per_octave=bins_per_octave, hop_length=hop_length)\n",
    "        # timesteps\n",
    "        frames = list(range(0, spectrogram.shape[1]))\n",
    "        times = librosa.frames_to_time(frames, sr=sample_rate, hop_length=hop_length)\n",
    "        \n",
    "        # output\n",
    "        new_album = album + '_' + shift\n",
    "        if new_album not in Timeseries['The Beatles']:\n",
    "            Timeseries['The Beatles'][new_album] = {}\n",
    "            Timestamps['The Beatles'][new_album] = {}\n",
    "\n",
    "        new_track = track_no + '_' + shift\n",
    "        Timeseries['The Beatles'][new_album][new_track] = librosa.amplitude_to_db(abs(spectrogram), ref=np.max).T\n",
    "        Timestamps['The Beatles'][new_album][new_track] = times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale Spectrogram Data\n",
    "for album in Timeseries[Artist].keys():\n",
    "    for track_no in Timeseries[Artist][album]:\n",
    "        if album.find('_down') != -1 or album.find('_up') != -1:\n",
    "            Timeseries[Artist][album][track_no] += 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChordLib = {'C' : 0, 'C#': 1, 'Db' : 1, 'D' : 2, 'D#' : 3, 'Eb' : 3, 'E' : 4, 'Fb' : 4,\n",
    "            'F' : 5, 'F#' : 6, 'Gb' : 6, 'G' : 7, 'G#' : 8, 'Ab' : 8, 'A' : 9, 'A#' : 10,\n",
    "            'Bb' : 10, 'B' : 11, 'Cb' : 11, 'N' : 12, 'X' : 13}\n",
    "Harmonic_Equivalents = {'A#' : 'Bb', 'C#' : 'Db', 'D#' : 'Eb', 'F#' : 'Gb', 'G#' : 'Ab'}\n",
    "Semitone_List = ['C', 'C#', 'D', 'Eb', 'E', 'F', 'F#', 'G', 'G#', 'A', 'Bb', 'B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in Path('Big-Dataset/The Beatles').glob('**/scratch/**/*.lab'):\n",
    "    \n",
    "    path, track = os.path.split(filename)\n",
    "    path, album = os.path.split(path)\n",
    "    track_no = re.search('([0-9].)_-_',track).group(1)\n",
    "    \n",
    "    for pitch_shift, nshift in [('up1', 1), ('down1', 1), ('up2', 2), ('down2', 2),('up3', 3), ('down3', 3), ('up4', 4), ('down4', 4), ('up5', 5), ('down5', 5), ('up6', 6)]:\n",
    "        new_album = album + '_' + pitch_shift\n",
    "        new_track = track_no + '_' + pitch_shift\n",
    "        \n",
    "        if (new_album not in Chordlab['The Beatles']): \n",
    "            Chordlab['The Beatles'][new_album] = {}\n",
    "        \n",
    "        if pitch_shift.find('down') != -1:\n",
    "            chord_list = []\n",
    "            for _, starts, ends, chord in Chordlab['The Beatles'][album][track_no].itertuples():\n",
    "                rest = ''\n",
    "                if chord != 'N':\n",
    "                    if chord.find(':') != -1:\n",
    "                        chord, rest = chord.split(':')\n",
    "                        rest = ':' + rest\n",
    "                    if chord.find('/') != -1:\n",
    "                        chord, rest = chord.split('/')\n",
    "                        rest = '/' + rest\n",
    "                    chord_list.append([starts, ends, Semitone_List[ChordLib[chord] - nshift] + rest])\n",
    "                else:\n",
    "                    chord_list.append([starts, ends, chord])\n",
    "\n",
    "            df = pd.DataFrame(chord_list, columns = ['Starts', 'Ends', 'Chord'])\n",
    "            Chordlab[Artist][new_album][new_track] = df\n",
    "        else:\n",
    "            chord_list = []\n",
    "            for _, starts, ends, chord in Chordlab['The Beatles'][album][track_no].itertuples():\n",
    "                rest = ''\n",
    "                if chord != 'N':\n",
    "                    if chord.find(':') != -1:\n",
    "                        chord, rest = chord.split(':')\n",
    "                        rest = ':' + rest\n",
    "                    if chord.find('/') != -1:\n",
    "                        chord, rest = chord.split('/')\n",
    "                        rest = '/' + rest\n",
    "                    chord_list.append([starts, ends, Semitone_List[(ChordLib[chord] + nshift)%12] + rest])\n",
    "                else:\n",
    "                    chord_list.append([starts, ends, chord])\n",
    "\n",
    "            df = pd.DataFrame(chord_list, columns = ['Starts', 'Ends', 'Chord'])\n",
    "            Chordlab[Artist][new_album][new_track] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chord Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Chords in our Dataset:  407\n"
     ]
    }
   ],
   "source": [
    "### Load all chords in a dictionary\n",
    "Chords = []\n",
    "Appearances = {}\n",
    "for album in Chordlab['The Beatles'].keys():\n",
    "    for track_no in Chordlab['The Beatles'][album].keys():\n",
    "        for index, row in Chordlab['The Beatles'][album][track_no].iterrows():\n",
    "            if row['Chord'] not in Chords: \n",
    "                Chords.append(row['Chord'])\n",
    "                Appearances[row['Chord']] = 0\n",
    "            else: \n",
    "                Appearances[row['Chord']] += 1\n",
    "            \n",
    "### How many chords do we have in our dataset?\n",
    "print (\"Unique Chords in our Dataset: \",len(Chords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Major Chords:  11361 \n",
      "Minor Chords:  2853\n"
     ]
    }
   ],
   "source": [
    "Major_Chords = 0\n",
    "Minor_Chords = 0\n",
    "\n",
    "for chord in Chords:\n",
    "    if chord.find('min') != -1:\n",
    "        Minor_Chords += Appearances[chord]\n",
    "    else:\n",
    "        Major_Chords += Appearances[chord]\n",
    "        \n",
    "print ('Major Chords: ', Major_Chords, '\\nMinor Chords: ', Minor_Chords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Major Chords = 4*Minor Chords -> \n",
    "1. We need to increment the number of minor chords\n",
    "2. Or we can punish harder for the predictions on minor chords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Annotations Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChordLib = {'C' : 0, 'C#': 1, 'Db' : 1, 'D' : 2, 'D#' : 3, 'Eb' : 3, 'E' : 4, 'Fb' : 4, 'F' : 5, 'F#' : 6, 'Gb' : 6, 'G' : 7, 'G#' : 8, 'Ab' : 8, 'A' : 9, 'A#' : 10, 'Bb' : 10, 'B' : 11, 'Cb' : 11, 'N' : 12, 'X' : 13}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/intervals.png\" width=\"400\" />\n",
    "\n",
    "<caption><center> <b>Figure 2</b>: Semitones to Intervals.</center></caption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interval_to_semitone(interval):\n",
    "    if interval == '2':\n",
    "        return 2\n",
    "    elif interval == 'b2':\n",
    "        return 1\n",
    "    if interval == '3':\n",
    "        return 4\n",
    "    elif interval == 'b3':\n",
    "        return 3\n",
    "    if interval == '4':\n",
    "        return 5\n",
    "    if interval == '5':\n",
    "        return 7\n",
    "    elif interval == 'b5':\n",
    "        return 6\n",
    "    if interval == '6':\n",
    "        return 9\n",
    "    elif interval == 'b6':\n",
    "        return 8\n",
    "    if interval == '7':\n",
    "        return 11\n",
    "    elif interval == 'b7':\n",
    "        return 10\n",
    "    if interval == '9':\n",
    "        return 14\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Semitonize(interval, mode):\n",
    "    if interval == '0':\n",
    "        return 0\n",
    "    \n",
    "    if mode == 'Major':\n",
    "        return interval_to_semitone(interval)\n",
    "    elif mode == 'Minor':\n",
    "        return interval_to_semitone(interval)\n",
    "    elif mode == 'Dim':\n",
    "        return interval_to_semitone(interval)\n",
    "    elif mode == 'Aug':\n",
    "        return interval_to_semitone(interval)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fourths = {'N' : 0, 'dim7' : 1, 'min7' : 2, 'maj7' : 3, 'maj6' : 4, 'X' : 5}\n",
    "Triads = {'N' : 0, 'Major' : 1, 'Minor' : 2, 'Dim' : 3, 'Aug' : 4, 'Sus2' : 5, 'Sus4' : 6, 'X' : 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "Semitones = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_chords(Chords, df):\n",
    "    # silence\n",
    "    df['Root'].append(ChordLib['N'])\n",
    "    df['Bass'].append(ChordLib['N'])\n",
    "    df['Unknown'].append(0)\n",
    "    df['Triad'].append(Triads['N'])\n",
    "    df['Fourth Note'].append(Fourths['N'])\n",
    "    # for all chords in vocab\n",
    "    for chord in Chords:\n",
    "        if chord == 'N':\n",
    "            continue\n",
    "        \n",
    "        root, quality, extra, bass = mir_eval.chord.split(chord)\n",
    "        # initialize\n",
    "        Mode = 'Major'\n",
    "        fourth_note = ''\n",
    "        fourth_note_mode = ''\n",
    "        Unknown = False\n",
    "\n",
    "        if quality == '7':\n",
    "            #Dominant seventh\n",
    "            Mode = 'Major'\n",
    "            fourth_note = '7'\n",
    "            fourth_note_mode = 'min'\n",
    "        elif quality[:3] == 'min':\n",
    "            Mode = 'Minor'\n",
    "            if quality != 'min':\n",
    "                if quality[3] == '7':\n",
    "                    fourth_note = '7'\n",
    "                    fourth_note_mode = 'min'\n",
    "        elif quality[:3] == 'dim':\n",
    "            Mode = 'Dim'\n",
    "            if quality != 'dim':\n",
    "                fourth_note = quality[3]\n",
    "                fourth_note_mode = 'dim'\n",
    "        elif quality[:3] == 'aug':\n",
    "            # Root + Major third + Augmented fifth + Minor seventh\n",
    "            Mode = 'Aug'\n",
    "            if quality != 'aug':\n",
    "                fourth_note = quality[3]\n",
    "                fourth_note_mode = 'min'\n",
    "        elif quality[:3] == 'maj':\n",
    "            Mode = 'Major'\n",
    "            if quality != 'maj':\n",
    "                quality = quality[3:]\n",
    "                fourth_note_mode = 'maj'\n",
    "                fourth_note = quality[0]\n",
    "        elif quality[:4] == 'sus2':\n",
    "            Mode = 'Sus2'\n",
    "        elif quality[:4] == 'sus4':\n",
    "            Mode = 'Sus4'\n",
    "        elif quality[:4] == 'sus7':\n",
    "            Mode = 'Sus4'\n",
    "            fourth_note = '7'\n",
    "            fourth_note_mode = 'min'\n",
    "        elif quality[:4] == 'sus9':\n",
    "            Mode = 'Sus4'\n",
    "            fourth_note = '7'\n",
    "            fourth_note_mode = 'min'\n",
    "            Unknown = True\n",
    "        elif quality[:4] == 'hdim':\n",
    "            #half diminished\n",
    "            Mode ='Dim'\n",
    "            fourth_note_mode = 'min'\n",
    "            fourth_note = quality[4]\n",
    "        elif quality == '9':\n",
    "            #Dominant seventh\n",
    "            Mode = 'Major'\n",
    "            fourth_note = '7'\n",
    "            fourth_note_mode = 'min'\n",
    "        else:\n",
    "            Unknown = True\n",
    "\n",
    "        # find bass\n",
    "        if bass == '1':\n",
    "            bass = root\n",
    "        else:\n",
    "            bass = Semitones[(ChordLib[root] + interval_to_semitone(bass))%12]\n",
    "        \n",
    "        if not Unknown:\n",
    "            #print(root, bass, Mode, fourth_note)\n",
    "            df['Root'].append(ChordLib[root])\n",
    "            df['Bass'].append(ChordLib[bass])\n",
    "            df['Unknown'].append(0)\n",
    "            df['Triad'].append(Triads[Mode])\n",
    "            if (fourth_note != '7' and fourth_note != '6'):\n",
    "                fourth_note = 'N'\n",
    "                fourth_note_mode = ''\n",
    "            df['Fourth Note'].append(Fourths[fourth_note_mode + fourth_note])\n",
    "        else:\n",
    "            df['Root'].append(ChordLib[root])\n",
    "            df['Bass'].append(ChordLib[bass])\n",
    "            df['Unknown'].append(1)\n",
    "            df['Triad'].append(Triads[Mode])\n",
    "            df['Fourth Note'].append(Fourths['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=('Root', 'Bass', 'Unknown', 'Triad', 'Fourth Note'))\n",
    "representations = {'Root' : [], 'Bass' : [], 'Unknown' : [], 'Triad' : [], 'Fourth Note' : []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_chords(Chords, representations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert the dictionary to dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Chord</th>\n",
       "      <th>Root</th>\n",
       "      <th>Bass</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Triad</th>\n",
       "      <th>Fourth Note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>N</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>F:maj6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>G</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>A:min</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D:min7/4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>F:maj/9</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C/7</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C/5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Ab</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Bb</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Ab/7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Ab/b7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>F:7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>B</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>A</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>E</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>E:7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D:7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>A/b7</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>F#:min7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D:maj(11)</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D:maj(9)</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C:maj(#11)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>G/3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D#:dim7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D/b7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>G:min(9)/b3</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D/5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>G#:(1)</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D:min</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>G:7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C:7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>F#:dim</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>A:min/5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>A:dim/b5</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Eb</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>A:dim7/b3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>G:min/5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>F/5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Eb/5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>F:min</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>F:maj7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>G:min</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>F/3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>F:min/b7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D:dim</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>F:7/b7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Eb:dim</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>G:min/b7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Eb/3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>F:(1)</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Eb/2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>A:dim/b3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>G:(1)</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>F:min7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>G/5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Bb/b7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Chord        Root  Bass  Unknown  Triad  Fourth Note\n",
       "N              12    12        0      0            0\n",
       "F:maj6          5     5        0      1            4\n",
       "C               0     0        0      1            0\n",
       "G               7     7        0      1            0\n",
       "A:min           9     9        0      2            0\n",
       "D:min7/4        2     7        0      2            2\n",
       "F:maj/9         5     7        0      1            0\n",
       "C/7             0    11        0      1            0\n",
       "C/5             0     7        0      1            0\n",
       "F               5     5        0      1            0\n",
       "Ab              8     8        0      1            0\n",
       "Bb             10    10        0      1            0\n",
       "Ab/7            8     7        0      1            0\n",
       "Ab/b7           8     6        0      1            0\n",
       "F:7             5     5        0      1            2\n",
       "B              11    11        0      1            0\n",
       "A               9     9        0      1            0\n",
       "E               4     4        0      1            0\n",
       "E:7             4     4        0      1            2\n",
       "D               2     2        0      1            0\n",
       "D:7             2     2        0      1            2\n",
       "A/b7            9     7        0      1            0\n",
       "F#:min7         6     6        0      2            2\n",
       "D:maj(11)       2     2        0      1            0\n",
       "D:maj(9)        2     2        0      1            0\n",
       "C:maj(#11)      0     0        0      1            0\n",
       "G/3             7    11        0      1            0\n",
       "D#:dim7         3     3        0      3            1\n",
       "D/b7            2     0        0      1            0\n",
       "G:min(9)/b3     7    10        0      2            0\n",
       "D/5             2     9        0      1            0\n",
       "G#:(1)          8     8        1      1            5\n",
       "D:min           2     2        0      2            0\n",
       "G:7             7     7        0      1            2\n",
       "C:7             0     0        0      1            2\n",
       "F#:dim          6     6        0      3            0\n",
       "A:min/5         9     4        0      2            0\n",
       "A:dim/b5        9     3        0      3            0\n",
       "Eb              3     3        0      1            0\n",
       "A:dim7/b3       9     0        0      3            1\n",
       "G:min/5         7     2        0      2            0\n",
       "F/5             5     0        0      1            0\n",
       "Eb/5            3    10        0      1            0\n",
       "F:min           5     5        0      2            0\n",
       "F:maj7          5     5        0      1            3\n",
       "G:min           7     7        0      2            0\n",
       "F/3             5     9        0      1            0\n",
       "F:min/b7        5     3        0      2            0\n",
       "D:dim           2     2        0      3            0\n",
       "F:7/b7          5     3        0      1            2\n",
       "Eb:dim          3     3        0      3            0\n",
       "G:min/b7        7     5        0      2            0\n",
       "Eb/3            3     7        0      1            0\n",
       "F:(1)           5     5        1      1            5\n",
       "Eb/2            3     5        0      1            0\n",
       "A:dim/b3        9     0        0      3            0\n",
       "G:(1)           7     7        1      1            5\n",
       "F:min7          5     5        0      2            2\n",
       "G/5             7     2        0      1            0\n",
       "Bb/b7          10     8        0      1            0"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=representations, index=Chords).rename_axis('Chord', axis = 1)\n",
    "df.iloc[0:60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this is a dictionary for every chord<br>\n",
    "I'm going to index every chord with its timestep just liek before, but instead of a one hot of size 407, we will have the above representation<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
       "              dtype=<class 'numpy.float64'>, handle_unknown='error',\n",
       "              n_values=None, sparse=True)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OneHotEncoder(categories='auto')\n",
    "encoder.fit(np.array(list(range(0,14))).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
       "              dtype=<class 'numpy.float64'>, handle_unknown='error',\n",
       "              n_values=None, sparse=True)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_triads = OneHotEncoder(categories='auto')\n",
    "encoder_triads.fit(np.array(list(range(0,8))).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
       "              dtype=<class 'numpy.float64'>, handle_unknown='error',\n",
       "              n_values=None, sparse=True)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_fourth = OneHotEncoder(categories='auto')\n",
    "encoder_fourth.fit(np.array(list(range(0,6))).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09_-_Magical_Mystery_Tour  completed\n",
      "12_-_Let_It_Be  completed\n",
      "04_-_Beatles_for_Sale  completed\n",
      "10CD2_-_The_Beatles  completed\n",
      "05_-_Help!  completed\n",
      "03_-_A_Hard_Day's_Night  completed\n",
      "07_-_Revolver  completed\n",
      "10CD1_-_The_Beatles  completed\n",
      "08_-_Sgt._Pepper's_Lonely_Hearts_Club_Band  completed\n",
      "01_-_Please_Please_Me  completed\n",
      "06_-_Rubber_Soul  completed\n",
      "11_-_Abbey_Road  completed\n",
      "02_-_With_the_Beatles  completed\n"
     ]
    }
   ],
   "source": [
    "### Annotations\n",
    "Artist='The Beatles'\n",
    "root_vec = {}\n",
    "bass_vec = {}\n",
    "quality_vec = {}\n",
    "for album in Chordlab[Artist].keys():\n",
    "    root_vec[album] = {}\n",
    "    bass_vec[album] = {}\n",
    "    quality_vec[album] = {}\n",
    "    for track_no in Chordlab[Artist][album].keys():\n",
    "        df_rows = Chordlab[Artist][album][track_no].itertuples()\n",
    "        index = 0\n",
    "        max_len = len(Chordlab[Artist][album][track_no])\n",
    "        root = np.empty((14,))\n",
    "        bass = np.empty((14,))\n",
    "        quality = np.empty((15,)) # 1 + 8 + 6\n",
    "        row = next(df_rows)\n",
    "        for timestamp in Timestamps[Artist][album][track_no]:\n",
    "            if ((index + 1) < max_len) & (timestamp >= row[2]):\n",
    "                index += 1\n",
    "                row = next(df_rows)\n",
    "            root = np.column_stack((root, encoder.transform([[df.loc[row[3]]['Root']]]).toarray()[0]))\n",
    "            bass = np.column_stack((bass, encoder.transform([[df.loc[row[3]]['Bass']]]).toarray()[0]))\n",
    "            quality = np.column_stack((quality, np.append(np.append(df.loc[row[3]][2], encoder_triads.transform([[df.loc[row[3]][3]]]).toarray()[0]), encoder_fourth.transform([[df.loc[row[3]][4]]]).toarray()[0])))\n",
    "        root_vec[album][track_no] = root\n",
    "        bass_vec[album][track_no] = bass\n",
    "        quality_vec[album][track_no] = quality\n",
    "    print(album, ' completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take care fo the one extra row in the beginning of the array\n",
    "for album in root_vec.keys():\n",
    "    for track_no in root_vec[album].keys():\n",
    "        root_vec[album][track_no] = np.delete(root_vec[album][track_no], 0, 1)\n",
    "        bass_vec[album][track_no] = np.delete(bass_vec[album][track_no], 0, 1)\n",
    "        quality_vec[album][track_no] = np.delete(quality_vec[album][track_no], 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STORE\n",
    "import pickle\n",
    "\n",
    "with open('root_vec.pickle', 'wb') as handle:\n",
    "    pickle.dump(root_vec, handle, protocol=pickle.HIGHEST_PROTOCOL)  \n",
    "    \n",
    "with open('quality_vec.pickle', 'wb') as handle:\n",
    "    pickle.dump(quality_vec, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOAD\n",
    "import pickle\n",
    "\n",
    "with open('root_vec.pickle', 'rb') as handle:\n",
    "    root_vec = pickle.load(handle)\n",
    "    \n",
    "with open('quality_vec.pickle', 'rb') as handle:\n",
    "    quality_vec = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constructing numpy arrays\n",
    "chunk_size = slicing window (~10 secs)\n",
    "<br>\n",
    "input_features = nbins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test track\n",
    "test_track_no = '02'\n",
    "album_test_track = '07_-_Revolver'\n",
    "# validation album\n",
    "album_validate = '10CD1_-_The_Beatles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 300, 192) (1024, 300, 14) (1024, 300, 14) (6, 300, 192) (6, 300, 14) (6, 300, 14)\n"
     ]
    }
   ],
   "source": [
    "# train set\n",
    "x_train = np.zeros((1,chunk_size,input_features)) #num of frequencies\n",
    "y_train_root = np.zeros((1,chunk_size,14))\n",
    "y_train_bass = np.zeros((1,chunk_size,14))\n",
    "# test set\n",
    "x_test = np.zeros((1,chunk_size,input_features)) #num of frequencies\n",
    "y_test_root = np.zeros((1,chunk_size,14))\n",
    "y_test_bass = np.zeros((1,chunk_size,14))\n",
    "# validation set\n",
    "x_val = np.zeros((1,chunk_size,input_features)) #num of frequencies\n",
    "y_val_root = np.zeros((1,chunk_size,14))\n",
    "y_val_bass = np.zeros((1,chunk_size,14))\n",
    "\n",
    "for album in root_vec.keys():\n",
    "    if album.find(album_validate) != -1:\n",
    "        continue\n",
    "    for track_no in root_vec[album].keys():\n",
    "        timestep = 0\n",
    "        # size of the current track\n",
    "        chunks = root_vec[album][track_no].T.shape[0]\n",
    "        # track frequencies\n",
    "        timeseries = Timeseries['The Beatles'][album][track_no]\n",
    "        # track annotations\n",
    "        annotations_root = root_vec[album][track_no].T\n",
    "        annotations_bass = bass_vec[album][track_no].T\n",
    "        # slice and stack train-test data\n",
    "        if track_no.find(test_track_no) == -1 or album.find(album_test_track) == -1:\n",
    "            # train tracks\n",
    "            while timestep < chunks :\n",
    "                if (chunks - timestep) > chunk_size:\n",
    "                    batch_x = np.resize(timeseries[timestep:timestep+chunk_size,:], (1, chunk_size, input_features)) #num of frequencies\n",
    "                    x_train = np.append(x_train, batch_x, axis = 0)\n",
    "                    batch_y = np.resize(annotations_root[timestep:timestep+chunk_size,:], (1, chunk_size, 14))\n",
    "                    y_train_root = np.append(y_train_root, batch_y, axis = 0)\n",
    "                    batch_y = np.resize(annotations_bass[timestep:timestep+chunk_size,:], (1, chunk_size, 14))\n",
    "                    y_train_bass = np.append(y_train_bass, batch_y, axis = 0)\n",
    "                else:\n",
    "                    batch_x = timeseries[timestep:,:]\n",
    "                    batch_y_root = annotations_root[timestep:,:]\n",
    "                    batch_y_bass = annotations_bass[timestep:,:]\n",
    "                    for step in range (0, chunk_size + timestep - chunks):\n",
    "                        batch_x = np.vstack((batch_x, np.zeros((1,input_features))))\n",
    "                        batch_y_root = np.vstack((batch_y_root, encoder.transform([[df.loc['N']['Root']]]).toarray()[0]))\n",
    "                        batch_y_bass = np.vstack((batch_y_bass, encoder.transform([[df.loc['N']['Root']]]).toarray()[0]))\n",
    "                    x_train = np.append(x_train, np.array([batch_x]), axis = 0)\n",
    "                    y_train_root = np.append(y_train_root, np.array([batch_y_root]), axis = 0)\n",
    "                    y_train_bass = np.append(y_train_bass, np.array([batch_y_bass]), axis = 0)\n",
    "                timestep += chunk_size\n",
    "        else:\n",
    "            # test tracks\n",
    "            while timestep < chunks :\n",
    "                if (chunks - timestep) > chunk_size:\n",
    "                    batch_x = np.resize(timeseries[timestep:timestep+chunk_size,:], (1, chunk_size, input_features)) #num of frequencies\n",
    "                    x_test = np.append(x_test, batch_x, axis = 0)\n",
    "                    batch_y = np.resize(annotations_root[timestep:timestep+chunk_size,:], (1, chunk_size, 14))\n",
    "                    y_test_root = np.append(y_test_root, batch_y, axis = 0)\n",
    "                    batch_y = np.resize(annotations_bass[timestep:timestep+chunk_size,:], (1, chunk_size, 14))\n",
    "                    y_test_bass = np.append(y_test_bass, batch_y, axis = 0)\n",
    "                else:\n",
    "                    batch_x = timeseries[timestep:,:]\n",
    "                    batch_y_root = annotations_root[timestep:,:]\n",
    "                    batch_y_bass = annotations_bass[timestep:,:]\n",
    "                    for step in range (0, chunk_size + timestep - chunks):\n",
    "                        batch_x = np.vstack((batch_x, np.zeros((1,input_features))))\n",
    "                        batch_y_root = np.vstack((batch_y_root, encoder.transform([[df.loc['N']['Root']]]).toarray()[0]))\n",
    "                        batch_y_bass = np.vstack((batch_y_bass, encoder.transform([[df.loc['N']['Root']]]).toarray()[0]))\n",
    "                    x_test = np.append(x_test, np.array([batch_x]), axis = 0)\n",
    "                    y_test_root = np.append(y_test_root, np.array([batch_y_root]), axis = 0)\n",
    "                    y_test_bass = np.append(y_test_bass, np.array([batch_y_bass]), axis = 0)\n",
    "                # augment timesteps\n",
    "                timestep += chunk_size\n",
    "\n",
    "print (x_train.shape, y_train_root.shape, y_train_bass.shape, x_test.shape, y_test_root.shape, y_test_bass.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107, 300, 192) (107, 300, 14) (107, 300, 14)\n"
     ]
    }
   ],
   "source": [
    "# validation set\n",
    "x_val = np.zeros((1,chunk_size,input_features)) #num of frequencies\n",
    "y_val_root = np.zeros((1,chunk_size,14))\n",
    "y_val_bass = np.zeros((1,chunk_size,14))\n",
    "\n",
    "for track_no in root_vec[album_validate].keys():\n",
    "    timestep = 0\n",
    "    # size of the current track\n",
    "    chunks = root_vec[album_validate][track_no].T.shape[0]\n",
    "    # track frequencies\n",
    "    timeseries = Timeseries['The Beatles'][album_validate][track_no]\n",
    "    # track annotations\n",
    "    annotations_root = root_vec[album_validate][track_no].T\n",
    "    annotations_bass = bass_vec[album_validate][track_no].T\n",
    "    # validation tracks\n",
    "    while timestep < chunks :\n",
    "        if (chunks - timestep) > chunk_size:\n",
    "            batch_x = np.resize(timeseries[timestep:timestep+chunk_size,:], (1, chunk_size, input_features)) #num of frequencies\n",
    "            x_val = np.append(x_val, batch_x, axis = 0)\n",
    "            batch_y = np.resize(annotations_root[timestep:timestep+chunk_size,:], (1, chunk_size, 14))\n",
    "            y_val_root = np.append(y_val_root, batch_y, axis = 0)\n",
    "            batch_y = np.resize(annotations_bass[timestep:timestep+chunk_size,:], (1, chunk_size, 14))\n",
    "            y_val_bass = np.append(y_val_bass, batch_y, axis = 0)\n",
    "        else:\n",
    "            batch_x = timeseries[timestep:,:]\n",
    "            batch_y_root = annotations_root[timestep:,:]\n",
    "            batch_y_bass = annotations_bass[timestep:,:]\n",
    "            for step in range (0, chunk_size + timestep - chunks):\n",
    "                batch_x = np.vstack((batch_x, np.zeros((1,input_features))))\n",
    "                batch_y_root = np.vstack((batch_y_root, encoder.transform([[df.loc['N']['Root']]]).toarray()[0]))\n",
    "                batch_y_bass = np.vstack((batch_y_bass, encoder.transform([[df.loc['N']['Root']]]).toarray()[0]))\n",
    "            x_val = np.append(x_val, np.array([batch_x]), axis = 0)\n",
    "            y_val_root = np.append(y_val_root, np.array([batch_y_root]), axis = 0)\n",
    "            y_val_bass = np.append(y_val_bass, np.array([batch_y_bass]), axis = 0)\n",
    "        # augment timesteps\n",
    "        timestep += chunk_size\n",
    "\n",
    "print (x_val.shape, y_val_root.shape, y_val_bass.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**annotations quality**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 300, 15) (6, 300, 15)\n"
     ]
    }
   ],
   "source": [
    "y_train_quality = np.zeros((1,chunk_size,15))\n",
    "y_test_quality = np.zeros((1,chunk_size,15))\n",
    "y_val_quality = np.zeros((1,chunk_size,15))\n",
    "\n",
    "for album in root_vec.keys():\n",
    "    if album.find(album_validate) != -1:\n",
    "        continue\n",
    "    for track_no in root_vec[album].keys():\n",
    "        timestep = 0\n",
    "        # size of the current track\n",
    "        chunks = quality_vec[album][track_no].T.shape[0]\n",
    "        # track frequencies\n",
    "        timeseries = Timeseries['The Beatles'][album][track_no]\n",
    "        # track annotations\n",
    "        annotations_quality = quality_vec[album][track_no].T\n",
    "        # slice and stack train-test data\n",
    "        if track_no.find(test_track_no) == -1 or album.find(album_test_track) == -1:\n",
    "            # train tracks\n",
    "            while timestep < chunks :\n",
    "                if (chunks - timestep) > chunk_size:\n",
    "                    batch_y = np.resize(annotations_quality[timestep:timestep+chunk_size,:], (1, chunk_size, 15))\n",
    "                    y_train_quality = np.append(y_train_quality, batch_y, axis = 0)\n",
    "                else:\n",
    "                    batch_y = annotations_quality[timestep:,:]\n",
    "                    for step in range (0, chunk_size + timestep - chunks):\n",
    "                        batch_y = np.vstack((batch_y, np.append(np.append(df.loc['N'][1], encoder_triads.transform([[df.loc['N'][2]]]).toarray()[0]), encoder_fourth.transform([[df.loc['N'][3]]]).toarray()[0])))\n",
    "                    y_train_quality = np.append(y_train_quality, np.array([batch_y]), axis = 0)\n",
    "                timestep += chunk_size\n",
    "        else:\n",
    "            # test tracks\n",
    "            while timestep < chunks :\n",
    "                if (chunks - timestep) > chunk_size:\n",
    "                    batch_y = np.resize(annotations_quality[timestep:timestep+chunk_size,:], (1, chunk_size, 15))\n",
    "                    y_test_quality = np.append(y_test_quality, batch_y, axis = 0)\n",
    "                else: \n",
    "                    batch_y = annotations_quality[timestep:,:]\n",
    "                    for step in range (0, chunk_size + timestep - chunks):\n",
    "                        batch_y = np.vstack((batch_y, np.append(np.append(df.loc['N'][1], encoder_triads.transform([[df.loc['N'][2]]]).toarray()[0]), encoder_fourth.transform([[df.loc['N'][3]]]).toarray()[0])))\n",
    "                    y_test_quality = np.append(y_test_quality, np.array([batch_y]), axis = 0)\n",
    "                timestep += chunk_size\n",
    "\n",
    "print (y_train_quality.shape, y_test_quality.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107, 300, 15)\n"
     ]
    }
   ],
   "source": [
    "for track_no in root_vec[album_validate].keys():\n",
    "    timestep = 0\n",
    "    # size of the current track\n",
    "    chunks = quality_vec[album_validate][track_no].T.shape[0]\n",
    "    # track frequencies\n",
    "    timeseries = Timeseries['The Beatles'][album_validate][track_no]\n",
    "    # track annotations\n",
    "    annotations_quality = quality_vec[album_validate][track_no].T\n",
    "    # train tracks\n",
    "    while timestep < chunks :\n",
    "        if (chunks - timestep) > chunk_size:\n",
    "            batch_y = np.resize(annotations_quality[timestep:timestep+chunk_size,:], (1, chunk_size, 15))\n",
    "            y_val_quality = np.append(y_val_quality, batch_y, axis = 0)\n",
    "        else:\n",
    "            batch_y = annotations_quality[timestep:,:]\n",
    "            for step in range (0, chunk_size + timestep - chunks):\n",
    "                batch_y = np.vstack((batch_y, np.append(np.append(df.loc['N'][1], encoder_triads.transform([[df.loc['N'][2]]]).toarray()[0]), encoder_fourth.transform([[df.loc['N'][3]]]).toarray()[0])))\n",
    "            y_val_quality = np.append(y_val_quality, np.array([batch_y]), axis = 0)\n",
    "        timestep += chunk_size\n",
    "        \n",
    "print (y_val_quality.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the first row from every array because of the append, which left it all zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.delete(x_train,0,0)\n",
    "x_test = np.delete(x_test,0,0)\n",
    "x_val = np.delete(x_val,0,0)\n",
    "\n",
    "y_train_root = np.delete(y_train_root,0,0)\n",
    "y_test_root = np.delete(y_test_root,0,0)\n",
    "y_val_root = np.delete(y_val_root,0,0)\n",
    "\n",
    "y_train_bass = np.delete(y_train_bass,0,0)\n",
    "y_test_bass = np.delete(y_test_bass,0,0)\n",
    "y_val_bass = np.delete(y_val_bass,0,0)\n",
    "\n",
    "y_train_quality = np.delete(y_train_quality,0,0)\n",
    "y_test_quality = np.delete(y_test_quality,0,0)\n",
    "y_val_quality = np.delete(y_val_quality,0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MIREX TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation set\n",
    "x_mirex_test = {}\n",
    "y_mirex_test_root = {}\n",
    "y_mirex_test_bass = {}\n",
    "\n",
    "for track_no in root_vec[album_validate].keys():\n",
    "    x_temp = np.zeros((1,chunk_size,input_features)) #num of frequencies\n",
    "    y_temp_root = np.zeros((1,chunk_size,14))\n",
    "    y_temp_bass = np.zeros((1,chunk_size,14))\n",
    "    timestep = 0\n",
    "    # size of the current track\n",
    "    chunks = root_vec[album_validate][track_no].T.shape[0]\n",
    "    # track frequencies\n",
    "    timeseries = Timeseries['The Beatles'][album_validate][track_no]\n",
    "    # track annotations\n",
    "    annotations_root = root_vec[album_validate][track_no].T\n",
    "    annotations_bass = bass_vec[album_validate][track_no].T\n",
    "    # validation tracks\n",
    "    while timestep < chunks :\n",
    "        if (chunks - timestep) > chunk_size:\n",
    "            batch_x = np.resize(timeseries[timestep:timestep+chunk_size,:], (1, chunk_size, input_features)) #num of frequencies\n",
    "            x_temp = np.append(x_temp, batch_x, axis = 0)\n",
    "            batch_y = np.resize(annotations_root[timestep:timestep+chunk_size,:], (1, chunk_size, 14))\n",
    "            y_temp_root = np.append(y_temp_root, batch_y, axis = 0)\n",
    "            batch_y = np.resize(annotations_bass[timestep:timestep+chunk_size,:], (1, chunk_size, 14))\n",
    "            y_temp_bass = np.append(y_temp_bass, batch_y, axis = 0)\n",
    "        else:\n",
    "            batch_x = timeseries[timestep:,:]\n",
    "            batch_y_root = annotations_root[timestep:,:]\n",
    "            batch_y_bass = annotations_bass[timestep:,:]\n",
    "            for step in range (0, chunk_size + timestep - chunks):\n",
    "                batch_x = np.vstack((batch_x, np.zeros((1,input_features))))\n",
    "                batch_y_root = np.vstack((batch_y_root, encoder.transform([[df.loc['N']['Root']]]).toarray()[0]))\n",
    "                batch_y_bass = np.vstack((batch_y_bass, encoder.transform([[df.loc['N']['Root']]]).toarray()[0]))\n",
    "            x_temp = np.append(x_temp, np.array([batch_x]), axis = 0)\n",
    "            y_temp_root = np.append(y_temp_root, np.array([batch_y_root]), axis = 0)\n",
    "            y_temp_bass = np.append(y_temp_bass, np.array([batch_y_bass]), axis = 0)\n",
    "        # augment timesteps\n",
    "        timestep += chunk_size\n",
    "    x_temp = np.delete(x_temp,0,0)\n",
    "    x_temp = np.reshape(x_temp, (x_temp.shape[0], x_temp.shape[1], x_temp.shape[2], 1))\n",
    "    y_temp_root = np.delete(y_temp_root,0,0)\n",
    "    y_temp_bass = np.delete(y_temp_bass,0,0)\n",
    "    x_mirex_test[track_no] = x_temp\n",
    "    y_mirex_test_root[track_no] = y_temp_root\n",
    "    y_mirex_test_bass[track_no] = y_temp_bass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mirex_test_quality = {}\n",
    "for track_no in root_vec[album_validate].keys():\n",
    "    y_temp_quality = np.zeros((1,chunk_size,15))\n",
    "    timestep = 0\n",
    "    # size of the current track\n",
    "    chunks = quality_vec[album_validate][track_no].T.shape[0]\n",
    "    # track frequencies\n",
    "    timeseries = Timeseries['The Beatles'][album_validate][track_no]\n",
    "    # track annotations\n",
    "    annotations_quality = quality_vec[album_validate][track_no].T\n",
    "    # train tracks\n",
    "    while timestep < chunks :\n",
    "        if (chunks - timestep) > chunk_size:\n",
    "            batch_y = np.resize(annotations_quality[timestep:timestep+chunk_size,:], (1, chunk_size, 15))\n",
    "            y_temp_quality = np.append(y_temp_quality, batch_y, axis = 0)\n",
    "        else:\n",
    "            batch_y = annotations_quality[timestep:,:]\n",
    "            for step in range (0, chunk_size + timestep - chunks):\n",
    "                batch_y = np.vstack((batch_y, np.append(np.append(df.loc['N'][1], encoder_triads.transform([[df.loc['N'][2]]]).toarray()[0]), encoder_fourth.transform([[df.loc['N'][3]]]).toarray()[0])))\n",
    "            y_temp_quality = np.append(y_temp_quality, np.array([batch_y]), axis = 0)\n",
    "        timestep += chunk_size\n",
    "    y_temp_quality = np.delete(y_temp_quality,0,0)\n",
    "    y_mirex_test_quality[track_no] = y_temp_quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mirex_test_triad = {}\n",
    "y_mirex_test_fourth = {}\n",
    "for track_no in root_vec[album_validate].keys():\n",
    "    _, y_mirex_test_triad[track_no], y_mirex_test_fourth[track_no] = np.dsplit(y_mirex_test_quality[track_no], [1,9,15])[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('x_train_big.pickle', 'wb') as handle:\n",
    "    pickle.dump(x_train, handle, protocol=pickle.HIGHEST_PROTOCOL)  \n",
    "    \n",
    "with open('x_test_big.pickle', 'wb') as handle:\n",
    "    pickle.dump(x_test, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('x_val_big.pickle', 'wb') as handle:\n",
    "    pickle.dump(x_val, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('y_train_root_big.pickle', 'wb') as handle:\n",
    "    pickle.dump(y_train_root, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('y_val_root_big.pickle', 'wb') as handle:\n",
    "    pickle.dump(y_val_root, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('y_test_root_big.pickle', 'wb') as handle:\n",
    "    pickle.dump(y_test_root, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('y_train_bass_big.pickle', 'wb') as handle:\n",
    "    pickle.dump(y_train_bass, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('y_val_bass_big.pickle', 'wb') as handle:\n",
    "    pickle.dump(y_val_bass, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('y_test_bass_big.pickle', 'wb') as handle:\n",
    "    pickle.dump(y_test_bass, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('y_train_quality_big.pickle', 'wb') as handle:\n",
    "    pickle.dump(y_train_quality, handle, protocol=pickle.HIGHEST_PROTOCOL) \n",
    "\n",
    "with open('y_test_quality_big.pickle', 'wb') as handle:\n",
    "    pickle.dump(y_test_quality, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('y_val_quality_big.pickle', 'wb') as handle:\n",
    "    pickle.dump(y_val_quality, handle, protocol=pickle.HIGHEST_PROTOCOL)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('y_train_bass_big.pickle', 'wb') as handle:\n",
    "    pickle.dump(y_train_bass, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('y_val_bass_big.pickle', 'wb') as handle:\n",
    "    pickle.dump(y_val_bass, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('y_test_bass_big.pickle', 'wb') as handle:\n",
    "    pickle.dump(y_test_bass, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('x_train_big.pickle', 'rb') as handle:\n",
    "    x_train = pickle.load(handle)  \n",
    "    \n",
    "with open('x_test_big.pickle', 'rb') as handle:\n",
    "    x_test = pickle.load(handle)\n",
    "    \n",
    "with open('x_val_big.pickle', 'rb') as handle:\n",
    "    x_val = pickle.load(handle)\n",
    "    \n",
    "with open('y_train_root_big.pickle', 'rb') as handle:\n",
    "    y_train_root = pickle.load(handle)\n",
    "    \n",
    "with open('y_val_root_big.pickle', 'rb') as handle:\n",
    "    y_val_root = pickle.load(handle)\n",
    "    \n",
    "with open('y_test_root_big.pickle', 'rb') as handle:\n",
    "    y_test_root = pickle.load(handle)\n",
    "    \n",
    "with open('y_train_quality_big.pickle', 'rb') as handle:\n",
    "    y_train_quality = pickle.load(handle)\n",
    "\n",
    "with open('y_test_quality_big.pickle', 'rb') as handle:\n",
    "    y_test_quality = pickle.load(handle)\n",
    "    \n",
    "with open('y_val_quality_big.pickle', 'rb') as handle:\n",
    "    y_val_quality = pickle.load(handle)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('y_train_bass_big.pickle', 'rb') as handle:\n",
    "    y_train_bass = pickle.load(handle)\n",
    "\n",
    "with open('y_test_bass_big.pickle', 'rb') as handle:\n",
    "    y_test_bass = pickle.load(handle)\n",
    "    \n",
    "with open('y_val_bass_big.pickle', 'rb') as handle:\n",
    "    y_val_bass = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_unknown, y_test_triad, y_test_fourth = np.dsplit(y_test_quality, [1,9,15])[0:3]\n",
    "y_train_unknown, y_train_triad, y_train_fourth = np.dsplit(y_train_quality, [1,9,15])[0:3]\n",
    "y_val_unknown, y_val_triad, y_val_fourth = np.dsplit(y_val_quality, [1,9,15])[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalanced Classification\n",
    "In this project we built our own dataset from beatles, so raw data are accompanied by ireguralizations such as imbalanced classes. We come across X major chords, but only X/3 minor chords. Image for the rest of the classes. So in order to have a balanced classification, we need our model to balance all the classes, by <b> paying attention more to <u>certain samples</u> and not certain classes, beause our classification is <u>multi label</u> and <u>not multi class</u> !!</b><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "InverseLib = {0 : 'C', 1 : 'C#', 2 : 'D', 3 : 'Eb', 4 : 'E', 5 : 'F', 6 : 'F#', 7 : 'G', 8 : 'G#', 9 : 'A', 10 : 'Bb', 11 : 'B', 12 : 'N'}\n",
    "InverseLibTriad = {0 : 'N', 1 : 'Major', 2 : 'Minor', 3 : 'Dim', 4 : 'Aug', 5 : 'Sus2', 6 : 'Sus4', 7 : 'X'}\n",
    "InverseLibFourth = {0 : 'N', 1 : 'dim7', 2 : 'min7', 3 : 'maj7', 4 : 'maj6', 5 : 'X'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unique root chord appearances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A :\t 6899\n",
      "A# :\t 0\n",
      "Bb :\t 5187\n",
      "B :\t 6325\n",
      "C :\t 6296\n",
      "C# :\t 5058\n",
      "Db :\t 98\n",
      "D :\t 6641\n",
      "D# :\t 43\n",
      "Eb :\t 4654\n",
      "E :\t 6534\n",
      "F :\t 6100\n",
      "F# :\t 5572\n",
      "Gb :\t 40\n",
      "G :\t 6778\n",
      "G# :\t 4532\n",
      "Ab :\t 213\n",
      "N :\t 2135\n"
     ]
    }
   ],
   "source": [
    "Artist='The Beatles'\n",
    "Chord_Appearances = {'A' : 0, 'A#' : 0, 'Bb' : 0, 'B' : 0, 'C' : 0, 'C#' : 0, 'Db' : 0, 'D' : 0, 'D#' : 0, 'Eb' : 0,\n",
    "                    'E' : 0, 'F' : 0, 'F#' : 0, 'Gb' : 0, 'G' : 0, 'G#' : 0, 'Ab' : 0, 'N' : 0,}\n",
    "for album in Chordlab[Artist].keys():\n",
    "    for track_no in Chordlab[Artist][album].keys():\n",
    "        for index, starts, ends, chord in Chordlab[Artist][album][track_no].itertuples():\n",
    "            if chord.find(':') != -1:\n",
    "                chord, _ = chord.split(':')\n",
    "            if chord.find('/') != -1:\n",
    "                chord, _ = chord.split('/')\n",
    "            Chord_Appearances[chord] += 1\n",
    "            \n",
    "for root in Chord_Appearances.keys():\n",
    "    print(root, ':\\t', Chord_Appearances[root])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Triads_Appearances = {'N' : 0, 'Major' : 0, 'Minor' : 0, 'Dim' : 0, 'Aug' : 0, 'Sus2' : 0, 'Sus4' : 0, 'X' : 0}\n",
    "Fourths_Appearances = {'N' : 0, 'dim7' : 0, 'min7' : 0, 'maj7' : 0, 'maj6' : 0, 'X' : 0}\n",
    "Root_Appearances = {'C' : 0, 'C#' : 0,'D' : 0, 'Eb' : 0, 'E' : 0, 'F' : 0, 'F#' : 0, 'G' : 0, 'G#' : 0, 'A' : 0, 'Bb' : 0, 'B' : 0, 'N' : 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 271254, 'C#': 271254, 'D': 271254, 'Eb': 271254, 'E': 271254, 'F': 271254, 'F#': 271254, 'G': 271254, 'G#': 271254, 'A': 271254, 'Bb': 271254, 'B': 271254, 'N': 427752}\n"
     ]
    }
   ],
   "source": [
    "for chunk in y_train_root:\n",
    "    for label in chunk:\n",
    "        Root_Appearances[InverseLib[encoder.inverse_transform([label]).reshape(1,)[0]]] += 1\n",
    "              \n",
    "print (Root_Appearances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert one hot to integers\n",
    "y_ints = [y.argmax() for chunk in y_train_root for y in chunk]\n",
    "# compute class weights\n",
    "root_class_weights = class_weight.compute_class_weight('balanced', np.unique(y_ints, axis=0), y_ints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Triads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'N': 427752, 'Major': 2552400, 'Minor': 626460, 'Dim': 30588, 'Aug': 22116, 'Sus2': 2616, 'Sus4': 20868, 'X': 0}\n"
     ]
    }
   ],
   "source": [
    "for chunk in y_train_triad:\n",
    "    for label in chunk:\n",
    "        Triads_Appearances[InverseLibTriad[encoder_triads.inverse_transform([label]).reshape(1,)[0]]] += 1\n",
    "        \n",
    "print (Triads_Appearances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert one hot to integers\n",
    "y_ints = [y.argmax() for chunk in y_train_triad for y in chunk]\n",
    "# compute class weights\n",
    "triad_class_weights = class_weight.compute_class_weight('balanced', np.unique(y_ints, axis=0), y_ints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Fourths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'N': 6483384, 'dim7': 21288, 'min7': 696672, 'maj7': 55848, 'maj6': 69792, 'X': 38616}\n"
     ]
    }
   ],
   "source": [
    "for chunk in y_train_fourth:\n",
    "    for label in chunk:\n",
    "        Fourths_Appearances[InverseLibFourth[encoder_fourth.inverse_transform([label]).reshape(1,)[0]]] += 1\n",
    "        \n",
    "print (Fourths_Appearances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert one hot to integers\n",
    "y_ints = [y.argmax() for chunk in y_train_fourth for y in chunk]\n",
    "# compute class weights\n",
    "fourth_class_weights = class_weight.compute_class_weight('balanced', np.unique(y_ints, axis=0), y_ints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need for balancing here\n",
    "unknown_class_weights = {0:1,1:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Sample Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "triad_sample_weights = np.ones((x_train.shape[0], x_train.shape[1]))\n",
    "\n",
    "y_ints = [y.argmax() for chunk in y_train_triad for y in chunk]\n",
    "i = 0\n",
    "j = 0\n",
    "for yi in y_ints:\n",
    "    triad_sample_weights[i][j] = min(triad_class_weights[yi], 2)\n",
    "    j += 1\n",
    "    if j == chunk_size:\n",
    "        i += 1\n",
    "        j = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourth_sample_weights = np.ones((x_train.shape[0], x_train.shape[1]))\n",
    "\n",
    "y_ints = [y.argmax() for chunk in y_train_fourth for y in chunk]\n",
    "i = 0\n",
    "j = 0\n",
    "for yi in y_ints:\n",
    "    if fourth_class_weights[yi] <= 1:\n",
    "        w = 1\n",
    "    else:\n",
    "        w = np.log(fourth_class_weights[yi])\n",
    "    fourth_sample_weights[i][j] = min(w, 5)\n",
    "    j += 1\n",
    "    if j == chunk_size:\n",
    "        i += 1\n",
    "        j = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.054672789070193\n"
     ]
    }
   ],
   "source": [
    "print (np.max(fourth_sample_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fourth_sample_weights.pickle', 'wb') as handle:\n",
    "    pickle.dump(fourth_sample_weights, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_sample_weights = np.ones((x_train.shape[0], x_train.shape[1]))\n",
    "bass_sample_weights = np.ones((x_train.shape[0], x_train.shape[1]))\n",
    "unknown_sample_weights = np.ones((x_train.shape[0], x_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourth_sample_weights = np.ones((x_train.shape[0], x_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "triad_sample_weights = np.ones((x_train.shape[0], x_train.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, TimeDistributed, Embedding, LSTM, Bidirectional, Dropout, Dense, GRU, concatenate, Conv1D, Conv2D, Flatten,MaxPooling1D, MaxPooling2D, LocallyConnected1D, Activation, GaussianNoise, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.initializers import RandomNormal, RandomUniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BLSTM_2Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BLSTM_2Layer(chords_num, input_features, timesteps, batch_size):\n",
    "    \n",
    "    main_input = Input(shape=(timesteps,input_features), name='main_input')\n",
    "    \n",
    "    #BLSTM\n",
    "    x = Bidirectional(LSTM(units = 64, \n",
    "                           batch_input_shape = (batch_size, timesteps, input_features),\n",
    "                           kernel_initializer = 'glorot_uniform',\n",
    "                           activation='tanh',\n",
    "                           bias_initializer = RandomNormal(),\n",
    "                           recurrent_activation='sigmoid',\n",
    "                           recurrent_regularizer='l2',\n",
    "                           return_sequences = True))(main_input)\n",
    "    x = Dropout(0.4)(x)\n",
    "    #BLSTM on the concatanted output\n",
    "    x = Bidirectional(LSTM(units = 64,\n",
    "                           kernel_initializer = 'glorot_uniform',\n",
    "                           bias_initializer = RandomNormal(),\n",
    "                           recurrent_activation='sigmoid',\n",
    "                           activation='tanh',\n",
    "                           recurrent_regularizer='l2',\n",
    "                           return_sequences=True))(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    \n",
    "    x = Dense(128)(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    #Dense for classification\n",
    "    x = Dense(chords_num)(x)\n",
    "    main_output = Activation('softmax')(x)\n",
    "    #model\n",
    "    model = Model(inputs=[main_input], outputs=[main_output])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Qualities_BLSTM_2Layer(chords_num, input_features, timesteps, batch_size):\n",
    "    \n",
    "    main_input = Input(shape=(timesteps,input_features), name='main_input')\n",
    "    \n",
    "    x = Dropout(0.2)(main_input)\n",
    "    x = Dense(100)(x)\n",
    "    #BLSTM\n",
    "    x = Bidirectional(LSTM(units = 64, activation='tanh', return_sequences = True))(x)\n",
    "    \n",
    "    x = Dropout(0.4)(x)\n",
    "    #BLSTM\n",
    "    x = Bidirectional(LSTM(units = 64, activation='tanh', return_sequences=True))(x)\n",
    "    \n",
    "    x = Dropout(0.4)(x)\n",
    "    \n",
    "    #Dense for classification\n",
    "    u = TimeDistributed(Dense(1))(x)\n",
    "    unknown = Activation('sigmoid')(u)\n",
    "    \n",
    "    g = TimeDistributed(Dense(8))(x)\n",
    "    triad = Activation('softmax')(g)\n",
    "\n",
    "    d = TimeDistributed(Dense(6))(x)\n",
    "    fourth = Activation('softmax')(d)\n",
    "\n",
    "    \n",
    "    \n",
    "    # concatenation\n",
    "    main_output = concatenate([unknown,triad,fourth], axis=-1)\n",
    "    \n",
    "    #model\n",
    "    model = Model(inputs=[main_input], outputs=[main_output])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RCNN_Net(chords_num, input_features, timesteps, batch_size):\n",
    "    \n",
    "    main_input = Input(shape=(timesteps,input_features,1), name='main_input')\n",
    "    \n",
    "    # Root part\n",
    "    #Convolutional Stack 1\n",
    "    c =  Conv2D(filters=16, \n",
    "            kernel_size=(3,3),\n",
    "            padding='same')(main_input)\n",
    "    c = Activation('relu')(c)\n",
    "    c = BatchNormalization()(c)\n",
    "    \n",
    "    c =  Conv2D(filters=16, \n",
    "            kernel_size=(3,3),\n",
    "            padding='same')(c)\n",
    "    c = Activation('relu')(c)\n",
    "    c = BatchNormalization()(c)\n",
    "    \n",
    "    c =  Conv2D(filters=16, \n",
    "            kernel_size=(3,3),\n",
    "            padding='same')(c)\n",
    "    c = Activation('relu')(c)\n",
    "    c = BatchNormalization()(c)\n",
    "    \n",
    "    c = MaxPooling2D(pool_size=(1,3))(c)\n",
    "    c = Dropout(0.25)(c)\n",
    "    \n",
    "    \n",
    "    c =  Conv2D(filters=32, \n",
    "            kernel_size=(3,3),\n",
    "            padding='same')(c)\n",
    "    c = Activation('relu')(c)\n",
    "    c = BatchNormalization()(c)\n",
    "    \n",
    "    c =  Conv2D(filters=32, \n",
    "            kernel_size=(3,3),\n",
    "            padding='same')(c)\n",
    "    c = Activation('relu')(c)\n",
    "    c = BatchNormalization()(c)\n",
    "    \n",
    "    c =  Conv2D(filters=32, \n",
    "            kernel_size=(3,3),\n",
    "            padding='same')(c)\n",
    "    c = Activation('relu')(c)\n",
    "    c = BatchNormalization()(c)\n",
    "    \n",
    "    c = MaxPooling2D(pool_size=(1,3))(c)\n",
    "    c = Dropout(0.25)(c)\n",
    "    \n",
    "    \n",
    "    c =  Conv2D(filters=64, \n",
    "            kernel_size=(3,3),\n",
    "            padding='same')(c)\n",
    "    c = Activation('relu')(c)\n",
    "    c = BatchNormalization()(c)\n",
    "    \n",
    "    c =  Conv2D(filters=64, \n",
    "            kernel_size=(3,3),\n",
    "            padding='same')(c)\n",
    "    c = Activation('relu')(c)\n",
    "    c = BatchNormalization()(c)\n",
    "    \n",
    "    \n",
    "    c = MaxPooling2D(pool_size=(1,4))(c)\n",
    "    c = Dropout(0.25)(c)\n",
    "    \n",
    "    \n",
    "    xc = TimeDistributed(Flatten())(c)\n",
    "    xc = BatchNormalization()(xc)\n",
    "    \n",
    "    xc = Dense(128)(xc)\n",
    "    # Root Part\n",
    "    root = Bidirectional(LSTM(units = 64,\n",
    "                              return_sequences=True))(xc)\n",
    "    \n",
    "    linear = Dropout(0.4)(root)\n",
    "    #Dense for classification\n",
    "    r = TimeDistributed(Dense(chords_num))(linear)\n",
    "    root = Activation('softmax', name='root_output')(r)\n",
    "    \n",
    "    b = TimeDistributed(Dense(chords_num))(linear)\n",
    "    bass = Activation('softmax', name='bass_output')(b)\n",
    "    \n",
    "    t = TimeDistributed(Dense(8))(linear)\n",
    "    triad = Activation('softmax', name='triad_output')(t)\n",
    "    \n",
    "    f = TimeDistributed(Dense(6))(linear)\n",
    "    fourth = Activation('softmax', name='fourth_output')(f)\n",
    "    \n",
    "    #model\n",
    "    model = Model(inputs=[main_input], outputs=[root,bass,triad,fourth])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RCNN_Net(chords_num, input_features, timesteps, batch_size):\n",
    "    \n",
    "    main_input = Input(shape=(timesteps,input_features,1), name='main_input')\n",
    "    \n",
    "    # Root part\n",
    "    #Convolutional Stack 1\n",
    "    c =  Conv2D(filters=16, \n",
    "            kernel_size=(3,3),\n",
    "            padding='same')(main_input)\n",
    "    c = Activation('relu')(c)\n",
    "    c = BatchNormalization()(c)\n",
    "    \n",
    "    c =  Conv2D(filters=16, \n",
    "            kernel_size=(3,3),\n",
    "            padding='same')(c)\n",
    "    c = Activation('relu')(c)\n",
    "    c = BatchNormalization()(c)\n",
    "    \n",
    "    c =  Conv2D(filters=16, \n",
    "            kernel_size=(3,3),\n",
    "            padding='same')(c)\n",
    "    c = Activation('relu')(c)\n",
    "    c = BatchNormalization()(c)\n",
    "    \n",
    "    c = MaxPooling2D(pool_size=(1,3))(c)\n",
    "    c = Dropout(0.25)(c)\n",
    "    \n",
    "    \n",
    "    c =  Conv2D(filters=32, \n",
    "            kernel_size=(3,3),\n",
    "            padding='same')(c)\n",
    "    c = Activation('relu')(c)\n",
    "    c = BatchNormalization()(c)\n",
    "    \n",
    "    c =  Conv2D(filters=32, \n",
    "            kernel_size=(3,3),\n",
    "            padding='same')(c)\n",
    "    c = Activation('relu')(c)\n",
    "    c = BatchNormalization()(c)\n",
    "    \n",
    "    c =  Conv2D(filters=32, \n",
    "            kernel_size=(3,3),\n",
    "            padding='same')(c)\n",
    "    c = Activation('relu')(c)\n",
    "    c = BatchNormalization()(c)\n",
    "    \n",
    "    c = MaxPooling2D(pool_size=(1,3))(c)\n",
    "    c = Dropout(0.25)(c)\n",
    "    \n",
    "    \n",
    "    c =  Conv2D(filters=64, \n",
    "            kernel_size=(3,3),\n",
    "            padding='same')(c)\n",
    "    c = Activation('relu')(c)\n",
    "    c = BatchNormalization()(c)\n",
    "    \n",
    "    c =  Conv2D(filters=64, \n",
    "            kernel_size=(3,3),\n",
    "            padding='same')(c)\n",
    "    c = Activation('relu')(c)\n",
    "    c = BatchNormalization()(c)\n",
    "    \n",
    "    \n",
    "    c = MaxPooling2D(pool_size=(1,4))(c)\n",
    "    c = Dropout(0.25)(c)\n",
    "    \n",
    "    \n",
    "    c =  Conv2D(filters=128, \n",
    "            kernel_size=(3,3),\n",
    "            padding='same')(c)\n",
    "    c = Activation('relu')(c)\n",
    "    c = BatchNormalization()(c)\n",
    "    \n",
    "    c =  Conv2D(filters=128, \n",
    "            kernel_size=(3,3),\n",
    "            padding='same')(c)\n",
    "    c = Activation('relu')(c)\n",
    "    c = BatchNormalization()(c)\n",
    "    \n",
    "    c = Dense(64)(c)\n",
    "    \n",
    "    xc = TimeDistributed(Flatten())(c)\n",
    "    xc = BatchNormalization()(xc)\n",
    "\n",
    "    # Root Part\n",
    "    root = Bidirectional(LSTM(units = 128,\n",
    "                              return_sequences=True))(xc)\n",
    "    \n",
    "    linear = Dropout(0.4)(root)\n",
    "    #Dense for classification\n",
    "    r = TimeDistributed(Dense(chords_num))(linear)\n",
    "    root = Activation('softmax', name='root_output')(r)\n",
    "    \n",
    "    b = TimeDistributed(Dense(chords_num))(linear)\n",
    "    bass = Activation('softmax', name='bass_output')(b)\n",
    "    \n",
    "    t = TimeDistributed(Dense(8))(linear)\n",
    "    triad = Activation('softmax', name='triad_output')(t)\n",
    "    \n",
    "    f = TimeDistributed(Dense(6))(linear)\n",
    "    fourth = Activation('softmax', name='fourth_output')(f)\n",
    "    \n",
    "    #model\n",
    "    model = Model(inputs=[main_input], outputs=[root,bass,triad,fourth])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RCNN_Net(14, input_features, chunk_size, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {\n",
    "    \"root_output\": \"categorical_crossentropy\",\n",
    "    \"bass_output\": \"categorical_crossentropy\",\n",
    "    \"triad_output\": \"categorical_crossentropy\",\n",
    "    \"fourth_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {\"root_output\": 1.0, \"bass_output\": 1.0, \"triad_output\": 1.0, \"fourth_output\": 1.0}\n",
    "opt = keras.optimizers.Adam()\n",
    "\n",
    "model.compile(optimizer=opt, loss=losses, loss_weights=lossWeights, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_20\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         [(None, 300, 192, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 300, 192, 16) 160         main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 300, 192, 16) 0           conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 300, 192, 16) 64          activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 300, 192, 16) 2320        batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 300, 192, 16) 0           conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 300, 192, 16) 64          activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 300, 192, 16) 2320        batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 300, 192, 16) 0           conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 300, 192, 16) 64          activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_58 (MaxPooling2D) (None, 300, 64, 16)  0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)            (None, 300, 64, 16)  0           max_pooling2d_58[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 300, 64, 32)  4640        dropout_79[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 300, 64, 32)  0           conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 300, 64, 32)  128         activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 300, 64, 32)  9248        batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 300, 64, 32)  0           conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 300, 64, 32)  128         activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 300, 64, 32)  9248        batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 300, 64, 32)  0           conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 300, 64, 32)  128         activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_59 (MaxPooling2D) (None, 300, 21, 32)  0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)            (None, 300, 21, 32)  0           max_pooling2d_59[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 300, 21, 64)  18496       dropout_80[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 300, 21, 64)  0           conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 300, 21, 64)  256         activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 300, 21, 64)  36928       batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 300, 21, 64)  0           conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 300, 21, 64)  256         activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_60 (MaxPooling2D) (None, 300, 5, 64)   0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_81 (Dropout)            (None, 300, 5, 64)   0           max_pooling2d_60[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 300, 5, 128)  73856       dropout_81[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 300, 5, 128)  0           conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 300, 5, 128)  512         activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 300, 5, 128)  147584      batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 300, 5, 128)  0           conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 300, 5, 128)  512         activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_87 (Dense)                (None, 300, 5, 64)   8256        batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_97 (TimeDistri (None, 300, 320)     0           dense_87[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 300, 320)     1280        time_distributed_97[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_25 (Bidirectional (None, 300, 256)     459776      batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_82 (Dropout)            (None, 300, 256)     0           bidirectional_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_98 (TimeDistri (None, 300, 14)      3598        dropout_82[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_99 (TimeDistri (None, 300, 14)      3598        dropout_82[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_100 (TimeDistr (None, 300, 8)       2056        dropout_82[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_101 (TimeDistr (None, 300, 6)       1542        dropout_82[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "root_output (Activation)        (None, 300, 14)      0           time_distributed_98[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bass_output (Activation)        (None, 300, 14)      0           time_distributed_99[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "triad_output (Activation)       (None, 300, 8)       0           time_distributed_100[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fourth_output (Activation)      (None, 300, 6)       0           time_distributed_101[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 787,018\n",
      "Trainable params: 785,322\n",
      "Non-trainable params: 1,696\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"model2_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to use the hybrid model\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], x_train.shape[2], 1))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], x_test.shape[2], 1))\n",
    "x_val = np.reshape(x_val, (x_val.shape[0], x_val.shape[1], x_val.shape[2], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], x_train.shape[2]))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], x_test.shape[2]))\n",
    "x_val = np.reshape(x_val, (x_val.shape[0], x_val.shape[1], x_val.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1023 samples, validate on 106 samples\n",
      "Epoch 1/30\n",
      "1023/1023 [==============================] - 93s 91ms/sample - loss: 6.2973 - root_output_loss: 2.3092 - bass_output_loss: 2.3112 - triad_output_loss: 0.9522 - fourth_output_loss: 0.7239 - root_output_accuracy: 0.2170 - bass_output_accuracy: 0.2130 - triad_output_accuracy: 0.7133 - fourth_output_accuracy: 0.8021 - val_loss: 8.0637 - val_root_output_loss: 2.6466 - val_bass_output_loss: 2.9051 - val_triad_output_loss: 1.7919 - val_fourth_output_loss: 0.7804 - val_root_output_accuracy: 0.1311 - val_bass_output_accuracy: 0.0801 - val_triad_output_accuracy: 0.1838 - val_fourth_output_accuracy: 0.8142\n",
      "Epoch 2/30\n",
      "1023/1023 [==============================] - 88s 86ms/sample - loss: 5.4971 - root_output_loss: 2.1658 - bass_output_loss: 2.1617 - triad_output_loss: 0.6858 - fourth_output_loss: 0.4836 - root_output_accuracy: 0.2403 - bass_output_accuracy: 0.2436 - triad_output_accuracy: 0.7791 - fourth_output_accuracy: 0.8797 - val_loss: 6.1692 - val_root_output_loss: 2.4513 - val_bass_output_loss: 2.4369 - val_triad_output_loss: 0.8166 - val_fourth_output_loss: 0.5888 - val_root_output_accuracy: 0.2279 - val_bass_output_accuracy: 0.2201 - val_triad_output_accuracy: 0.7186 - val_fourth_output_accuracy: 0.8142\n",
      "Epoch 3/30\n",
      "1023/1023 [==============================] - 88s 86ms/sample - loss: 5.0750 - root_output_loss: 1.9771 - bass_output_loss: 1.9628 - triad_output_loss: 0.6617 - fourth_output_loss: 0.4729 - root_output_accuracy: 0.3429 - bass_output_accuracy: 0.3572 - triad_output_accuracy: 0.7801 - fourth_output_accuracy: 0.8799 - val_loss: 5.2648 - val_root_output_loss: 2.0609 - val_bass_output_loss: 2.0909 - val_triad_output_loss: 0.7221 - val_fourth_output_loss: 0.5858 - val_root_output_accuracy: 0.4468 - val_bass_output_accuracy: 0.4590 - val_triad_output_accuracy: 0.7284 - val_fourth_output_accuracy: 0.8142\n",
      "Epoch 4/30\n",
      "1023/1023 [==============================] - 89s 87ms/sample - loss: 3.8711 - root_output_loss: 1.4024 - bass_output_loss: 1.3302 - triad_output_loss: 0.6541 - fourth_output_loss: 0.4836 - root_output_accuracy: 0.5878 - bass_output_accuracy: 0.6107 - triad_output_accuracy: 0.7770 - fourth_output_accuracy: 0.8777 - val_loss: 4.2692 - val_root_output_loss: 1.5666 - val_bass_output_loss: 1.5258 - val_triad_output_loss: 0.7573 - val_fourth_output_loss: 0.5725 - val_root_output_accuracy: 0.5800 - val_bass_output_accuracy: 0.5754 - val_triad_output_accuracy: 0.7302 - val_fourth_output_accuracy: 0.8142\n",
      "Epoch 5/30\n",
      "1023/1023 [==============================] - 89s 87ms/sample - loss: 3.0041 - root_output_loss: 0.9970 - bass_output_loss: 0.9197 - triad_output_loss: 0.6142 - fourth_output_loss: 0.4729 - root_output_accuracy: 0.7110 - bass_output_accuracy: 0.7353 - triad_output_accuracy: 0.7824 - fourth_output_accuracy: 0.8763 - val_loss: 3.6611 - val_root_output_loss: 1.1531 - val_bass_output_loss: 1.1550 - val_triad_output_loss: 0.7195 - val_fourth_output_loss: 0.6160 - val_root_output_accuracy: 0.6814 - val_bass_output_accuracy: 0.6773 - val_triad_output_accuracy: 0.7426 - val_fourth_output_accuracy: 0.8142\n",
      "Epoch 6/30\n",
      "1023/1023 [==============================] - 88s 86ms/sample - loss: 2.5244 - root_output_loss: 0.7765 - bass_output_loss: 0.7104 - triad_output_loss: 0.5782 - fourth_output_loss: 0.4595 - root_output_accuracy: 0.7819 - bass_output_accuracy: 0.7989 - triad_output_accuracy: 0.7899 - fourth_output_accuracy: 0.8776 - val_loss: 3.2817 - val_root_output_loss: 0.9660 - val_bass_output_loss: 1.0276 - val_triad_output_loss: 0.6573 - val_fourth_output_loss: 0.5439 - val_root_output_accuracy: 0.7296 - val_bass_output_accuracy: 0.7217 - val_triad_output_accuracy: 0.7411 - val_fourth_output_accuracy: 0.8143\n",
      "Epoch 7/30\n",
      "1023/1023 [==============================] - 90s 88ms/sample - loss: 2.2607 - root_output_loss: 0.6648 - bass_output_loss: 0.6136 - triad_output_loss: 0.5373 - fourth_output_loss: 0.4452 - root_output_accuracy: 0.8130 - bass_output_accuracy: 0.8282 - triad_output_accuracy: 0.8042 - fourth_output_accuracy: 0.8771 - val_loss: 3.0360 - val_root_output_loss: 0.8275 - val_bass_output_loss: 0.8983 - val_triad_output_loss: 0.6069 - val_fourth_output_loss: 0.5552 - val_root_output_accuracy: 0.7672 - val_bass_output_accuracy: 0.7608 - val_triad_output_accuracy: 0.7761 - val_fourth_output_accuracy: 0.8137\n",
      "Epoch 8/30\n",
      "1023/1023 [==============================] - 88s 86ms/sample - loss: 2.0338 - root_output_loss: 0.5739 - bass_output_loss: 0.5372 - triad_output_loss: 0.4863 - fourth_output_loss: 0.4360 - root_output_accuracy: 0.8390 - bass_output_accuracy: 0.8497 - triad_output_accuracy: 0.8245 - fourth_output_accuracy: 0.8775 - val_loss: 2.8537 - val_root_output_loss: 0.7490 - val_bass_output_loss: 0.8345 - val_triad_output_loss: 0.5488 - val_fourth_output_loss: 0.5485 - val_root_output_accuracy: 0.7897 - val_bass_output_accuracy: 0.7750 - val_triad_output_accuracy: 0.8091 - val_fourth_output_accuracy: 0.8156\n",
      "Epoch 9/30\n",
      "1023/1023 [==============================] - 87s 85ms/sample - loss: 1.8877 - root_output_loss: 0.5260 - bass_output_loss: 0.4997 - triad_output_loss: 0.4437 - fourth_output_loss: 0.4184 - root_output_accuracy: 0.8511 - bass_output_accuracy: 0.8584 - triad_output_accuracy: 0.8430 - fourth_output_accuracy: 0.8785 - val_loss: 2.7460 - val_root_output_loss: 0.6890 - val_bass_output_loss: 0.8271 - val_triad_output_loss: 0.5152 - val_fourth_output_loss: 0.5634 - val_root_output_accuracy: 0.7983 - val_bass_output_accuracy: 0.7810 - val_triad_output_accuracy: 0.8208 - val_fourth_output_accuracy: 0.8152\n",
      "Epoch 10/30\n",
      "1023/1023 [==============================] - 87s 85ms/sample - loss: 1.7787 - root_output_loss: 0.4926 - bass_output_loss: 0.4687 - triad_output_loss: 0.4074 - fourth_output_loss: 0.4102 - root_output_accuracy: 0.8591 - bass_output_accuracy: 0.8667 - triad_output_accuracy: 0.8603 - fourth_output_accuracy: 0.8793 - val_loss: 2.7655 - val_root_output_loss: 0.6678 - val_bass_output_loss: 0.8084 - val_triad_output_loss: 0.5505 - val_fourth_output_loss: 0.5696 - val_root_output_accuracy: 0.8089 - val_bass_output_accuracy: 0.7907 - val_triad_output_accuracy: 0.8119 - val_fourth_output_accuracy: 0.8150\n",
      "Epoch 11/30\n",
      "1023/1023 [==============================] - 88s 86ms/sample - loss: 1.6762 - root_output_loss: 0.4601 - bass_output_loss: 0.4386 - triad_output_loss: 0.3818 - fourth_output_loss: 0.3959 - root_output_accuracy: 0.8680 - bass_output_accuracy: 0.8754 - triad_output_accuracy: 0.8708 - fourth_output_accuracy: 0.8818 - val_loss: 2.7609 - val_root_output_loss: 0.6852 - val_bass_output_loss: 0.8236 - val_triad_output_loss: 0.4973 - val_fourth_output_loss: 0.5596 - val_root_output_accuracy: 0.8018 - val_bass_output_accuracy: 0.7842 - val_triad_output_accuracy: 0.8399 - val_fourth_output_accuracy: 0.8151\n",
      "Epoch 12/30\n",
      "1023/1023 [==============================] - 88s 86ms/sample - loss: 1.5761 - root_output_loss: 0.4306 - bass_output_loss: 0.4128 - triad_output_loss: 0.3522 - fourth_output_loss: 0.3805 - root_output_accuracy: 0.8750 - bass_output_accuracy: 0.8813 - triad_output_accuracy: 0.8824 - fourth_output_accuracy: 0.8843 - val_loss: 2.6145 - val_root_output_loss: 0.6591 - val_bass_output_loss: 0.7645 - val_triad_output_loss: 0.4294 - val_fourth_output_loss: 0.5732 - val_root_output_accuracy: 0.8125 - val_bass_output_accuracy: 0.7953 - val_triad_output_accuracy: 0.8517 - val_fourth_output_accuracy: 0.8176\n",
      "Epoch 13/30\n",
      "1023/1023 [==============================] - 91s 89ms/sample - loss: 1.4957 - root_output_loss: 0.4066 - bass_output_loss: 0.3959 - triad_output_loss: 0.3305 - fourth_output_loss: 0.3627 - root_output_accuracy: 0.8808 - bass_output_accuracy: 0.8845 - triad_output_accuracy: 0.8920 - fourth_output_accuracy: 0.8881 - val_loss: 2.6261 - val_root_output_loss: 0.6517 - val_bass_output_loss: 0.7857 - val_triad_output_loss: 0.4288 - val_fourth_output_loss: 0.5589 - val_root_output_accuracy: 0.8175 - val_bass_output_accuracy: 0.8005 - val_triad_output_accuracy: 0.8647 - val_fourth_output_accuracy: 0.8193\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1023/1023 [==============================] - 89s 87ms/sample - loss: 1.4409 - root_output_loss: 0.3946 - bass_output_loss: 0.3789 - triad_output_loss: 0.3178 - fourth_output_loss: 0.3496 - root_output_accuracy: 0.8834 - bass_output_accuracy: 0.8891 - triad_output_accuracy: 0.8954 - fourth_output_accuracy: 0.8913 - val_loss: 2.4879 - val_root_output_loss: 0.6153 - val_bass_output_loss: 0.7401 - val_triad_output_loss: 0.4219 - val_fourth_output_loss: 0.5252 - val_root_output_accuracy: 0.8199 - val_bass_output_accuracy: 0.8068 - val_triad_output_accuracy: 0.8574 - val_fourth_output_accuracy: 0.8194\n",
      "Epoch 15/30\n",
      "1023/1023 [==============================] - 87s 85ms/sample - loss: 1.3812 - root_output_loss: 0.3757 - bass_output_loss: 0.3642 - triad_output_loss: 0.3015 - fourth_output_loss: 0.3398 - root_output_accuracy: 0.8893 - bass_output_accuracy: 0.8929 - triad_output_accuracy: 0.9011 - fourth_output_accuracy: 0.8944 - val_loss: 2.4659 - val_root_output_loss: 0.5988 - val_bass_output_loss: 0.6939 - val_triad_output_loss: 0.4342 - val_fourth_output_loss: 0.5546 - val_root_output_accuracy: 0.8242 - val_bass_output_accuracy: 0.8161 - val_triad_output_accuracy: 0.8494 - val_fourth_output_accuracy: 0.8155\n",
      "Epoch 16/30\n",
      "1023/1023 [==============================] - 87s 85ms/sample - loss: 1.3113 - root_output_loss: 0.3556 - bass_output_loss: 0.3458 - triad_output_loss: 0.2875 - fourth_output_loss: 0.3223 - root_output_accuracy: 0.8950 - bass_output_accuracy: 0.8987 - triad_output_accuracy: 0.9063 - fourth_output_accuracy: 0.8983 - val_loss: 2.6082 - val_root_output_loss: 0.6192 - val_bass_output_loss: 0.7550 - val_triad_output_loss: 0.4706 - val_fourth_output_loss: 0.5650 - val_root_output_accuracy: 0.8247 - val_bass_output_accuracy: 0.8091 - val_triad_output_accuracy: 0.8519 - val_fourth_output_accuracy: 0.8233\n",
      "Epoch 17/30\n",
      "1023/1023 [==============================] - 88s 86ms/sample - loss: 1.2701 - root_output_loss: 0.3438 - bass_output_loss: 0.3371 - triad_output_loss: 0.2778 - fourth_output_loss: 0.3113 - root_output_accuracy: 0.8984 - bass_output_accuracy: 0.9013 - triad_output_accuracy: 0.9099 - fourth_output_accuracy: 0.9017 - val_loss: 2.6227 - val_root_output_loss: 0.6090 - val_bass_output_loss: 0.7413 - val_triad_output_loss: 0.5083 - val_fourth_output_loss: 0.5647 - val_root_output_accuracy: 0.8235 - val_bass_output_accuracy: 0.8123 - val_triad_output_accuracy: 0.8508 - val_fourth_output_accuracy: 0.8231\n",
      "Epoch 18/30\n",
      "1023/1023 [==============================] - 87s 86ms/sample - loss: 1.2164 - root_output_loss: 0.3274 - bass_output_loss: 0.3218 - triad_output_loss: 0.2667 - fourth_output_loss: 0.3005 - root_output_accuracy: 0.9034 - bass_output_accuracy: 0.9053 - triad_output_accuracy: 0.9140 - fourth_output_accuracy: 0.9050 - val_loss: 2.5507 - val_root_output_loss: 0.6215 - val_bass_output_loss: 0.7531 - val_triad_output_loss: 0.4444 - val_fourth_output_loss: 0.5439 - val_root_output_accuracy: 0.8249 - val_bass_output_accuracy: 0.8113 - val_triad_output_accuracy: 0.8666 - val_fourth_output_accuracy: 0.8318\n",
      "Epoch 19/30\n",
      "1023/1023 [==============================] - 87s 85ms/sample - loss: 1.1747 - root_output_loss: 0.3190 - bass_output_loss: 0.3111 - triad_output_loss: 0.2546 - fourth_output_loss: 0.2898 - root_output_accuracy: 0.9051 - bass_output_accuracy: 0.9073 - triad_output_accuracy: 0.9173 - fourth_output_accuracy: 0.9075 - val_loss: 2.4917 - val_root_output_loss: 0.6130 - val_bass_output_loss: 0.7241 - val_triad_output_loss: 0.4173 - val_fourth_output_loss: 0.5617 - val_root_output_accuracy: 0.8266 - val_bass_output_accuracy: 0.8113 - val_triad_output_accuracy: 0.8709 - val_fourth_output_accuracy: 0.8173\n",
      "Epoch 20/30\n",
      "1023/1023 [==============================] - 88s 86ms/sample - loss: 1.1269 - root_output_loss: 0.3062 - bass_output_loss: 0.3016 - triad_output_loss: 0.2411 - fourth_output_loss: 0.2779 - root_output_accuracy: 0.9088 - bass_output_accuracy: 0.9110 - triad_output_accuracy: 0.9221 - fourth_output_accuracy: 0.9112 - val_loss: 2.4545 - val_root_output_loss: 0.5928 - val_bass_output_loss: 0.6992 - val_triad_output_loss: 0.4003 - val_fourth_output_loss: 0.5871 - val_root_output_accuracy: 0.8335 - val_bass_output_accuracy: 0.8226 - val_triad_output_accuracy: 0.8811 - val_fourth_output_accuracy: 0.8313\n",
      "Epoch 21/30\n",
      "1023/1023 [==============================] - 87s 86ms/sample - loss: 1.0879 - root_output_loss: 0.2982 - bass_output_loss: 0.2960 - triad_output_loss: 0.2325 - fourth_output_loss: 0.2612 - root_output_accuracy: 0.9103 - bass_output_accuracy: 0.9123 - triad_output_accuracy: 0.9251 - fourth_output_accuracy: 0.9164 - val_loss: 2.5823 - val_root_output_loss: 0.6042 - val_bass_output_loss: 0.7230 - val_triad_output_loss: 0.4569 - val_fourth_output_loss: 0.6072 - val_root_output_accuracy: 0.8308 - val_bass_output_accuracy: 0.8171 - val_triad_output_accuracy: 0.8692 - val_fourth_output_accuracy: 0.8301\n",
      "Epoch 22/30\n",
      "1023/1023 [==============================] - 87s 85ms/sample - loss: 1.0527 - root_output_loss: 0.2867 - bass_output_loss: 0.2829 - triad_output_loss: 0.2270 - fourth_output_loss: 0.2560 - root_output_accuracy: 0.9138 - bass_output_accuracy: 0.9157 - triad_output_accuracy: 0.9265 - fourth_output_accuracy: 0.9187 - val_loss: 2.5037 - val_root_output_loss: 0.5922 - val_bass_output_loss: 0.7188 - val_triad_output_loss: 0.4021 - val_fourth_output_loss: 0.6152 - val_root_output_accuracy: 0.8316 - val_bass_output_accuracy: 0.8195 - val_triad_output_accuracy: 0.8742 - val_fourth_output_accuracy: 0.8270\n",
      "Epoch 23/30\n",
      "1023/1023 [==============================] - 87s 85ms/sample - loss: 1.0189 - root_output_loss: 0.2793 - bass_output_loss: 0.2776 - triad_output_loss: 0.2144 - fourth_output_loss: 0.2476 - root_output_accuracy: 0.9153 - bass_output_accuracy: 0.9165 - triad_output_accuracy: 0.9314 - fourth_output_accuracy: 0.9206 - val_loss: 2.6767 - val_root_output_loss: 0.6572 - val_bass_output_loss: 0.7754 - val_triad_output_loss: 0.4184 - val_fourth_output_loss: 0.6093 - val_root_output_accuracy: 0.8240 - val_bass_output_accuracy: 0.8121 - val_triad_output_accuracy: 0.8671 - val_fourth_output_accuracy: 0.8251\n",
      "Epoch 24/30\n",
      "1023/1023 [==============================] - 88s 86ms/sample - loss: 0.9842 - root_output_loss: 0.2703 - bass_output_loss: 0.2682 - triad_output_loss: 0.2080 - fourth_output_loss: 0.2375 - root_output_accuracy: 0.9190 - bass_output_accuracy: 0.9195 - triad_output_accuracy: 0.9324 - fourth_output_accuracy: 0.9245 - val_loss: 2.5179 - val_root_output_loss: 0.5925 - val_bass_output_loss: 0.7248 - val_triad_output_loss: 0.4413 - val_fourth_output_loss: 0.5547 - val_root_output_accuracy: 0.8283 - val_bass_output_accuracy: 0.8138 - val_triad_output_accuracy: 0.8672 - val_fourth_output_accuracy: 0.8298\n",
      "Epoch 25/30\n",
      "1023/1023 [==============================] - 87s 85ms/sample - loss: 1.1244 - root_output_loss: 0.3175 - bass_output_loss: 0.3172 - triad_output_loss: 0.2380 - fourth_output_loss: 0.2519 - root_output_accuracy: 0.9046 - bass_output_accuracy: 0.9046 - triad_output_accuracy: 0.9233 - fourth_output_accuracy: 0.9199 - val_loss: 2.9578 - val_root_output_loss: 0.7318 - val_bass_output_loss: 0.8510 - val_triad_output_loss: 0.5052 - val_fourth_output_loss: 0.6129 - val_root_output_accuracy: 0.7995 - val_bass_output_accuracy: 0.7840 - val_triad_output_accuracy: 0.8319 - val_fourth_output_accuracy: 0.7901\n",
      "Epoch 26/30\n",
      "1023/1023 [==============================] - 87s 85ms/sample - loss: 1.1372 - root_output_loss: 0.3167 - bass_output_loss: 0.3110 - triad_output_loss: 0.2443 - fourth_output_loss: 0.2652 - root_output_accuracy: 0.9045 - bass_output_accuracy: 0.9073 - triad_output_accuracy: 0.9208 - fourth_output_accuracy: 0.9155 - val_loss: 2.6055 - val_root_output_loss: 0.6297 - val_bass_output_loss: 0.7261 - val_triad_output_loss: 0.4609 - val_fourth_output_loss: 0.6122 - val_root_output_accuracy: 0.8262 - val_bass_output_accuracy: 0.8108 - val_triad_output_accuracy: 0.8675 - val_fourth_output_accuracy: 0.8098\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1023/1023 [==============================] - 87s 85ms/sample - loss: 1.0151 - root_output_loss: 0.2819 - bass_output_loss: 0.2777 - triad_output_loss: 0.2156 - fourth_output_loss: 0.2400 - root_output_accuracy: 0.9149 - bass_output_accuracy: 0.9163 - triad_output_accuracy: 0.9302 - fourth_output_accuracy: 0.9228 - val_loss: 2.5214 - val_root_output_loss: 0.6023 - val_bass_output_loss: 0.6802 - val_triad_output_loss: 0.4069 - val_fourth_output_loss: 0.6711 - val_root_output_accuracy: 0.8352 - val_bass_output_accuracy: 0.8231 - val_triad_output_accuracy: 0.8770 - val_fourth_output_accuracy: 0.8219\n",
      "Epoch 28/30\n",
      "1023/1023 [==============================] - 87s 85ms/sample - loss: 0.9518 - root_output_loss: 0.2672 - bass_output_loss: 0.2667 - triad_output_loss: 0.1972 - fourth_output_loss: 0.2206 - root_output_accuracy: 0.9194 - bass_output_accuracy: 0.9197 - triad_output_accuracy: 0.9371 - fourth_output_accuracy: 0.9300 - val_loss: 2.5780 - val_root_output_loss: 0.6072 - val_bass_output_loss: 0.7329 - val_triad_output_loss: 0.4369 - val_fourth_output_loss: 0.6303 - val_root_output_accuracy: 0.8319 - val_bass_output_accuracy: 0.8132 - val_triad_output_accuracy: 0.8732 - val_fourth_output_accuracy: 0.8284\n",
      "Epoch 29/30\n",
      "1023/1023 [==============================] - 87s 85ms/sample - loss: 0.8907 - root_output_loss: 0.2457 - bass_output_loss: 0.2478 - triad_output_loss: 0.1847 - fourth_output_loss: 0.2126 - root_output_accuracy: 0.9252 - bass_output_accuracy: 0.9253 - triad_output_accuracy: 0.9403 - fourth_output_accuracy: 0.9316 - val_loss: 2.5992 - val_root_output_loss: 0.6010 - val_bass_output_loss: 0.7218 - val_triad_output_loss: 0.4436 - val_fourth_output_loss: 0.6445 - val_root_output_accuracy: 0.8340 - val_bass_output_accuracy: 0.8136 - val_triad_output_accuracy: 0.8758 - val_fourth_output_accuracy: 0.8263\n",
      "Epoch 30/30\n",
      "1023/1023 [==============================] - 87s 85ms/sample - loss: 0.8596 - root_output_loss: 0.2381 - bass_output_loss: 0.2410 - triad_output_loss: 0.1766 - fourth_output_loss: 0.2039 - root_output_accuracy: 0.9270 - bass_output_accuracy: 0.9269 - triad_output_accuracy: 0.9437 - fourth_output_accuracy: 0.9342 - val_loss: 2.5679 - val_root_output_loss: 0.6034 - val_bass_output_loss: 0.7153 - val_triad_output_loss: 0.4376 - val_fourth_output_loss: 0.6209 - val_root_output_accuracy: 0.8382 - val_bass_output_accuracy: 0.8179 - val_triad_output_accuracy: 0.8768 - val_fourth_output_accuracy: 0.8262\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "\n",
    "# train\n",
    "callback_history = model.fit(x_train, \n",
    "                             {\"root_output\": y_train_root, \"bass_output\": y_train_bass, \"triad_output\": y_train_triad,\"fourth_output\": y_train_fourth},\n",
    "                             epochs=epochs, \n",
    "                             validation_data=(x_val, {\"root_output\": y_val_root, \"bass_output\": y_val_bass, \"triad_output\": y_val_triad,\"fourth_output\": y_val_fourth}), \n",
    "                             batch_size=batch_size,\n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track  05\n",
      "Accuracy root: \t\t 38.83 % \n",
      "Accuracy bass: \t\t 21.83 % \n",
      "Accuracy triad: \t 85.50 % \n",
      "Accuracy fourth: \t 6.83 % \n",
      "\n",
      "Track  10\n",
      "Accuracy root: \t\t 94.93 % \n",
      "Accuracy bass: \t\t 94.67 % \n",
      "Accuracy triad: \t 96.27 % \n",
      "Accuracy fourth: \t 96.53 % \n",
      "\n",
      "Track  02\n",
      "Accuracy root: \t\t 64.67 % \n",
      "Accuracy bass: \t\t 57.56 % \n",
      "Accuracy triad: \t 79.48 % \n",
      "Accuracy fourth: \t 80.15 % \n",
      "\n",
      "Track  17\n",
      "Accuracy root: \t\t 93.43 % \n",
      "Accuracy bass: \t\t 88.14 % \n",
      "Accuracy triad: \t 89.48 % \n",
      "Accuracy fourth: \t 83.33 % \n",
      "\n",
      "Track  12\n",
      "Accuracy root: \t\t 92.27 % \n",
      "Accuracy bass: \t\t 91.33 % \n",
      "Accuracy triad: \t 93.53 % \n",
      "Accuracy fourth: \t 100.00 % \n",
      "\n",
      "Track  08\n",
      "Accuracy root: \t\t 97.11 % \n",
      "Accuracy bass: \t\t 94.11 % \n",
      "Accuracy triad: \t 92.44 % \n",
      "Accuracy fourth: \t 88.78 % \n",
      "\n",
      "Track  14\n",
      "Accuracy root: \t\t 93.85 % \n",
      "Accuracy bass: \t\t 94.70 % \n",
      "Accuracy triad: \t 96.52 % \n",
      "Accuracy fourth: \t 99.96 % \n",
      "\n",
      "Track  16\n",
      "Accuracy root: \t\t 86.25 % \n",
      "Accuracy bass: \t\t 81.17 % \n",
      "Accuracy triad: \t 91.25 % \n",
      "Accuracy fourth: \t 87.75 % \n",
      "\n",
      "Track  06\n",
      "Accuracy root: \t\t 89.52 % \n",
      "Accuracy bass: \t\t 88.33 % \n",
      "Accuracy triad: \t 91.86 % \n",
      "Accuracy fourth: \t 100.00 % \n",
      "\n",
      "Track  09\n",
      "Accuracy root: \t\t 91.94 % \n",
      "Accuracy bass: \t\t 91.89 % \n",
      "Accuracy triad: \t 93.44 % \n",
      "Accuracy fourth: \t 59.39 % \n",
      "\n",
      "Track  01\n",
      "Accuracy root: \t\t 92.67 % \n",
      "Accuracy bass: \t\t 91.28 % \n",
      "Accuracy triad: \t 99.61 % \n",
      "Accuracy fourth: \t 91.44 % \n",
      "\n",
      "Track  15\n",
      "Accuracy root: \t\t 98.83 % \n",
      "Accuracy bass: \t\t 98.00 % \n",
      "Accuracy triad: \t 98.50 % \n",
      "Accuracy fourth: \t 75.17 % \n",
      "\n",
      "Track  07\n",
      "Accuracy root: \t\t 86.18 % \n",
      "Accuracy bass: \t\t 86.42 % \n",
      "Accuracy triad: \t 83.88 % \n",
      "Accuracy fourth: \t 94.58 % \n",
      "\n",
      "Track  11\n",
      "Accuracy root: \t\t 72.60 % \n",
      "Accuracy bass: \t\t 66.67 % \n",
      "Accuracy triad: \t 74.40 % \n",
      "Accuracy fourth: \t 86.27 % \n",
      "\n",
      "Track  03\n",
      "Accuracy root: \t\t 81.87 % \n",
      "Accuracy bass: \t\t 86.00 % \n",
      "Accuracy triad: \t 86.27 % \n",
      "Accuracy fourth: \t 61.53 % \n",
      "\n",
      "Track  13\n",
      "Accuracy root: \t\t 90.46 % \n",
      "Accuracy bass: \t\t 97.08 % \n",
      "Accuracy triad: \t 91.17 % \n",
      "Accuracy fourth: \t 55.33 % \n",
      "\n",
      "Track  04\n",
      "Accuracy root: \t\t 95.10 % \n",
      "Accuracy bass: \t\t 93.62 % \n",
      "Accuracy triad: \t 95.71 % \n",
      "Accuracy fourth: \t 98.71 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "for track_no in root_vec[album_validate].keys():\n",
    "    loss, _, _, _, _, accuracy_root, accuracy_bass, accuracy_triad, accuracy_fourth = model.evaluate(x_mirex_test[track_no], [y_mirex_test_root[track_no], y_mirex_test_bass[track_no], y_mirex_test_triad[track_no], y_mirex_test_fourth[track_no]], batch_size=batch_size, verbose=0)\n",
    "    print(\"Track \", track_no)\n",
    "    print(\"Accuracy root: \\t\\t% 3.2f %% \\nAccuracy bass: \\t\\t% 3.2f %% \\nAccuracy triad: \\t% 3.2f %% \\nAccuracy fourth: \\t% 3.2f %% \" %(100*accuracy_root, 100*accuracy_bass, 100*accuracy_triad, 100*accuracy_fourth))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predictions -> Chords**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict root\n",
    "root_predictions = {}\n",
    "bass_predictions = {}\n",
    "triad_predictions = {}\n",
    "fourth_predictions = {}\n",
    "for track_no in root_vec[album_validate].keys():\n",
    "    root_predictions[track_no], bass_predictions[track_no], triad_predictions[track_no], fourth_predictions[track_no] = model.predict(x_mirex_test[track_no], batch_size=batch_size, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Qualities:**<br>\n",
    "Unknown | Major | Minor | Minor Seventh | Major Seventh | Augmented | Diminished | Ninth | Major Sixth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimations_root = {}\n",
    "estimations_triad = {}\n",
    "estimations_fourth = {}\n",
    "estimations_bass = {}\n",
    "\n",
    "for track_no in root_vec[album_validate].keys():\n",
    "    estimations_root[track_no] = []\n",
    "    for batch_chords in root_predictions[track_no]:\n",
    "        for chord in batch_chords:\n",
    "            estimations_root[track_no].append(InverseLib[encoder.inverse_transform([chord]).reshape(1,)[0]])\n",
    "\n",
    "    estimations_bass[track_no] = []            \n",
    "    for batch_chords in bass_predictions[track_no]:\n",
    "        for chord in batch_chords:\n",
    "            estimations_bass[track_no].append(InverseLib[encoder.inverse_transform([chord]).reshape(1,)[0]])\n",
    "    \n",
    "    estimations_triad[track_no] = []  \n",
    "    for quality in triad_predictions[track_no]:\n",
    "        for s in quality:\n",
    "            estimations_triad[track_no].append(InverseLibTriad[encoder_triads.inverse_transform([s]).reshape(1,)[0]])\n",
    "    \n",
    "    estimations_fourth[track_no] = []  \n",
    "    for quality in fourth_predictions[track_no]:\n",
    "        for s in quality:\n",
    "            estimations_fourth[track_no].append(InverseLibFourth[encoder_fourth.inverse_transform([s]).reshape(1,)[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Efficiency of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,5))\n",
    "# summarize history for accuracy\n",
    "plt.plot(callback_history.history['root_output_accuracy'])\n",
    "plt.plot(callback_history.history['val_root_output_accuracy'])\n",
    "plt.plot(callback_history.history['triad_output_accuracy'])\n",
    "plt.plot(callback_history.history['val_triad_output_accuracy'])\n",
    "plt.plot(callback_history.history['fourth_output_accuracy'])\n",
    "plt.plot(callback_history.history['val_fourth_output_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['root train', 'root val', 'triad train', 'triad val', 'fourth train', 'fourth val'], loc='upper left')\n",
    "plt.show()\n",
    "plt.figure(figsize=(16,5))\n",
    "# summarize history for loss\n",
    "plt.plot(callback_history.history['loss'])\n",
    "plt.plot(callback_history.history['val_loss'])\n",
    "plt.title('model total loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build function to transform **Root + Unknown + Triad + Fourth** -> **Full Chord**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to identify chord:\n",
    "- feed the separate intervals -> return the full chord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a chordifier as a structure -> maybe a tree\n",
    "def Chordify(root = 'N', bass = 'null', triad = 'null', fourth = 'null', unknown = 'null'):\n",
    "    # silence\n",
    "    if root == 'N': return root\n",
    "    inverse = ''\n",
    "    chord = root\n",
    "    \n",
    "    # cases\n",
    "    if triad != 'Major' and triad != 'N' or (fourth != 'N' and fourth != 'X' and fourth != 'null'):\n",
    "        chord += ':'\n",
    "        \n",
    "    if triad == 'Aug' and fourth != 'min7':\n",
    "        chord += 'aug'\n",
    "    elif triad == 'Aug' and fourth == 'min7':\n",
    "        chord += 'aug7'\n",
    "        \n",
    "    if triad == 'Sus2':\n",
    "        chord += 'sus2'\n",
    "        \n",
    "    if triad == 'Sus4':\n",
    "        chord += 'sus4'\n",
    "    \n",
    "    if fourth == 'min7' and triad == 'Minor':\n",
    "        chord += 'min7'\n",
    "    elif fourth == 'min7' and triad == 'Dim':\n",
    "        chord += 'hdim7'\n",
    "    elif triad == 'Minor':\n",
    "        chord += 'min'\n",
    "    \n",
    "    if triad == 'Dim' and fourth != 'min7':\n",
    "        chord += 'dim'\n",
    "    \n",
    "    if fourth == 'min7' and triad == 'Major':\n",
    "        chord += '7'\n",
    "    \n",
    "    if fourth == 'maj7':\n",
    "        chord += 'maj7'\n",
    "        \n",
    "    if fourth == 'maj6':\n",
    "        chord += 'maj6'\n",
    "    \n",
    "    # bass inversions\n",
    "    if bass != 'null':\n",
    "        if root != bass:\n",
    "            semitones = (12 - ChordLib[root]) - (12 - ChordLib[bass])\n",
    "            if semitones < 0:\n",
    "                semitones += 12\n",
    "            if semitones != 0:\n",
    "                if semitones == 2:\n",
    "                    inverse = '/2'\n",
    "                elif semitones == 1:\n",
    "                    inverse = '/b2'\n",
    "                elif semitones == 3:\n",
    "                    inverse = '/b3'\n",
    "                elif semitones == 4:\n",
    "                    inverse = '/3'\n",
    "                elif semitones == 5:\n",
    "                    inverse = '/4'\n",
    "                elif semitones == 6:\n",
    "                    inverse = '/b5'\n",
    "                elif semitones == 7:\n",
    "                    inverse = '/5'\n",
    "                elif semitones == 9:\n",
    "                    inverse = '/b7'\n",
    "                elif semitones == 10:\n",
    "                    inverse = '/7'\n",
    "                elif semitones == 11:\n",
    "                    inverse = '/#7'\n",
    "            chord += inverse\n",
    "\n",
    "    return chord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heuristic solution to find the chord changes and smooth results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "for track_no in root_vec[album_validate].keys():\n",
    "    estimated_root_list = estimations_root[track_no]\n",
    "    estimated_bass_list = estimations_bass[track_no]\n",
    "    estimated_triad_list = estimations_triad[track_no]\n",
    "    estimated_fourth_list = estimations_fourth[track_no]\n",
    "    # initializations\n",
    "    min_frames = 4\n",
    "    current_chord_index = 0\n",
    "    current_chord = estimated_root_list[0]\n",
    "    current_mode = estimated_triad_list[0]\n",
    "    current_bass = estimated_bass_list[0]\n",
    "    current_fourth = estimated_fourth_list[0]\n",
    "    previous_chord = estimated_root_list[0]\n",
    "    previous_bass = estimated_bass_list[0]\n",
    "    previous_mode = estimated_triad_list[0]\n",
    "    previous_fourth = estimated_fourth_list[0]\n",
    "    # 0 where chord is same, 1 where the chord changes\n",
    "    chord_change = list(np.zeros((len(estimated_root_list),)))\n",
    "    appearances = 1\n",
    "    # scan root for lstm noise\n",
    "    for i in range(1, len(estimated_root_list)):\n",
    "        chord_root = estimated_root_list[i]\n",
    "        if previous_chord != chord_root:\n",
    "            previous_chord = chord_root\n",
    "            if appearances <= min_frames:\n",
    "                for j in range(i-appearances, i):\n",
    "                    estimated_root_list[j] = previous_chord\n",
    "            appearances = 1\n",
    "        else:\n",
    "            appearances += 1\n",
    "    # re-scan root, and when root changes -> chord change = 1\n",
    "    previous_chord = estimated_root_list[0]\n",
    "    chord_change[0] = 1\n",
    "    for i in range(1, len(estimated_root_list)):\n",
    "        chord_root = estimated_root_list[i]\n",
    "        if previous_chord != chord_root:\n",
    "            chord_change[i] = 1\n",
    "            previous_chord = chord_root\n",
    "    # scan triads and fourths on chord change, to smooth lstm noise\n",
    "    appearances_triad = 0\n",
    "    appearances_fourth = 0\n",
    "    appearances_bass = 0\n",
    "    for i in range(0, len(estimated_root_list)):\n",
    "        mode = estimated_triad_list[i]\n",
    "        fourth = estimated_fourth_list[i]\n",
    "        bass = estimated_bass_list[i]\n",
    "        if chord_change[i]:\n",
    "            if appearances_triad <= min_frames:\n",
    "                for j in range(i-appearances_triad, i):\n",
    "                    estimated_triad_list[j-1] = previous_mode\n",
    "            if appearances_fourth <= min_frames:\n",
    "                for j in range(i-appearances_fourth, i):\n",
    "                    estimated_fourth_list[j-1] = previous_fourth\n",
    "            if appearances_bass <= min_frames:\n",
    "                for j in range(i-appearances_bass, i):\n",
    "                    estimated_bass_list[j-1] = previous_bass\n",
    "            appearances_triad = 0\n",
    "            appearances_fourth = 0\n",
    "            appearances_bass = 0\n",
    "            previous_mode = mode\n",
    "            previous_fourth = fourth\n",
    "            previous_bass = bass\n",
    "        # triad\n",
    "        if current_mode != mode:\n",
    "            if appearances_triad <= min_frames:\n",
    "                for j in range(i-appearances_triad, i):\n",
    "                    estimated_triad_list[j] = previous_mode\n",
    "            else:\n",
    "                previous_mode = current_mode\n",
    "            current_mode = mode\n",
    "            appearances_triad = 1\n",
    "        else:\n",
    "            appearances_triad += 1\n",
    "        # fourth\n",
    "        if current_fourth != fourth:\n",
    "            if appearances_fourth <= min_frames:\n",
    "                for j in range(i-appearances_fourth, i):\n",
    "                    estimated_fourth_list[j] = previous_fourth\n",
    "            else:\n",
    "                previous_fourth = current_fourth\n",
    "            current_fourth = fourth\n",
    "            appearances_fourth = 1\n",
    "        else:\n",
    "            appearances_fourth += 1\n",
    "        # bass\n",
    "        if current_bass != bass:\n",
    "            if appearances_bass <= min_frames:\n",
    "                for j in range(i-appearances_bass, i):\n",
    "                    estimated_bass_list[j] = previous_bass\n",
    "            else:\n",
    "                previous_bass = current_bass\n",
    "            current_bass = bass\n",
    "            appearances_bass = 1\n",
    "        else:\n",
    "            appearances_bass += 1\n",
    "    #update\n",
    "    estimations_root[track_no] = estimated_root_list\n",
    "    estimations_bass[track_no] = estimated_bass_list\n",
    "    estimations_triad[track_no] = estimated_triad_list\n",
    "    estimations_fourth[track_no] = estimated_fourth_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 E E Minor N  |  N\n",
      "1 E E Minor N  |  E:min(2)\n",
      "2 E E Minor N  |  E:min(2)\n",
      "3 E E Minor N  |  E:min(2)\n",
      "4 E E Minor N  |  E:min(2)\n",
      "5 E E Minor N  |  E:min(2)\n",
      "6 E E Minor N  |  E:min(2)\n",
      "7 E E Minor N  |  E:min(2)\n",
      "8 E E Minor N  |  E:min(2)\n",
      "9 E E Minor N  |  E:min(2)\n",
      "10 E E Minor N  |  E:min(2)\n",
      "11 E E Minor N  |  E:min(2)\n",
      "12 E E Minor N  |  E:min(2)\n",
      "13 E E Minor N  |  E:min(2)\n",
      "14 E E Minor N  |  E:min(2)\n",
      "15 E E Minor N  |  E:min(2)\n",
      "16 E E Minor N  |  E:min(2)\n",
      "17 E E Minor N  |  E:min(2)\n",
      "18 E E Minor N  |  E:min(2)\n",
      "19 E E Minor N  |  E:min(2)\n",
      "20 E E Minor N  |  E:min(2)\n",
      "21 E E Minor N  |  E:min(2)\n",
      "22 E E Minor N  |  E:min(2)\n",
      "23 E E Minor N  |  E:min(2)\n",
      "24 E E Minor N  |  E:min(2)\n",
      "25 E E Minor N  |  E:min(2)\n",
      "26 E E Minor N  |  E:min(2)\n",
      "27 E E Minor N  |  E:min(2)\n",
      "28 E E Minor N  |  E:min(2)\n",
      "29 E E Minor N  |  E:min(2)\n",
      "30 E E Minor N  |  E:min(2)\n",
      "31 E E Minor N  |  E:min(2)\n",
      "32 E E Minor N  |  E:min(2)\n",
      "33 E E Minor N  |  E:min(2)\n",
      "34 E E Minor N  |  E:min(2)\n",
      "35 E E Minor N  |  E:min(2)\n",
      "36 E E Minor N  |  E:min(2)\n",
      "37 E E Minor N  |  E:min(2)\n",
      "38 E E Minor N  |  E:min(2)\n",
      "39 E E Minor N  |  E:min(2)\n",
      "40 E E Minor N  |  E:min(2)\n",
      "41 E E Minor N  |  E:min(2)\n",
      "42 E E Minor N  |  E:min(2)\n",
      "43 E E Minor N  |  E:min(2)\n",
      "44 E E Minor N  |  E:min(2)\n",
      "45 E E Minor N  |  E:min(2)\n",
      "46 E E Minor N  |  E:min(2)\n",
      "47 E E Minor N  |  E:min(2)\n",
      "48 E E Minor N  |  E:min(2)\n",
      "49 E E Minor N  |  E:min(2)\n",
      "50 E E Minor N  |  E:min(2)\n",
      "51 E E Minor N  |  E:min(2)\n",
      "52 E E Minor N  |  E:min(2)\n",
      "53 E E Minor N  |  E:min(2)\n",
      "54 E E Minor N  |  E:min(2)\n",
      "55 E E Minor N  |  E:min(2)\n",
      "56 E E Minor N  |  E:min(2)\n",
      "57 E E Minor N  |  E:min(2)\n",
      "58 E E Minor N  |  E:min(2)\n",
      "59 E E Minor N  |  E:min(2)\n",
      "60 E E Minor N  |  E:min(2)\n",
      "61 E E Minor N  |  E:min(2)\n",
      "62 E E Minor N  |  E:min(2)\n",
      "63 E E Minor N  |  E:min(2)\n",
      "64 E E Minor N  |  E:min(2)\n",
      "65 E E Minor N  |  E:min(2)\n",
      "66 E E Minor N  |  E:min(2)\n",
      "67 E E Major N  |  E:min(2)\n",
      "68 E E Major N  |  E:min(2)\n",
      "69 E E Major N  |  E:min(2)\n",
      "70 E E Major N  |  E:min(2)\n",
      "71 E E Major N  |  E:min(2)\n",
      "72 E E Major N  |  E:min(2)\n",
      "73 E E Major N  |  E:min(2)\n",
      "74 E E Major N  |  E:min(2)\n",
      "75 E E Major N  |  E:min(2)\n",
      "76 E E Major N  |  E:min(2)\n",
      "77 E E Minor N  |  E:min(2)\n",
      "78 E E Minor N  |  E:min(2)\n",
      "79 E E Minor N  |  E:min(2)\n",
      "80 E E Minor N  |  E:min(2)\n",
      "81 E E Minor N  |  E:min(2)\n",
      "82 E E Minor N  |  E:min(2)\n",
      "83 E E Minor N  |  E:min(2)\n",
      "84 E E Minor N  |  E:min(2)\n",
      "85 E E Minor N  |  E:min(2)\n",
      "86 E Eb Minor N  |  E:min(2)\n",
      "87 E Eb Minor N  |  E:min(2)\n",
      "88 E Eb Minor N  |  E:min(2)\n",
      "89 E Eb Minor N  |  E:min(2)\n",
      "90 E Eb Minor N  |  E:min(2)\n",
      "91 C E Major N  |  C\n",
      "92 C C Major N  |  C\n",
      "93 C C Major N  |  C\n",
      "94 C C Major N  |  C\n",
      "95 C C Major N  |  C\n",
      "96 C C Major N  |  C\n",
      "97 C C Major N  |  C\n",
      "98 C C Major N  |  C\n",
      "99 C C Major N  |  C\n",
      "100 C C Major N  |  C\n",
      "101 C C Major N  |  C\n",
      "102 C C Major N  |  C\n",
      "103 G G Major N  |  G\n",
      "104 G G Major N  |  G\n",
      "105 G G Major N  |  G\n",
      "106 G G Major N  |  G\n",
      "107 G G Major N  |  G\n",
      "108 G G Major N  |  G\n",
      "109 G G Major N  |  G\n",
      "110 G G Major N  |  G\n",
      "111 G G Major N  |  G\n",
      "112 G G Major N  |  G\n",
      "113 G G Major N  |  G\n",
      "114 C C Major N  |  C\n",
      "115 C C Major N  |  C\n",
      "116 C C Major N  |  C\n",
      "117 C C Major N  |  C\n",
      "118 C C Major N  |  C\n",
      "119 C C Major N  |  C\n",
      "120 C C Major N  |  C\n",
      "121 C C Major N  |  C\n",
      "122 C C Major N  |  C\n",
      "123 C C Major N  |  C\n",
      "124 C C Major N  |  C\n",
      "125 F F Minor N  |  C\n",
      "126 F F Minor N  |  F:min\n",
      "127 F F Minor N  |  F:min\n",
      "128 F F Minor N  |  F:min\n",
      "129 F F Minor N  |  F:min\n",
      "130 F F Minor N  |  F:min\n",
      "131 F F Minor N  |  F:min\n",
      "132 F F Minor N  |  F:min\n",
      "133 F F Minor N  |  F:min\n",
      "134 F F Minor N  |  F:min\n",
      "135 F F Minor N  |  F:min\n",
      "136 C C Major N  |  F:min\n",
      "137 C C Major N  |  C\n",
      "138 C C Major N  |  C\n",
      "139 C C Major N  |  C\n",
      "140 C C Major N  |  C\n",
      "141 C C Major N  |  C\n",
      "142 C C Major N  |  C\n",
      "143 C C Major N  |  C\n",
      "144 C C Major N  |  C\n",
      "145 C C Major N  |  C\n",
      "146 C C Major N  |  C\n",
      "147 F C Major N  |  C\n",
      "148 F F Minor N  |  F:min\n",
      "149 F F Minor N  |  F:min\n",
      "150 F F Minor N  |  F:min\n",
      "151 F F Minor N  |  F:min\n",
      "152 F F Minor N  |  F:min\n",
      "153 F F Minor N  |  F:min\n",
      "154 F F Minor N  |  F:min\n",
      "155 F F Minor N  |  F:min\n",
      "156 F F Minor N  |  F:min\n",
      "157 F F Major N  |  F:min\n",
      "158 G G Major N  |  F:min\n",
      "159 G G Major N  |  G\n",
      "160 G G Major N  |  G\n",
      "161 G G Major N  |  G\n",
      "162 G G Major N  |  G\n",
      "163 G G Major N  |  G\n",
      "164 G G Major N  |  G\n",
      "165 G G Major N  |  G\n",
      "166 G G Major N  |  G\n",
      "167 G G Major N  |  G\n",
      "168 G G Major N  |  G\n",
      "169 G G Major N  |  G\n",
      "170 A A Major N  |  A\n",
      "171 A A Major N  |  A\n",
      "172 A A Major N  |  A\n",
      "173 A A Major N  |  A\n",
      "174 A A Major N  |  A\n",
      "175 A A Major N  |  A\n",
      "176 A A Major N  |  A\n",
      "177 A A Major N  |  A\n",
      "178 A A Major N  |  A\n",
      "179 A A Major N  |  A\n",
      "180 A A Major N  |  A\n",
      "181 E E Major N  |  A\n",
      "182 E E Major N  |  E\n",
      "183 E E Major N  |  E\n",
      "184 E E Major N  |  E\n",
      "185 E E Major N  |  E\n",
      "186 E E Major N  |  E\n",
      "187 E E Major N  |  E\n",
      "188 E E Major N  |  E\n",
      "189 E E Major N  |  E\n",
      "190 E E Major N  |  E\n",
      "191 E E Major N  |  E\n",
      "192 A A Major N  |  E\n",
      "193 A A Major N  |  A\n",
      "194 A A Major N  |  A\n",
      "195 A A Major N  |  A\n",
      "196 A A Major N  |  A\n",
      "197 A A Major N  |  A\n",
      "198 A A Major N  |  A\n",
      "199 A A Major N  |  A\n",
      "200 A A Major N  |  A\n",
      "201 A A Major N  |  A\n",
      "202 A A Major N  |  A\n",
      "203 A A Major N  |  A\n",
      "204 D D Minor N  |  D:min\n",
      "205 D D Minor N  |  D:min\n",
      "206 D D Minor N  |  D:min\n",
      "207 D D Minor N  |  D:min\n",
      "208 D D Minor N  |  D:min\n",
      "209 D D Minor N  |  D:min\n",
      "210 D D Minor N  |  D:min\n",
      "211 D D Minor N  |  D:min\n",
      "212 D D Minor N  |  D:min\n",
      "213 D D Minor N  |  D:min\n",
      "214 D D Minor N  |  D:min\n",
      "215 A A Major N  |  A\n",
      "216 A A Major N  |  A\n",
      "217 A A Major N  |  A\n",
      "218 A A Major N  |  A\n",
      "219 A A Major N  |  A\n",
      "220 A A Major N  |  A\n",
      "221 A A Major N  |  A\n",
      "222 A A Major N  |  A\n",
      "223 A A Major N  |  A\n",
      "224 A A Major N  |  A\n",
      "225 A A Major N  |  A\n",
      "226 D D Minor N  |  D:min\n",
      "227 D D Minor N  |  D:min\n",
      "228 D D Minor N  |  D:min\n",
      "229 D D Minor N  |  D:min\n",
      "230 D D Minor N  |  D:min\n",
      "231 D D Minor N  |  D:min\n",
      "232 D D Minor N  |  D:min\n",
      "233 D D Minor N  |  D:min\n",
      "234 D D Minor N  |  D:min\n",
      "235 D D Minor N  |  D:min\n",
      "236 D D Minor N  |  D:min\n",
      "237 E E Major N  |  E\n",
      "238 E E Major N  |  E\n",
      "239 E E Major N  |  E\n",
      "240 E E Major N  |  E\n",
      "241 E E Major N  |  E\n",
      "242 E E Major N  |  E\n",
      "243 E E Major N  |  E\n",
      "244 E E Major N  |  E\n",
      "245 E E Major N  |  E\n",
      "246 E E Major N  |  E\n",
      "247 E E Major N  |  E\n",
      "248 E E Major N  |  E\n",
      "249 E E Major N  |  E\n",
      "250 E E Major N  |  E\n",
      "251 E E Major N  |  E\n",
      "252 E E Major N  |  E\n",
      "253 E E Major N  |  E\n",
      "254 E E Major N  |  E\n",
      "255 E E Major N  |  E\n",
      "256 E E Major N  |  E\n",
      "257 E E Major N  |  E\n",
      "258 E E Major N  |  E\n",
      "259 E E Major N  |  E\n",
      "260 A A Minor N  |  E\n",
      "261 A A Minor N  |  A:min\n",
      "262 A A Minor N  |  A:min\n",
      "263 A A Minor N  |  A:min\n",
      "264 A A Minor N  |  A:min\n",
      "265 A A Minor N  |  A:min\n",
      "266 A A Minor N  |  A:min\n",
      "267 A A Minor N  |  A:min\n",
      "268 A A Minor N  |  A:min\n",
      "269 A A Minor N  |  A:min\n",
      "270 A A Minor N  |  A:min\n",
      "271 A A Minor N  |  A:min\n",
      "272 A A Minor N  |  A:min\n",
      "273 A A Minor N  |  A:min\n",
      "274 A A Minor N  |  A:min\n",
      "275 A A Minor N  |  A:min\n",
      "276 A A Minor N  |  A:min\n",
      "277 A A Minor N  |  A:min\n",
      "278 C C Major N  |  C\n",
      "279 C C Major N  |  C\n",
      "280 C C Major N  |  C\n",
      "281 C C Major N  |  C\n",
      "282 C C Major N  |  C\n",
      "283 C C Major N  |  C\n",
      "284 C C Major N  |  C\n",
      "285 C C Major N  |  C\n",
      "286 C C Major N  |  C\n",
      "287 C C Major N  |  C\n",
      "288 C C Major N  |  C\n",
      "289 C C Major N  |  C\n",
      "290 C C Major N  |  C\n",
      "291 C C Major N  |  C\n",
      "292 C C Major N  |  C\n",
      "293 C C Major N  |  C\n",
      "294 C C Major N  |  C\n",
      "295 C C Major N  |  C\n",
      "296 F F Major N  |  F\n",
      "297 F F Major N  |  F\n",
      "298 F F Major N  |  F\n",
      "299 F F Major N  |  F\n",
      "300 F F Major N  |  F\n",
      "301 F F Major N  |  F\n",
      "302 F F Major N  |  F\n",
      "303 F F Major N  |  F\n",
      "304 F F Major N  |  F\n",
      "305 F F Major N  |  F\n",
      "306 F F Major N  |  F\n",
      "307 F F Major N  |  F\n",
      "308 F F Major N  |  F\n",
      "309 F F Major N  |  F\n",
      "310 F F Major N  |  F\n",
      "311 F F Major N  |  F\n",
      "312 F F Major N  |  F\n",
      "313 F F Major N  |  F\n",
      "314 F F Major N  |  F\n",
      "315 F F Major N  |  F\n",
      "316 F F Major N  |  F\n",
      "317 F F Major N  |  F\n",
      "318 F F Major N  |  F\n",
      "319 F F Major N  |  F\n",
      "320 F F Major N  |  F\n",
      "321 F F Major N  |  F\n",
      "322 G G Major N  |  G\n",
      "323 G G Major N  |  G\n",
      "324 G G Major N  |  G\n",
      "325 G G Major N  |  G\n",
      "326 G G Major N  |  G\n",
      "327 G G Major N  |  G\n",
      "328 G G Major N  |  G\n",
      "329 G G Major N  |  G\n",
      "330 A A Major N  |  G\n",
      "331 A A Minor N  |  A:min\n",
      "332 A A Minor N  |  A:min\n",
      "333 A A Minor N  |  A:min\n",
      "334 A A Minor N  |  A:min\n",
      "335 A A Minor N  |  A:min\n",
      "336 A A Minor N  |  A:min\n",
      "337 A A Minor N  |  A:min\n",
      "338 A A Minor N  |  A:min\n",
      "339 A A Minor N  |  A:min\n",
      "340 A A Minor N  |  A:min\n",
      "341 A A Minor N  |  A:min\n",
      "342 A A Minor N  |  A:min\n",
      "343 A A Minor N  |  A:min\n",
      "344 A A Minor N  |  A:min\n",
      "345 A A Minor N  |  A:min\n",
      "346 A A Minor N  |  A:min\n",
      "347 A A Minor N  |  A:min\n",
      "348 C C Major N  |  C\n",
      "349 C C Major N  |  C\n",
      "350 C C Major N  |  C\n",
      "351 C C Major N  |  C\n",
      "352 C C Major N  |  C\n",
      "353 C C Major N  |  C\n",
      "354 C C Major N  |  C\n",
      "355 C C Major N  |  C\n",
      "356 C C Major N  |  C\n",
      "357 C C Major N  |  C\n",
      "358 C C Major N  |  C\n",
      "359 C C Major N  |  C\n",
      "360 C C Major N  |  C\n",
      "361 C C Major N  |  C\n",
      "362 C C Major N  |  C\n",
      "363 C C Major N  |  C\n",
      "364 C C Major N  |  C\n",
      "365 C C Major N  |  C\n",
      "366 F F Major N  |  F\n",
      "367 F F Major N  |  F\n",
      "368 F F Major N  |  F\n",
      "369 F F Major N  |  F\n",
      "370 F F Major N  |  F\n",
      "371 F F Major N  |  F\n",
      "372 F F Major N  |  F\n",
      "373 F F Major N  |  F\n",
      "374 F F Major N  |  F\n",
      "375 F F Major N  |  F\n",
      "376 F F Major N  |  F\n",
      "377 F F Major N  |  F\n",
      "378 F F Major N  |  F\n",
      "379 F F Major N  |  F\n",
      "380 F F Major N  |  F\n",
      "381 F F Major N  |  F\n",
      "382 F F Major N  |  F\n",
      "383 F F Major N  |  F\n",
      "384 F F Major N  |  F\n",
      "385 F F Major N  |  F\n",
      "386 F F Major N  |  F\n",
      "387 F F Major N  |  F\n",
      "388 F F Major N  |  F\n",
      "389 F F Major N  |  F\n",
      "390 F F Major N  |  F\n",
      "391 G G Major N  |  F\n",
      "392 G G Major N  |  G\n",
      "393 G G Major N  |  G\n",
      "394 G G Major N  |  G\n",
      "395 G G Major N  |  G\n",
      "396 G G Major N  |  G\n",
      "397 G G Major N  |  G\n",
      "398 G G Major N  |  G\n",
      "399 G G Major N  |  G\n",
      "400 E E Major N  |  G\n",
      "401 E E Major N  |  E\n",
      "402 E E Major N  |  E\n",
      "403 E E Major N  |  E\n",
      "404 E E Major N  |  E\n",
      "405 E E Major N  |  E\n",
      "406 E E Major N  |  E\n",
      "407 E E Major N  |  E\n",
      "408 E E Major N  |  E\n",
      "409 E E Major N  |  E\n",
      "410 E E Major N  |  E\n",
      "411 E E Major N  |  E\n",
      "412 E E Major N  |  E\n",
      "413 E E Major N  |  E\n",
      "414 E E Major N  |  E\n",
      "415 E E Major N  |  E\n",
      "416 E E Major N  |  E\n",
      "417 E E Major N  |  E\n",
      "418 G G Major N  |  G\n",
      "419 G G Major N  |  G\n",
      "420 G G Major N  |  G\n",
      "421 G G Major N  |  G\n",
      "422 G G Major N  |  G\n",
      "423 G G Major N  |  G\n",
      "424 G G Major N  |  G\n",
      "425 G G Major N  |  G\n",
      "426 G G Major N  |  G\n",
      "427 G G Major N  |  G\n",
      "428 G G Major N  |  G\n",
      "429 G G Major N  |  G\n",
      "430 G G Major N  |  G\n",
      "431 G G Major N  |  G\n",
      "432 G G Major N  |  G\n",
      "433 G G Major N  |  G\n",
      "434 G G Major N  |  G\n",
      "435 A A Minor N  |  A:min\n",
      "436 A A Minor N  |  A:min\n",
      "437 A A Minor N  |  A:min\n",
      "438 A A Minor N  |  A:min\n",
      "439 A A Minor N  |  A:min\n",
      "440 A A Minor N  |  A:min\n",
      "441 A A Minor N  |  A:min\n",
      "442 A A Minor N  |  A:min\n",
      "443 A A Minor N  |  A:min\n",
      "444 A A Minor N  |  A:min\n",
      "445 A C Minor N  |  A:min\n",
      "446 A C Minor N  |  A:min\n",
      "447 A C Minor N  |  A:min\n",
      "448 A C Minor N  |  A:min\n",
      "449 A C Minor N  |  A:min\n",
      "450 A C Minor N  |  A:min\n",
      "451 A C Minor N  |  A:min\n",
      "452 A A Minor N  |  A:min\n",
      "453 F F Minor N  |  F:min\n",
      "454 F F Minor N  |  F:min\n",
      "455 F F Minor N  |  F:min\n",
      "456 F F Minor N  |  F:min\n",
      "457 F F Minor N  |  F:min\n",
      "458 F F Minor N  |  F:min\n",
      "459 F F Minor N  |  F:min\n",
      "460 F F Minor N  |  F:min\n",
      "461 F F Minor N  |  F:min\n",
      "462 F F Minor N  |  F:min\n",
      "463 F F Minor N  |  F:min\n",
      "464 F F Minor N  |  F:min\n",
      "465 F F Minor N  |  F:min\n",
      "466 F F Minor N  |  F:min\n",
      "467 F F Minor N  |  F:min\n",
      "468 F F Minor N  |  F:min\n",
      "469 F F Minor N  |  F:min\n",
      "470 F F Minor N  |  F:min\n",
      "471 F F Minor N  |  F:min\n",
      "472 F F Minor N  |  F:min\n",
      "473 F F Minor N  |  F:min\n",
      "474 F F Minor N  |  F:min\n",
      "475 F F Minor N  |  F:min\n",
      "476 F F Minor N  |  F:min\n",
      "477 F F Minor N  |  F:min\n",
      "478 F F Minor N  |  F:min\n",
      "479 F F Minor N  |  F:min\n",
      "480 F F Minor N  |  F:min\n",
      "481 F F Minor N  |  F:min\n",
      "482 F F Minor N  |  F:min\n",
      "483 F F Minor N  |  F:min\n",
      "484 F N N N  |  F:min\n",
      "485 N N N N  |  N\n",
      "486 N N N N  |  N\n",
      "487 N N N N  |  N\n",
      "488 N N N N  |  N\n",
      "489 N N N N  |  N\n",
      "490 N N N N  |  N\n",
      "491 N N N N  |  N\n",
      "492 N N N N  |  N\n",
      "493 N N N N  |  N\n",
      "494 N N N N  |  N\n",
      "495 N N N N  |  N\n",
      "496 C C Major N  |  C\n",
      "497 C C Major N  |  C\n",
      "498 C C Major N  |  C\n",
      "499 C C Major N  |  C\n",
      "500 C C Major N  |  C\n",
      "501 C C Major N  |  C\n",
      "502 C C Major N  |  C\n",
      "503 C C Major N  |  C\n",
      "504 C C Major N  |  C\n",
      "505 C C Major N  |  C\n",
      "506 C C Major N  |  C\n",
      "507 G G Major N  |  G\n",
      "508 G G Major N  |  G\n",
      "509 G G Major N  |  G\n",
      "510 G G Major N  |  G\n",
      "511 G G Major N  |  G\n",
      "512 G G Major N  |  G\n",
      "513 G G Major N  |  G\n",
      "514 G G Major N  |  G\n",
      "515 G G Major N  |  G\n",
      "516 G G Major N  |  G\n",
      "517 G G Major N  |  G\n",
      "518 C C Major N  |  G\n",
      "519 C C Major N  |  C\n",
      "520 C C Major N  |  C\n",
      "521 C C Major N  |  C\n",
      "522 C C Major N  |  C\n",
      "523 C C Major N  |  C\n",
      "524 C C Major N  |  C\n",
      "525 C C Major N  |  C\n",
      "526 C C Major N  |  C\n",
      "527 C C Major N  |  C\n",
      "528 C C Major N  |  C\n",
      "529 C C Major N  |  C\n",
      "530 F F Major N  |  F:min\n",
      "531 F F Major N  |  F:min\n",
      "532 F F Minor N  |  F:min\n",
      "533 F F Minor N  |  F:min\n",
      "534 F F Minor N  |  F:min\n",
      "535 F F Minor N  |  F:min\n",
      "536 F F Minor N  |  F:min\n",
      "537 F F Minor N  |  F:min\n",
      "538 F F Minor N  |  F:min\n",
      "539 F F Minor N  |  F:min\n",
      "540 F F Minor N  |  F:min\n",
      "541 C C Major N  |  C\n",
      "542 C C Major N  |  C\n",
      "543 C C Major N  |  C\n",
      "544 C C Major N  |  C\n",
      "545 C C Major N  |  C\n",
      "546 C C Major N  |  C\n",
      "547 C C Major N  |  C\n",
      "548 C C Major N  |  C\n",
      "549 C C Major N  |  C\n",
      "550 C C Major N  |  C\n",
      "551 C C Major N  |  C\n",
      "552 F F Minor N  |  C\n",
      "553 F F Minor N  |  F:min\n",
      "554 F F Minor N  |  F:min\n",
      "555 F F Minor N  |  F:min\n",
      "556 F F Minor N  |  F:min\n",
      "557 F F Minor N  |  F:min\n",
      "558 F F Minor N  |  F:min\n",
      "559 F F Minor N  |  F:min\n",
      "560 F F Minor N  |  F:min\n",
      "561 F F Minor N  |  F:min\n",
      "562 F F Minor N  |  F:min\n",
      "563 G G Major N  |  F:min\n",
      "564 G G Major N  |  G\n",
      "565 G G Major N  |  G\n",
      "566 G G Major N  |  G\n",
      "567 G G Major N  |  G\n",
      "568 G G Major N  |  G\n",
      "569 G G Major N  |  G\n",
      "570 G G Major N  |  G\n",
      "571 G G Major N  |  G\n",
      "572 G G Major N  |  G\n",
      "573 G G Major N  |  G\n",
      "574 G G Major N  |  G\n",
      "575 A A Major N  |  A\n",
      "576 A A Major N  |  A\n",
      "577 A A Major N  |  A\n",
      "578 A A Major N  |  A\n",
      "579 A A Major N  |  A\n",
      "580 A A Major N  |  A\n",
      "581 A A Major N  |  A\n",
      "582 A A Major N  |  A\n",
      "583 A A Major N  |  A\n",
      "584 A A Major N  |  A\n",
      "585 A A Major N  |  A\n",
      "586 E E Major N  |  E\n",
      "587 E E Major N  |  E\n",
      "588 E E Major N  |  E\n",
      "589 E E Major N  |  E\n",
      "590 E E Major N  |  E\n",
      "591 E E Major N  |  E\n",
      "592 E E Major N  |  E\n",
      "593 E E Major N  |  E\n",
      "594 E E Major N  |  E\n",
      "595 E E Major N  |  E\n",
      "596 E E Major N  |  E\n",
      "597 A A Major N  |  E\n",
      "598 A A Major N  |  A\n",
      "599 A A Major N  |  A\n",
      "600 A A Major N  |  A\n",
      "601 A A Major N  |  A\n",
      "602 A A Major N  |  A\n",
      "603 A A Major N  |  A\n",
      "604 A A Major N  |  A\n",
      "605 A A Major N  |  A\n",
      "606 A A Major N  |  A\n",
      "607 A A Major N  |  A\n",
      "608 D D Major N  |  A\n",
      "609 D D Minor N  |  D:min\n",
      "610 D D Minor N  |  D:min\n",
      "611 D D Minor N  |  D:min\n",
      "612 D D Minor N  |  D:min\n",
      "613 D D Minor N  |  D:min\n",
      "614 D D Minor N  |  D:min\n",
      "615 D D Minor N  |  D:min\n",
      "616 D D Minor N  |  D:min\n",
      "617 D D Minor N  |  D:min\n",
      "618 D D Minor N  |  D:min\n",
      "619 D D Major N  |  D:min\n",
      "620 A A Major N  |  A\n",
      "621 A A Major N  |  A\n",
      "622 A A Major N  |  A\n",
      "623 A A Major N  |  A\n",
      "624 A A Major N  |  A\n",
      "625 A A Major N  |  A\n",
      "626 A A Major N  |  A\n",
      "627 A A Major N  |  A\n",
      "628 A A Major N  |  A\n",
      "629 A A Major N  |  A\n",
      "630 A A Major N  |  A\n",
      "631 D D Minor N  |  D:min\n",
      "632 D D Minor N  |  D:min\n",
      "633 D D Minor N  |  D:min\n",
      "634 D D Minor N  |  D:min\n",
      "635 D D Minor N  |  D:min\n",
      "636 D D Minor N  |  D:min\n",
      "637 D D Minor N  |  D:min\n",
      "638 D D Minor N  |  D:min\n",
      "639 D D Minor N  |  D:min\n",
      "640 D D Minor N  |  D:min\n",
      "641 D D Minor N  |  D:min\n",
      "642 E E Major N  |  D:min\n",
      "643 E E Major N  |  E\n",
      "644 E E Major N  |  E\n",
      "645 E E Major N  |  E\n",
      "646 E E Major N  |  E\n",
      "647 E E Major N  |  E\n",
      "648 E E Major N  |  E\n",
      "649 E E Major N  |  E\n",
      "650 E E Major N  |  E\n",
      "651 E E Major N  |  E\n",
      "652 E E Major N  |  E\n",
      "653 E E Major N  |  E\n",
      "654 E E Major N  |  E\n",
      "655 E E Major N  |  E\n",
      "656 E E Major N  |  E\n",
      "657 E E Major N  |  E\n",
      "658 E E Major N  |  E\n",
      "659 E E Major N  |  E\n",
      "660 E E Major N  |  E\n",
      "661 E E Major N  |  E\n",
      "662 E E Major N  |  E\n",
      "663 E E Major N  |  E\n",
      "664 E E Major N  |  E\n",
      "665 A A Minor N  |  A:min\n",
      "666 A A Minor N  |  A:min\n",
      "667 A A Minor N  |  A:min\n",
      "668 A A Minor N  |  A:min\n",
      "669 A A Minor N  |  A:min\n",
      "670 A A Minor N  |  A:min\n",
      "671 A A Minor N  |  A:min\n",
      "672 A A Minor N  |  A:min\n",
      "673 A A Minor N  |  A:min\n",
      "674 A A Minor N  |  A:min\n",
      "675 A A Minor N  |  A:min\n",
      "676 A A Minor N  |  A:min\n",
      "677 A A Minor N  |  A:min\n",
      "678 A A Minor N  |  A:min\n",
      "679 A A Minor N  |  A:min\n",
      "680 A A Minor N  |  A:min\n",
      "681 A A Minor N  |  A:min\n",
      "682 A A Minor N  |  A:min\n",
      "683 C C Major N  |  A:min\n",
      "684 C C Major N  |  C\n",
      "685 C C Major N  |  C\n",
      "686 C C Major N  |  C\n",
      "687 C C Major N  |  C\n",
      "688 C C Major N  |  C\n",
      "689 C C Major N  |  C\n",
      "690 C C Major N  |  C\n",
      "691 C C Major N  |  C\n",
      "692 C C Major N  |  C\n",
      "693 C C Major N  |  C\n",
      "694 C C Major N  |  C\n",
      "695 C C Major N  |  C\n",
      "696 C C Major N  |  C\n",
      "697 C C Major N  |  C\n",
      "698 C C Major N  |  C\n",
      "699 C C Major N  |  C\n",
      "700 C C Major N  |  C\n",
      "701 F F Major N  |  C\n",
      "702 F F Major N  |  F\n",
      "703 F F Major N  |  F\n",
      "704 F F Major N  |  F\n",
      "705 F F Major N  |  F\n",
      "706 F F Major N  |  F\n",
      "707 F F Major N  |  F\n",
      "708 F F Major N  |  F\n",
      "709 F F Major N  |  F\n",
      "710 F F Major N  |  F\n",
      "711 F F Major N  |  F\n",
      "712 F F Major N  |  F\n",
      "713 F F Major N  |  F\n",
      "714 F F Major N  |  F\n",
      "715 F F Major N  |  F\n",
      "716 F F Major N  |  F\n",
      "717 F F Major N  |  F\n",
      "718 F F Major N  |  F\n",
      "719 F F Major N  |  F\n",
      "720 F F Major N  |  F\n",
      "721 F F Major N  |  F\n",
      "722 F F Major N  |  F\n",
      "723 F F Major N  |  F\n",
      "724 F F Major N  |  F\n",
      "725 F F Major N  |  F\n",
      "726 F F Major N  |  F\n",
      "727 G G Major N  |  F\n",
      "728 G G Major N  |  G\n",
      "729 G G Major N  |  G\n",
      "730 G G Major N  |  G\n",
      "731 G G Major N  |  G\n",
      "732 G G Major N  |  G\n",
      "733 G G Major N  |  G\n",
      "734 G G Major N  |  G\n",
      "735 G G Major N  |  G\n",
      "736 A A Minor N  |  A:min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "737 A A Minor N  |  A:min\n",
      "738 A A Minor N  |  A:min\n",
      "739 A A Minor N  |  A:min\n",
      "740 A A Minor N  |  A:min\n",
      "741 A A Minor N  |  A:min\n",
      "742 A A Minor N  |  A:min\n",
      "743 A A Minor N  |  A:min\n",
      "744 A A Minor N  |  A:min\n",
      "745 A A Minor N  |  A:min\n",
      "746 A A Minor N  |  A:min\n",
      "747 A A Minor N  |  A:min\n",
      "748 A A Minor N  |  A:min\n",
      "749 A A Minor N  |  A:min\n",
      "750 A A Minor N  |  A:min\n",
      "751 A A Minor N  |  A:min\n",
      "752 A A Minor N  |  A:min\n",
      "753 A C Minor N  |  A:min\n",
      "754 C C Major N  |  C\n",
      "755 C C Major N  |  C\n",
      "756 C C Major N  |  C\n",
      "757 C C Major N  |  C\n",
      "758 C C Major N  |  C\n",
      "759 C C Major N  |  C\n",
      "760 C C Major N  |  C\n",
      "761 C C Major N  |  C\n",
      "762 C C Major N  |  C\n",
      "763 C C Major N  |  C\n",
      "764 C C Major N  |  C\n",
      "765 C C Major N  |  C\n",
      "766 C C Major N  |  C\n",
      "767 C C Major N  |  C\n",
      "768 C C Major N  |  C\n",
      "769 C C Major N  |  C\n",
      "770 C C Major N  |  C\n",
      "771 F F Major N  |  F\n",
      "772 F F Major N  |  F\n",
      "773 F F Major N  |  F\n",
      "774 F F Major N  |  F\n",
      "775 F F Major N  |  F\n",
      "776 F F Major N  |  F\n",
      "777 F F Major N  |  F\n",
      "778 F F Major N  |  F\n",
      "779 F F Major N  |  F\n",
      "780 F F Major N  |  F\n",
      "781 F F Major N  |  F\n",
      "782 F F Major N  |  F\n",
      "783 F F Major N  |  F\n",
      "784 F F Major N  |  F\n",
      "785 F F Major N  |  F\n",
      "786 F F Major N  |  F\n",
      "787 F F Major N  |  F\n",
      "788 F F Major N  |  F\n",
      "789 F F Major N  |  F\n",
      "790 F F Major N  |  F\n",
      "791 F F Major N  |  F\n",
      "792 F F Major N  |  F\n",
      "793 F F Major N  |  F\n",
      "794 F F Major N  |  F\n",
      "795 F F Major N  |  F\n",
      "796 F F Major N  |  F\n",
      "797 F F Major N  |  F\n",
      "798 G G Major N  |  G\n",
      "799 G G Major N  |  G\n",
      "800 G G Major N  |  G\n",
      "801 G G Major N  |  G\n",
      "802 G G Major N  |  G\n",
      "803 G G Major N  |  G\n",
      "804 G G Major N  |  G\n",
      "805 G G Major N  |  G\n",
      "806 E E Major N  |  G\n",
      "807 E E Major N  |  E\n",
      "808 E E Major N  |  E\n",
      "809 E E Major N  |  E\n",
      "810 E E Major N  |  E\n",
      "811 E E Major N  |  E\n",
      "812 E E Major N  |  E\n",
      "813 E E Major N  |  E\n",
      "814 E E Major N  |  E\n",
      "815 E E Major N  |  E\n",
      "816 E E Major N  |  E\n",
      "817 E E Major N  |  E\n",
      "818 E E Major N  |  E\n",
      "819 E E Major N  |  E\n",
      "820 E E Major N  |  E\n",
      "821 E E Major N  |  E\n",
      "822 E E Major N  |  E\n",
      "823 E E Major N  |  E\n",
      "824 G G Major N  |  E\n",
      "825 G G Major N  |  G\n",
      "826 G G Major N  |  G\n",
      "827 G G Major N  |  G\n",
      "828 G G Major N  |  G\n",
      "829 G G Major N  |  G\n",
      "830 G G Major N  |  G\n",
      "831 G G Major N  |  G\n",
      "832 G G Major N  |  G\n",
      "833 G G Major N  |  G\n",
      "834 G G Major N  |  G\n",
      "835 G G Major N  |  G\n",
      "836 G G Major N  |  G\n",
      "837 G G Major N  |  G\n",
      "838 G G Major N  |  G\n",
      "839 G G Major N  |  G\n",
      "840 G G Major N  |  G\n",
      "841 A A Minor N  |  G\n",
      "842 A A Minor N  |  A:min\n",
      "843 A A Minor N  |  A:min\n",
      "844 A A Minor N  |  A:min\n",
      "845 A A Minor N  |  A:min\n",
      "846 A A Minor N  |  A:min\n",
      "847 A A Minor N  |  A:min\n",
      "848 A A Minor N  |  A:min\n",
      "849 A A Minor N  |  A:min\n",
      "850 A C Minor N  |  A:min\n",
      "851 A C Minor N  |  A:min\n",
      "852 A C Minor N  |  A:min\n",
      "853 A C Minor N  |  A:min\n",
      "854 A C Minor N  |  A:min\n",
      "855 F C Minor N  |  A:min\n",
      "856 F C Minor N  |  A:min\n",
      "857 F C Minor N  |  A:min\n",
      "858 F C Minor N  |  A:min\n",
      "859 F F Minor N  |  F:min\n",
      "860 F F Minor N  |  F:min\n",
      "861 F F Minor N  |  F:min\n",
      "862 F F Minor N  |  F:min\n",
      "863 F F Minor N  |  F:min\n",
      "864 F F Minor N  |  F:min\n",
      "865 F F Minor N  |  F:min\n",
      "866 F F Minor N  |  F:min\n",
      "867 F F Minor N  |  F:min\n",
      "868 F F Minor N  |  F:min\n",
      "869 F F Minor N  |  F:min\n",
      "870 F F Minor N  |  F:min\n",
      "871 F F Minor N  |  F:min\n",
      "872 F F Minor N  |  F:min\n",
      "873 F F Minor N  |  F:min\n",
      "874 F F Minor N  |  F:min\n",
      "875 F F Minor N  |  F:min\n",
      "876 F F Minor N  |  F:min\n",
      "877 F F Minor N  |  F:min\n",
      "878 F F Minor N  |  F:min\n",
      "879 F F Minor N  |  F:min\n",
      "880 F F Minor N  |  F:min\n",
      "881 F F Minor N  |  F:min\n",
      "882 F F Minor N  |  F:min\n",
      "883 F F Minor N  |  F:min\n",
      "884 F F Minor N  |  F:min\n",
      "885 F F Minor N  |  F:min\n",
      "886 F F Minor N  |  F:min\n",
      "887 F F Minor N  |  F:min\n",
      "888 F F N N  |  F:min\n",
      "889 N F N N  |  F:min\n",
      "890 N N N N  |  F:min\n",
      "891 N N N N  |  F:min\n",
      "892 N N N N  |  F:min\n",
      "893 N N N N  |  F:min\n",
      "894 N N N N  |  N\n",
      "895 N N N N  |  N\n",
      "896 N N N N  |  N\n",
      "897 N N N N  |  N\n",
      "898 N N N N  |  N\n",
      "899 N N N N  |  N\n",
      "900 N N N N  |  N\n",
      "901 N N N N  |  N\n",
      "902 N N N N  |  N\n",
      "903 N N N N  |  N\n",
      "904 N N N N  |  N\n",
      "905 C C Major N  |  C\n",
      "906 C C Major N  |  C\n",
      "907 C C Major N  |  C\n",
      "908 C C Major N  |  C\n",
      "909 C C Major N  |  C\n",
      "910 C C Major N  |  C\n",
      "911 C C Major N  |  C\n",
      "912 C C Major N  |  C\n",
      "913 C C Major N  |  C\n",
      "914 C C Major N  |  C\n",
      "915 C C Major N  |  C\n",
      "916 G G Major N  |  G\n",
      "917 G G Major N  |  G\n",
      "918 G G Major N  |  G\n",
      "919 G G Major N  |  G\n",
      "920 G G Major N  |  G\n",
      "921 G G Major N  |  G\n",
      "922 G G Major N  |  G\n",
      "923 G G Major N  |  G\n",
      "924 G G Major N  |  G\n",
      "925 G G Major N  |  G\n",
      "926 G G Major N  |  G\n",
      "927 C C Major N  |  C\n",
      "928 C C Major N  |  C\n",
      "929 C C Major N  |  C\n",
      "930 C C Major N  |  C\n",
      "931 C C Major N  |  C\n",
      "932 C C Major N  |  C\n",
      "933 C C Major N  |  C\n",
      "934 C C Major N  |  C\n",
      "935 C C Major N  |  C\n",
      "936 C C Major N  |  C\n",
      "937 C C Major N  |  C\n",
      "938 C C Major N  |  C\n",
      "939 F F Major N  |  F:min\n",
      "940 F F Major N  |  F:min\n",
      "941 F F Major N  |  F:min\n",
      "942 F F Minor N  |  F:min\n",
      "943 F F Minor N  |  F:min\n",
      "944 F F Minor N  |  F:min\n",
      "945 F F Minor N  |  F:min\n",
      "946 F F Minor N  |  F:min\n",
      "947 F F Minor N  |  F:min\n",
      "948 F F Minor N  |  F:min\n",
      "949 F F Major N  |  F:min\n",
      "950 C C Major N  |  C\n",
      "951 C C Major N  |  C\n",
      "952 C C Major N  |  C\n",
      "953 C C Major N  |  C\n",
      "954 C C Major N  |  C\n",
      "955 C C Major N  |  C\n",
      "956 C C Major N  |  C\n",
      "957 C C Major N  |  C\n",
      "958 C C Major N  |  C\n",
      "959 C C Major N  |  C\n",
      "960 C C Major N  |  C\n",
      "961 F F Minor N  |  C\n",
      "962 F F Minor N  |  F:min\n",
      "963 F F Minor N  |  F:min\n",
      "964 F F Minor N  |  F:min\n",
      "965 F F Minor N  |  F:min\n",
      "966 F F Minor N  |  F:min\n",
      "967 F F Minor N  |  F:min\n",
      "968 F F Minor N  |  F:min\n",
      "969 F F Minor N  |  F:min\n",
      "970 F F Minor N  |  F:min\n",
      "971 F F Major N  |  F:min\n",
      "972 G G Major N  |  F:min\n",
      "973 G G Major N  |  G\n",
      "974 G G Major N  |  G\n",
      "975 G G Major N  |  G\n",
      "976 G G Major N  |  G\n",
      "977 G G Major N  |  G\n",
      "978 G G Major N  |  G\n",
      "979 G G Major N  |  G\n",
      "980 G G Major N  |  G\n",
      "981 G G Major N  |  G\n",
      "982 G G Major N  |  G\n",
      "983 A A Major N  |  G\n",
      "984 A A Major N  |  A\n",
      "985 A A Major N  |  A\n",
      "986 A A Major N  |  A\n",
      "987 A A Major N  |  A\n",
      "988 A A Major N  |  A\n",
      "989 A A Major N  |  A\n",
      "990 A A Major N  |  A\n",
      "991 A A Major N  |  A\n",
      "992 A A Major N  |  A\n",
      "993 A A Major N  |  A\n",
      "994 A A Major N  |  A\n",
      "995 E E Major N  |  E\n",
      "996 E E Major N  |  E\n",
      "997 E E Major N  |  E\n",
      "998 E E Major N  |  E\n",
      "999 E E Major N  |  E\n",
      "1000 E E Major N  |  E\n",
      "1001 E E Major N  |  E\n",
      "1002 E E Major N  |  E\n",
      "1003 E E Major N  |  E\n",
      "1004 E E Major N  |  E\n",
      "1005 E E Major N  |  E\n",
      "1006 A A Major N  |  E\n",
      "1007 A A Major N  |  A\n",
      "1008 A A Major N  |  A\n",
      "1009 A A Major N  |  A\n",
      "1010 A A Major N  |  A\n",
      "1011 A A Major N  |  A\n",
      "1012 A A Major N  |  A\n",
      "1013 A A Major N  |  A\n",
      "1014 A A Major N  |  A\n",
      "1015 A A Major N  |  A\n",
      "1016 A A Major N  |  A\n",
      "1017 D D Minor N  |  A\n",
      "1018 D D Minor N  |  D:min\n",
      "1019 D D Minor N  |  D:min\n",
      "1020 D D Minor N  |  D:min\n",
      "1021 D D Minor N  |  D:min\n",
      "1022 D D Minor N  |  D:min\n",
      "1023 D D Minor N  |  D:min\n",
      "1024 D D Minor N  |  D:min\n",
      "1025 D D Minor N  |  D:min\n",
      "1026 D D Minor N  |  D:min\n",
      "1027 D D Minor N  |  D:min\n",
      "1028 D D Minor N  |  D:min\n",
      "1029 A A Major N  |  A\n",
      "1030 A A Major N  |  A\n",
      "1031 A A Major N  |  A\n",
      "1032 A A Major N  |  A\n",
      "1033 A A Major N  |  A\n",
      "1034 A A Major N  |  A\n",
      "1035 A A Major N  |  A\n",
      "1036 A A Major N  |  A\n",
      "1037 A A Major N  |  A\n",
      "1038 A A Major N  |  A\n",
      "1039 A A Major N  |  A\n",
      "1040 D D Minor N  |  D:min\n",
      "1041 D D Minor N  |  D:min\n",
      "1042 D D Minor N  |  D:min\n",
      "1043 D D Minor N  |  D:min\n",
      "1044 D D Minor N  |  D:min\n",
      "1045 D D Minor N  |  D:min\n",
      "1046 D D Minor N  |  D:min\n",
      "1047 D D Minor N  |  D:min\n",
      "1048 D D Minor N  |  D:min\n",
      "1049 D D Minor N  |  D:min\n",
      "1050 D D Minor N  |  D:min\n",
      "1051 E E Major N  |  D:min\n",
      "1052 E E Major N  |  E\n",
      "1053 E E Major N  |  E\n",
      "1054 E E Major N  |  E\n",
      "1055 E E Major N  |  E\n",
      "1056 E E Major N  |  E\n",
      "1057 E E Major N  |  E/b7\n",
      "1058 E E Major N  |  E/b7\n",
      "1059 E E Major N  |  E/b7\n",
      "1060 E E Major N  |  E/b7\n",
      "1061 E E Major N  |  E/b7\n",
      "1062 E E Major N  |  E/b7\n",
      "1063 E E Major N  |  E/b6\n",
      "1064 E E Major N  |  E/b6\n",
      "1065 E E Major N  |  E/b6\n",
      "1066 E E Major N  |  E/b6\n",
      "1067 E E Major N  |  E/b6\n",
      "1068 E E Major N  |  E/b6\n",
      "1069 E E Major N  |  E/5\n",
      "1070 E E Major N  |  E/5\n",
      "1071 E E Major N  |  E/5\n",
      "1072 E E Major N  |  E/5\n",
      "1073 E E Major N  |  E/5\n",
      "1074 A A Minor N  |  A:min\n",
      "1075 A A Minor N  |  A:min\n",
      "1076 A A Minor N  |  A:min\n",
      "1077 A A Minor N  |  A:min\n",
      "1078 A A Minor N  |  A:min\n",
      "1079 A A Minor N  |  A:min\n",
      "1080 A A Minor N  |  A:min\n",
      "1081 A A Minor N  |  A:min\n",
      "1082 A A Minor N  |  A:min\n",
      "1083 A A Minor N  |  A:min\n",
      "1084 A A Minor N  |  A:min\n",
      "1085 A A Minor N  |  A:min\n",
      "1086 A A Minor N  |  A:min\n",
      "1087 A A Minor N  |  A:min\n",
      "1088 A A Minor N  |  A:min\n",
      "1089 A A Minor N  |  A:min\n",
      "1090 A A Minor N  |  A:min\n",
      "1091 A A Minor N  |  A:min\n",
      "1092 C C Minor N  |  C\n",
      "1093 C C Minor N  |  C\n",
      "1094 C C Minor N  |  C\n",
      "1095 C C Minor N  |  C\n",
      "1096 C C Minor N  |  C\n",
      "1097 A C Minor N  |  C\n",
      "1098 A C Minor N  |  C\n",
      "1099 A C Minor N  |  C\n",
      "1100 A C Minor N  |  C\n",
      "1101 A C Minor N  |  C\n",
      "1102 A C Minor N  |  C\n",
      "1103 A C Minor N  |  C\n",
      "1104 A C Minor N  |  C\n",
      "1105 A C Minor N  |  C\n",
      "1106 A C Minor N  |  C\n",
      "1107 A C Minor N  |  C\n",
      "1108 A C Minor N  |  C\n",
      "1109 F C Minor N  |  C\n",
      "1110 F F Major N  |  F\n",
      "1111 F F Major N  |  F\n",
      "1112 F F Major N  |  F\n",
      "1113 F F Major N  |  F\n",
      "1114 F F Major N  |  F\n",
      "1115 F F Major N  |  F\n",
      "1116 F F Major N  |  F\n",
      "1117 F F Major N  |  F\n",
      "1118 F F Major N  |  F\n",
      "1119 F F Major N  |  F\n",
      "1120 F F Major N  |  F\n",
      "1121 F F Major N  |  F\n",
      "1122 F F Major N  |  F\n",
      "1123 F F Major N  |  F\n",
      "1124 F F Major N  |  F\n",
      "1125 F F Major N  |  F\n",
      "1126 F F Major N  |  F\n",
      "1127 F F Major N  |  F\n",
      "1128 F F Major N  |  F\n",
      "1129 F F Major N  |  F\n",
      "1130 F F Major N  |  F\n",
      "1131 F F Major N  |  F\n",
      "1132 F F Major N  |  F\n",
      "1133 F F Major N  |  F\n",
      "1134 F F Major N  |  F\n",
      "1135 F F Major N  |  F\n",
      "1136 G G Major N  |  G\n",
      "1137 G G Major N  |  G\n",
      "1138 G G Major N  |  G\n",
      "1139 G G Major N  |  G\n",
      "1140 G G Major N  |  G\n",
      "1141 G G Major N  |  G\n",
      "1142 G G Major N  |  G\n",
      "1143 G G Major N  |  G\n",
      "1144 G G Major N  |  G\n",
      "1145 A A Minor N  |  G\n",
      "1146 A A Minor N  |  A:min\n",
      "1147 A A Minor N  |  A:min\n",
      "1148 A A Minor N  |  A:min\n",
      "1149 A A Minor N  |  A:min\n",
      "1150 A A Minor N  |  A:min\n",
      "1151 A A Minor N  |  A:min\n",
      "1152 A A Minor N  |  A:min\n",
      "1153 A A Minor N  |  A:min\n",
      "1154 A A Minor N  |  A:min\n",
      "1155 A A Minor N  |  A:min\n",
      "1156 A A Minor N  |  A:min\n",
      "1157 A A Minor N  |  A:min\n",
      "1158 A A Minor N  |  A:min\n",
      "1159 A A Minor N  |  A:min\n",
      "1160 A A Minor N  |  A:min\n",
      "1161 A A Minor N  |  A:min\n",
      "1162 A A Minor N  |  A:min\n",
      "1163 C C Major N  |  A:min\n",
      "1164 C C Major N  |  C\n",
      "1165 C C Major N  |  C\n",
      "1166 C C Major N  |  C\n",
      "1167 C C Major N  |  C\n",
      "1168 C C Major N  |  C\n",
      "1169 C C Major N  |  C\n",
      "1170 C C Major N  |  C\n",
      "1171 C C Major N  |  C\n",
      "1172 C C Major N  |  C\n",
      "1173 C C Major N  |  C\n",
      "1174 C C Major N  |  C\n",
      "1175 C C Major N  |  C\n",
      "1176 C C Major N  |  C\n",
      "1177 C C Major N  |  C\n",
      "1178 C C Major N  |  C\n",
      "1179 C C Major N  |  C\n",
      "1180 C C Major N  |  C\n",
      "1181 F F Major N  |  F\n",
      "1182 F F Major N  |  F\n",
      "1183 F F Major N  |  F\n",
      "1184 F F Major N  |  F\n",
      "1185 F F Major N  |  F\n",
      "1186 F F Major N  |  F\n",
      "1187 F F Major N  |  F\n",
      "1188 F F Major N  |  F\n",
      "1189 F F Major N  |  F\n",
      "1190 F F Major N  |  F\n",
      "1191 F F Major N  |  F\n",
      "1192 F F Major N  |  F\n",
      "1193 F F Major N  |  F\n",
      "1194 F F Major N  |  F\n",
      "1195 F F Major N  |  F\n",
      "1196 F F Major N  |  F\n",
      "1197 F F Major N  |  F\n",
      "1198 F F Major N  |  F\n",
      "1199 F F Major N  |  F\n",
      "1200 F F Major N  |  F\n",
      "1201 F F Major N  |  F\n",
      "1202 F F Major N  |  F\n",
      "1203 F F Major N  |  F\n",
      "1204 F F Major N  |  F\n",
      "1205 F F Major N  |  F\n",
      "1206 F G Major N  |  F\n",
      "1207 G G Major N  |  F\n",
      "1208 G G Major N  |  G\n",
      "1209 G G Major N  |  G\n",
      "1210 G G Major N  |  G\n",
      "1211 G G Major N  |  G\n",
      "1212 G G Major N  |  G\n",
      "1213 G G Major N  |  G\n",
      "1214 G G Major N  |  G\n",
      "1215 G G Major N  |  G\n",
      "1216 E E Major N  |  E\n",
      "1217 E E Major N  |  E\n",
      "1218 E E Major N  |  E\n",
      "1219 E E Major N  |  E\n",
      "1220 E E Major N  |  E\n",
      "1221 E E Major N  |  E\n",
      "1222 E E Major N  |  E\n",
      "1223 E E Major N  |  E\n",
      "1224 E E Major N  |  E\n",
      "1225 E E Major N  |  E\n",
      "1226 E E Major N  |  E\n",
      "1227 E E Major N  |  E\n",
      "1228 E E Major N  |  E\n",
      "1229 E E Major N  |  E\n",
      "1230 E E Major N  |  E\n",
      "1231 E E Major N  |  E\n",
      "1232 E E Major N  |  E\n",
      "1233 E E Major N  |  E\n",
      "1234 G G Major N  |  G\n",
      "1235 G G Major N  |  G\n",
      "1236 G G Major N  |  G\n",
      "1237 G G Major N  |  G\n",
      "1238 G G Major N  |  G\n",
      "1239 G G Major N  |  G\n",
      "1240 G G Major N  |  G\n",
      "1241 G G Major N  |  G\n",
      "1242 G G Major N  |  G\n",
      "1243 G G Major N  |  G\n",
      "1244 G G Major N  |  G\n",
      "1245 G G Major N  |  G\n",
      "1246 G G Major N  |  G\n",
      "1247 G G Major N  |  G\n",
      "1248 G G Major N  |  G\n",
      "1249 G G Major N  |  G\n",
      "1250 G G Major N  |  G\n",
      "1251 A A Minor N  |  G\n",
      "1252 A A Minor N  |  A:min\n",
      "1253 A A Minor N  |  A:min\n",
      "1254 A A Minor N  |  A:min\n",
      "1255 A A Minor N  |  A:min\n",
      "1256 A A Minor N  |  A:min\n",
      "1257 A A Minor N  |  A:min\n",
      "1258 A A Minor N  |  A:min\n",
      "1259 A A Minor N  |  A:min\n",
      "1260 A A Minor N  |  A:min\n",
      "1261 A A Minor N  |  A:min\n",
      "1262 A A Minor N  |  A:min\n",
      "1263 A A Minor N  |  A:min\n",
      "1264 A A Minor N  |  A:min\n",
      "1265 A A Minor N  |  A:min\n",
      "1266 A A Minor N  |  A:min\n",
      "1267 A A Minor N  |  A:min\n",
      "1268 A A Minor N  |  A:min\n",
      "1269 F F Minor N  |  F:min\n",
      "1270 F F Minor N  |  F:min\n",
      "1271 F F Minor N  |  F:min\n",
      "1272 F F Minor N  |  F:min\n",
      "1273 F F Minor N  |  F:min\n",
      "1274 F F Minor N  |  F:min\n",
      "1275 F F Minor N  |  F:min\n",
      "1276 F F Minor N  |  F:min\n",
      "1277 F F Minor N  |  F:min\n",
      "1278 F F Minor N  |  F:min\n",
      "1279 F F Minor N  |  F:min\n",
      "1280 F F Minor N  |  F:min\n",
      "1281 F F Minor N  |  F:min\n",
      "1282 F F Minor N  |  F:min\n",
      "1283 F F Minor N  |  F:min\n",
      "1284 F F Minor N  |  F:min\n",
      "1285 F F Minor N  |  F:min\n",
      "1286 F F Minor N  |  F:min\n",
      "1287 F F Minor N  |  F:min\n",
      "1288 F F Minor N  |  F:min\n",
      "1289 F F Minor N  |  F:min\n",
      "1290 F F Minor N  |  F:min\n",
      "1291 F F Minor N  |  F:min\n",
      "1292 F F Minor N  |  F:min\n",
      "1293 F F Minor N  |  F:min\n",
      "1294 F F Minor N  |  F:min\n",
      "1295 F F Minor N  |  F:min\n",
      "1296 F F Minor N  |  F:min\n",
      "1297 F F Minor N  |  F:min\n",
      "1298 F F Minor N  |  F:min\n",
      "1299 F C Minor N  |  F:min\n",
      "1300 F C Minor N  |  F:min\n",
      "1301 F C Minor N  |  F:min\n",
      "1302 F C Minor N  |  F:min\n",
      "1303 F C Minor N  |  F:min\n",
      "1304 F C Minor N  |  F:min\n",
      "1305 F C Minor N  |  N\n",
      "1306 F N N N  |  N\n",
      "1307 N N N N  |  N\n",
      "1308 C C N N  |  N\n",
      "1309 C C N N  |  N\n",
      "1310 C C Major N  |  C\n",
      "1311 C C Major N  |  C\n",
      "1312 C C Major N  |  C\n",
      "1313 C C Major N  |  C\n",
      "1314 C C Major N  |  C\n",
      "1315 C C Major N  |  C\n",
      "1316 C C Major N  |  C\n",
      "1317 C C Major N  |  C\n",
      "1318 C C Major N  |  C\n",
      "1319 C C Major N  |  C\n",
      "1320 C C Major N  |  C\n",
      "1321 G G Major N  |  G\n",
      "1322 G G Major N  |  G\n",
      "1323 G G Major N  |  G\n",
      "1324 G G Major N  |  G\n",
      "1325 G G Major N  |  G\n",
      "1326 G G Major N  |  G\n",
      "1327 G G Major N  |  G\n",
      "1328 G G Major N  |  G\n",
      "1329 G G Major N  |  G\n",
      "1330 G G Major N  |  G\n",
      "1331 G G Major N  |  G\n",
      "1332 C C Major N  |  G\n",
      "1333 C C Major N  |  C\n",
      "1334 C C Major N  |  C\n",
      "1335 C C Major N  |  C\n",
      "1336 C C Major N  |  C\n",
      "1337 C C Major N  |  C\n",
      "1338 C C Major N  |  C\n",
      "1339 C C Major N  |  C\n",
      "1340 C C Major N  |  C\n",
      "1341 C C Major N  |  C\n",
      "1342 C C Major N  |  C\n",
      "1343 C C Major N  |  C\n",
      "1344 F F Minor N  |  F:min\n",
      "1345 F F Minor N  |  F:min\n",
      "1346 F F Minor N  |  F:min\n",
      "1347 F F Minor N  |  F:min\n",
      "1348 F F Minor N  |  F:min\n",
      "1349 F F Minor N  |  F:min\n",
      "1350 F F Minor N  |  F:min\n",
      "1351 F F Minor N  |  F:min\n",
      "1352 F F Minor N  |  F:min\n",
      "1353 F F Minor N  |  F:min\n",
      "1354 F F Major N  |  F:min\n",
      "1355 C C Major N  |  C\n",
      "1356 C C Major N  |  C\n",
      "1357 C C Major N  |  C\n",
      "1358 C C Major N  |  C\n",
      "1359 C C Major N  |  C\n",
      "1360 C C Major N  |  C\n",
      "1361 C C Major N  |  C\n",
      "1362 C C Major N  |  C\n",
      "1363 C C Major N  |  C\n",
      "1364 C C Major N  |  C\n",
      "1365 C C Major N  |  C\n",
      "1366 F F Major N  |  C\n",
      "1367 F F Minor N  |  F:min\n",
      "1368 F F Minor N  |  F:min\n",
      "1369 F F Minor N  |  F:min\n",
      "1370 F F Minor N  |  F:min\n",
      "1371 F F Minor N  |  F:min\n",
      "1372 F F Minor N  |  F:min\n",
      "1373 F F Minor N  |  F:min\n",
      "1374 F F Minor N  |  F:min\n",
      "1375 F F Minor N  |  F:min\n",
      "1376 F F Minor N  |  F:min\n",
      "1377 G F Major N  |  F:min\n",
      "1378 G G Major N  |  G\n",
      "1379 G G Major N  |  G\n",
      "1380 G G Major N  |  G\n",
      "1381 G G Major N  |  G\n",
      "1382 G G Major N  |  G\n",
      "1383 G G Major N  |  G\n",
      "1384 G G Major N  |  G\n",
      "1385 G G Major N  |  G\n",
      "1386 G G Major N  |  G\n",
      "1387 G G Major N  |  G\n",
      "1388 G G Major N  |  G\n",
      "1389 A A Major N  |  A\n",
      "1390 A A Major N  |  A\n",
      "1391 A A Major N  |  A\n",
      "1392 A A Major N  |  A\n",
      "1393 A A Major N  |  A\n",
      "1394 A A Major N  |  A\n",
      "1395 A A Major N  |  A\n",
      "1396 A A Major N  |  A\n",
      "1397 A A Major N  |  A\n",
      "1398 A A Major N  |  A\n",
      "1399 A A Major N  |  A\n",
      "1400 E E Major N  |  A\n",
      "1401 E E Major N  |  E\n",
      "1402 E E Major N  |  E\n",
      "1403 E E Major N  |  E\n",
      "1404 E E Major N  |  E\n",
      "1405 E E Major N  |  E\n",
      "1406 E E Major N  |  E\n",
      "1407 E E Major N  |  E\n",
      "1408 E E Major N  |  E\n",
      "1409 E E Major N  |  E\n",
      "1410 E E Major N  |  E\n",
      "1411 A A Major N  |  E\n",
      "1412 A A Major N  |  A\n",
      "1413 A A Major N  |  A\n",
      "1414 A A Major N  |  A\n",
      "1415 A A Major N  |  A\n",
      "1416 A A Major N  |  A\n",
      "1417 A A Major N  |  A\n",
      "1418 A A Major N  |  A\n",
      "1419 A A Major N  |  A\n",
      "1420 A A Major N  |  A\n",
      "1421 A A Major N  |  A\n",
      "1422 A A Major N  |  A\n",
      "1423 D D Major N  |  D:min\n",
      "1424 D D Minor N  |  D:min\n",
      "1425 D D Minor N  |  D:min\n",
      "1426 D D Minor N  |  D:min\n",
      "1427 D D Minor N  |  D:min\n",
      "1428 D D Minor N  |  D:min\n",
      "1429 D D Minor N  |  D:min\n",
      "1430 D D Minor N  |  D:min\n",
      "1431 D D Minor N  |  D:min\n",
      "1432 D D Minor N  |  D:min\n",
      "1433 D D Major N  |  D:min\n",
      "1434 A A Major N  |  A\n",
      "1435 A A Major N  |  A\n",
      "1436 A A Major N  |  A\n",
      "1437 A A Major N  |  A\n",
      "1438 A A Major N  |  A\n",
      "1439 A A Major N  |  A\n",
      "1440 A A Major N  |  A\n",
      "1441 A A Major N  |  A\n",
      "1442 A A Major N  |  A\n",
      "1443 A A Major N  |  A\n",
      "1444 A A Major N  |  A\n",
      "1445 D D Minor N  |  A\n",
      "1446 D D Minor N  |  D:min\n",
      "1447 D D Minor N  |  D:min\n",
      "1448 D D Minor N  |  D:min\n",
      "1449 D D Minor N  |  D:min\n",
      "1450 D D Minor N  |  D:min\n",
      "1451 D D Minor N  |  D:min\n",
      "1452 D D Minor N  |  D:min\n",
      "1453 D D Minor N  |  D:min\n",
      "1454 D D Minor N  |  D:min\n",
      "1455 D D Minor N  |  D:min\n",
      "1456 E E Major N  |  D:min\n",
      "1457 E E Major N  |  E\n",
      "1458 E E Major N  |  E\n",
      "1459 E E Major N  |  E\n",
      "1460 E E Major N  |  E\n",
      "1461 E E Major N  |  E\n",
      "1462 E E Major N  |  E\n",
      "1463 E E Major N  |  E\n",
      "1464 E E Major N  |  E\n",
      "1465 E E Major N  |  E\n",
      "1466 E E Major N  |  E\n",
      "1467 C C Major N  |  E\n",
      "1468 C C Major N  |  C\n",
      "1469 C C Major N  |  C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1470 C C Major N  |  C\n",
      "1471 C C Major N  |  C\n",
      "1472 C C Major N  |  C\n",
      "1473 C C Major N  |  C\n",
      "1474 C C Major N  |  C\n",
      "1475 C C Major N  |  C\n",
      "1476 C C Major N  |  C\n",
      "1477 C C Major N  |  C\n",
      "1478 C G Major N  |  C\n",
      "1479 G G Major N  |  G\n",
      "1480 G G Major N  |  G\n",
      "1481 G G Major N  |  G\n",
      "1482 G G Major N  |  G\n",
      "1483 G G Major N  |  G\n",
      "1484 G G Major N  |  G\n",
      "1485 G G Major N  |  G\n",
      "1486 G G Major N  |  G\n",
      "1487 G G Major N  |  G\n",
      "1488 G G Major N  |  G\n",
      "1489 G G Major N  |  G\n",
      "1490 C C Major N  |  C\n",
      "1491 C C Major N  |  C\n",
      "1492 C C Major N  |  C\n",
      "1493 C C Major N  |  C\n",
      "1494 C C Major N  |  C\n",
      "1495 C C Major N  |  C\n",
      "1496 C C Major N  |  C\n",
      "1497 C C Major N  |  C\n",
      "1498 C C Major N  |  C\n",
      "1499 C C Major N  |  C\n",
      "1500 D D Minor N  |  C\n",
      "1501 D D Minor N  |  C\n",
      "1502 D D Minor N  |  F:min\n",
      "1503 D D Minor N  |  F:min\n",
      "1504 D D Minor N  |  F:min\n",
      "1505 D D Minor N  |  F:min\n",
      "1506 D D Minor N  |  F:min\n",
      "1507 D D Minor N  |  F:min\n",
      "1508 D D Minor N  |  F:min\n",
      "1509 D D Minor N  |  F:min\n",
      "1510 D D Minor N  |  F:min\n",
      "1511 D D Minor N  |  F:min\n",
      "1512 C C Major N  |  F:min\n",
      "1513 C C Major N  |  C\n",
      "1514 C C Major N  |  C\n",
      "1515 C C Major N  |  C\n",
      "1516 C C Major N  |  C\n",
      "1517 C C Major N  |  C\n",
      "1518 C C Major N  |  C\n",
      "1519 C C Major N  |  C\n",
      "1520 C C Major N  |  C\n",
      "1521 C C Major N  |  C\n",
      "1522 C C Major N  |  C\n",
      "1523 C C Major N  |  C\n",
      "1524 F F Major N  |  F:min\n",
      "1525 F F Major N  |  F:min\n",
      "1526 F F Major N  |  F:min\n",
      "1527 F F Major N  |  F:min\n",
      "1528 F F Major N  |  F:min\n",
      "1529 F F Major N  |  F:min\n",
      "1530 F F Major N  |  F:min\n",
      "1531 F F Major N  |  F:min\n",
      "1532 F F Major N  |  F:min\n",
      "1533 F F Major N  |  F:min\n",
      "1534 G F Major N  |  F:min\n",
      "1535 G G Major N  |  G\n",
      "1536 G G Major N  |  G\n",
      "1537 G G Major N  |  G\n",
      "1538 G G Major N  |  G\n",
      "1539 G G Major N  |  G\n",
      "1540 G G Major N  |  G\n",
      "1541 G G Major N  |  G\n",
      "1542 G G Major N  |  G\n",
      "1543 G G Major N  |  G\n",
      "1544 G G Major N  |  G\n",
      "1545 G G Major N  |  G\n",
      "1546 A A Major N  |  G\n",
      "1547 A A Major N  |  A\n",
      "1548 A A Major N  |  A\n",
      "1549 A A Major N  |  A\n",
      "1550 A A Major N  |  A\n",
      "1551 A A Major N  |  A\n",
      "1552 A A Major N  |  A\n",
      "1553 A A Major N  |  A\n",
      "1554 A A Major N  |  A\n",
      "1555 A A Major N  |  A\n",
      "1556 A A Major N  |  A\n",
      "1557 E E Major N  |  A\n",
      "1558 E E Major N  |  E\n",
      "1559 E E Major N  |  E\n",
      "1560 E E Major N  |  E\n",
      "1561 E E Major N  |  E\n",
      "1562 E E Major N  |  E\n",
      "1563 E E Major N  |  E\n",
      "1564 E E Major N  |  E\n",
      "1565 E E Major N  |  E\n",
      "1566 E E Major N  |  E\n",
      "1567 E E Major N  |  E\n",
      "1568 E E Major N  |  E\n",
      "1569 A A Major N  |  A\n",
      "1570 A A Major N  |  A\n",
      "1571 A A Major N  |  A\n",
      "1572 A A Major N  |  A\n",
      "1573 A A Major N  |  A\n",
      "1574 A A Major N  |  A\n",
      "1575 A A Major N  |  A\n",
      "1576 A A Major N  |  A\n",
      "1577 A A Major N  |  A\n",
      "1578 A A Major N  |  A\n",
      "1579 A A Major N  |  A\n",
      "1580 D D Major N  |  D:min\n",
      "1581 D D Major N  |  D:min\n",
      "1582 D D Major N  |  D:min\n",
      "1583 D D Major N  |  D:min\n",
      "1584 D D Minor N  |  D:min\n",
      "1585 D D Minor N  |  D:min\n",
      "1586 D D Minor N  |  D:min\n",
      "1587 D D Minor N  |  D:min\n",
      "1588 D D Minor N  |  D:min\n",
      "1589 D D Minor N  |  D:min\n",
      "1590 D D Minor N  |  D:min\n",
      "1591 A A Major N  |  D:min\n",
      "1592 A A Major N  |  A\n",
      "1593 A A Major N  |  A\n",
      "1594 A A Major N  |  A\n",
      "1595 A A Major N  |  A\n",
      "1596 A A Major N  |  A\n",
      "1597 A A Major N  |  A\n",
      "1598 A A Major N  |  A\n",
      "1599 A A Major N  |  A\n",
      "1600 A A Major N  |  A\n",
      "1601 A A Major N  |  A\n",
      "1602 D D Minor N  |  D:min\n",
      "1603 D D Minor N  |  D:min\n",
      "1604 D D Minor N  |  D:min\n",
      "1605 D D Minor N  |  D:min\n",
      "1606 D D Minor N  |  D:min\n",
      "1607 D D Minor N  |  D:min\n",
      "1608 D D Minor N  |  D:min\n",
      "1609 D D Minor N  |  D:min\n",
      "1610 D D Minor N  |  D:min\n",
      "1611 D D Minor N  |  D:min\n",
      "1612 D D Minor N  |  D:min\n",
      "1613 D D Minor N  |  D:min\n",
      "1614 E E Major N  |  E\n",
      "1615 E E Major N  |  E\n",
      "1616 E E Major N  |  E\n",
      "1617 E E Major N  |  E\n",
      "1618 E E Major N  |  E\n",
      "1619 E E Major N  |  E\n",
      "1620 E E Major N  |  E\n",
      "1621 E E Major N  |  E\n",
      "1622 E E Major N  |  E\n",
      "1623 E E Major N  |  E\n",
      "1624 E E Major N  |  E\n",
      "1625 C C Major N  |  C\n",
      "1626 C C Major N  |  C\n",
      "1627 C C Major N  |  C\n",
      "1628 C C Major N  |  C\n",
      "1629 C C Major N  |  C\n",
      "1630 C C Major N  |  C\n",
      "1631 C C Major N  |  C\n",
      "1632 C C Major N  |  C\n",
      "1633 C C Major N  |  C\n",
      "1634 C C Major N  |  C\n",
      "1635 C C Major N  |  C\n",
      "1636 G G Major N  |  G\n",
      "1637 G G Major N  |  G\n",
      "1638 G G Major N  |  G\n",
      "1639 G G Major N  |  G\n",
      "1640 G G Major N  |  G\n",
      "1641 G G Major N  |  G\n",
      "1642 G G Major N  |  G\n",
      "1643 G G Major N  |  G\n",
      "1644 G G Major N  |  G\n",
      "1645 G G Major N  |  G\n",
      "1646 G G Major N  |  G\n",
      "1647 C C Major N  |  G\n",
      "1648 C C Major N  |  C\n",
      "1649 C C Major N  |  C\n",
      "1650 C C Major N  |  C\n",
      "1651 C C Major N  |  C\n",
      "1652 C C Major N  |  C\n",
      "1653 C C Major N  |  C\n",
      "1654 C C Major N  |  C\n",
      "1655 C C Major N  |  C\n",
      "1656 C C Major N  |  C\n",
      "1657 C C Major N  |  C\n",
      "1658 C C Major N  |  C\n",
      "1659 F F Major N  |  F:min\n",
      "1660 F F Major N  |  F:min\n",
      "1661 F F Major N  |  F:min\n",
      "1662 F F Major N  |  F:min\n",
      "1663 F F Major N  |  F:min\n",
      "1664 F F Major N  |  F:min\n",
      "1665 F F Major N  |  F:min\n",
      "1666 F F Major N  |  F:min\n",
      "1667 F F Major N  |  F:min\n",
      "1668 F F Major N  |  F:min\n",
      "1669 F F Major N  |  F:min\n",
      "1670 C C Major N  |  C\n",
      "1671 C C Major N  |  C\n",
      "1672 C C Major N  |  C\n",
      "1673 C C Major N  |  C\n",
      "1674 C C Major N  |  C\n",
      "1675 C C Major N  |  C\n",
      "1676 C C Major N  |  C\n",
      "1677 C C Major N  |  C\n",
      "1678 C C Major N  |  C\n",
      "1679 C C Major N  |  C\n",
      "1680 C C Major N  |  C\n",
      "1681 F F Major N  |  C\n",
      "1682 F F Minor N  |  F:min\n",
      "1683 F F Minor N  |  F:min\n",
      "1684 F F Minor N  |  F:min\n",
      "1685 F F Minor N  |  F:min\n",
      "1686 F F Minor N  |  F:min\n",
      "1687 F F Minor N  |  F:min\n",
      "1688 F F Minor N  |  F:min\n",
      "1689 F F Minor N  |  F:min\n",
      "1690 F F Minor N  |  F:min\n",
      "1691 F F Major N  |  F:min\n",
      "1692 G G Major N  |  F:min\n",
      "1693 G G Major N  |  G\n",
      "1694 G G Major N  |  G\n",
      "1695 G G Major N  |  G\n",
      "1696 G G Major N  |  G\n",
      "1697 G G Major N  |  G\n",
      "1698 G G Major N  |  G\n",
      "1699 G G Major N  |  G\n",
      "1700 G G Major N  |  G\n",
      "1701 G G Major N  |  G\n",
      "1702 G G Major N  |  G\n",
      "1703 G G Major N  |  G\n",
      "1704 A A Major N  |  G\n",
      "1705 A A Major N  |  A\n",
      "1706 A A Major N  |  A\n",
      "1707 A A Major N  |  A\n",
      "1708 A A Major N  |  A\n",
      "1709 A A Major N  |  A\n",
      "1710 A A Major N  |  A\n",
      "1711 A A Major N  |  A\n",
      "1712 A A Major N  |  A\n",
      "1713 A A Major N  |  A\n",
      "1714 A A Major N  |  A\n",
      "1715 A E Major N  |  A\n",
      "1716 E E Major N  |  E\n",
      "1717 E E Major N  |  E\n",
      "1718 E E Major N  |  E\n",
      "1719 E E Major N  |  E\n",
      "1720 E E Major N  |  E\n",
      "1721 E E Major N  |  E\n",
      "1722 E E Major N  |  E\n",
      "1723 E E Major N  |  E\n",
      "1724 E E Major N  |  E\n",
      "1725 E E Major N  |  E\n",
      "1726 A E Major N  |  E\n",
      "1727 A A Major N  |  A\n",
      "1728 A A Major N  |  A\n",
      "1729 A A Major N  |  A\n",
      "1730 A A Major N  |  A\n",
      "1731 A A Major N  |  A\n",
      "1732 A A Major N  |  A\n",
      "1733 A A Major N  |  A\n",
      "1734 A A Major N  |  A\n",
      "1735 A A Major N  |  A\n",
      "1736 A A Major N  |  A\n",
      "1737 A A Major N  |  A\n",
      "1738 D D Minor N  |  A\n",
      "1739 D D Minor N  |  D:min\n",
      "1740 D D Minor N  |  D:min\n",
      "1741 D D Minor N  |  D:min\n",
      "1742 D D Minor N  |  D:min\n",
      "1743 D D Minor N  |  D:min\n",
      "1744 D D Minor N  |  D:min\n",
      "1745 D D Minor N  |  D:min\n",
      "1746 D D Minor N  |  D:min\n",
      "1747 D D Minor N  |  D:min\n",
      "1748 D D Minor N  |  D:min\n",
      "1749 A A Major N  |  D:min\n",
      "1750 A A Major N  |  A\n",
      "1751 A A Major N  |  A\n",
      "1752 A A Major N  |  A\n",
      "1753 A A Major N  |  A\n",
      "1754 A A Major N  |  A\n",
      "1755 A A Major N  |  A\n",
      "1756 A A Major N  |  A\n",
      "1757 A A Major N  |  A\n",
      "1758 A A Major N  |  A\n",
      "1759 A A Major N  |  A\n",
      "1760 D D Major N  |  A\n",
      "1761 D D Minor N  |  D:min\n",
      "1762 D D Minor N  |  D:min\n",
      "1763 D D Minor N  |  D:min\n",
      "1764 D D Minor N  |  D:min\n",
      "1765 D D Minor N  |  D:min\n",
      "1766 D D Minor N  |  D:min\n",
      "1767 D D Minor N  |  D:min\n",
      "1768 D D Minor N  |  D:min\n",
      "1769 D D Minor N  |  D:min\n",
      "1770 D D Minor N  |  D:min\n",
      "1771 D D Minor N  |  D:min\n",
      "1772 E E Major N  |  E\n",
      "1773 E E Major N  |  E\n",
      "1774 E E Major N  |  E\n",
      "1775 E E Major N  |  E\n",
      "1776 E E Major N  |  E\n",
      "1777 E E Major N  |  E\n",
      "1778 E E Major N  |  E\n",
      "1779 E E Major N  |  E\n",
      "1780 E E Major N  |  E\n",
      "1781 E E Major N  |  E\n",
      "1782 E E Major N  |  E\n",
      "1783 C C Major N  |  C\n",
      "1784 C C Major N  |  C\n",
      "1785 C C Major N  |  C\n",
      "1786 C C Major N  |  C\n",
      "1787 C C Major N  |  C\n",
      "1788 C C Major N  |  C\n",
      "1789 C C Major N  |  C\n",
      "1790 C C Major N  |  C\n",
      "1791 C C Major N  |  C\n",
      "1792 C C Major N  |  C\n",
      "1793 C C Major N  |  C\n",
      "1794 G G Major N  |  C\n",
      "1795 G G Major N  |  G\n",
      "1796 G G Major N  |  G\n",
      "1797 G G Major N  |  G\n",
      "1798 G G Major N  |  G\n",
      "1799 G G Major N  |  G\n",
      "1800 G G Major N  |  G\n",
      "1801 G G Major N  |  G\n",
      "1802 G G Major N  |  G\n",
      "1803 G G Major N  |  G\n",
      "1804 G G Major N  |  G\n",
      "1805 C C Major N  |  G\n",
      "1806 C C Major N  |  C\n",
      "1807 C C Major N  |  C\n",
      "1808 C C Major N  |  C\n",
      "1809 C C Major N  |  C\n",
      "1810 C C Major N  |  C\n",
      "1811 C C Major N  |  C\n",
      "1812 C C Major N  |  C\n",
      "1813 C C Major N  |  C\n",
      "1814 C C Major N  |  C\n",
      "1815 C C Major N  |  C\n",
      "1816 F F Major N  |  C\n",
      "1817 F F Minor N  |  F:min\n",
      "1818 F F Minor N  |  F:min\n",
      "1819 F F Minor N  |  F:min\n",
      "1820 F F Minor N  |  F:min\n",
      "1821 F F Minor N  |  F:min\n",
      "1822 F F Minor N  |  F:min\n",
      "1823 F F Minor N  |  F:min\n",
      "1824 F F Minor N  |  F:min\n",
      "1825 F F Minor N  |  F:min\n",
      "1826 F F Major N  |  F:min\n",
      "1827 C C Major N  |  F:min\n",
      "1828 C C Major N  |  C\n",
      "1829 C C Major N  |  C\n",
      "1830 C C Major N  |  C\n",
      "1831 C C Major N  |  C\n",
      "1832 C C Major N  |  C\n",
      "1833 C C Major N  |  C\n",
      "1834 C C Major N  |  C\n",
      "1835 C C Major N  |  C\n",
      "1836 C C Major N  |  C\n",
      "1837 C C Major N  |  C\n",
      "1838 C C Major N  |  C\n",
      "1839 F F Major N  |  C\n",
      "1840 F F Major N  |  F:min\n",
      "1841 F F Major N  |  F:min\n",
      "1842 F F Major N  |  F:min\n",
      "1843 F F Minor N  |  F:min\n",
      "1844 F F Minor N  |  F:min\n",
      "1845 F F Minor N  |  F:min\n",
      "1846 F F Minor N  |  F:min\n",
      "1847 F F Minor N  |  F:min\n",
      "1848 F F Minor N  |  F:min\n",
      "1849 F F Major N  |  F:min\n",
      "1850 G G Major N  |  G\n",
      "1851 G G Major N  |  G\n",
      "1852 G G Major N  |  G\n",
      "1853 G G Major N  |  G\n",
      "1854 G G Major N  |  G\n",
      "1855 G G Major N  |  G\n",
      "1856 G G Major N  |  G\n",
      "1857 G G Major N  |  G\n",
      "1858 G G Major N  |  G\n",
      "1859 G G Major N  |  G\n",
      "1860 G G Major N  |  G\n",
      "1861 A A Major N  |  A\n",
      "1862 A A Major N  |  A\n",
      "1863 A A Major N  |  A\n",
      "1864 A A Major N  |  A\n",
      "1865 A A Major N  |  A\n",
      "1866 A A Major N  |  A\n",
      "1867 A A Major N  |  A\n",
      "1868 A A Major N  |  A\n",
      "1869 A A Major N  |  A\n",
      "1870 A A Major N  |  A\n",
      "1871 A A Major N  |  A\n",
      "1872 A A Major N  |  E\n",
      "1873 A A Major N  |  E\n",
      "1874 A A Major N  |  E\n",
      "1875 A A Major N  |  E\n",
      "1876 A A Major N  |  E\n",
      "1877 A A Major N  |  E\n",
      "1878 A A Major N  |  E\n",
      "1879 A A Major N  |  E\n",
      "1880 A A Major N  |  E\n",
      "1881 A A Major N  |  E\n",
      "1882 A A Major N  |  E\n",
      "1883 A A Major N  |  E\n",
      "1884 A A Major N  |  A\n",
      "1885 A A Major N  |  A\n",
      "1886 A A Major N  |  A\n",
      "1887 A A Major N  |  A\n",
      "1888 A A Major N  |  A\n",
      "1889 A A Major N  |  A\n",
      "1890 A A Major N  |  A\n",
      "1891 A A Major N  |  A\n",
      "1892 A A Major N  |  A\n",
      "1893 A A Major N  |  A\n",
      "1894 D D Major N  |  A\n",
      "1895 D D Major N  |  D:min\n",
      "1896 D D Minor N  |  D:min\n",
      "1897 D D Minor N  |  D:min\n",
      "1898 D D Minor N  |  D:min\n",
      "1899 D D Minor N  |  D:min\n",
      "1900 D D Minor N  |  D:min\n",
      "1901 D D Minor N  |  D:min\n",
      "1902 D D Minor N  |  D:min\n",
      "1903 D D Minor N  |  D:min\n",
      "1904 D D Minor N  |  D:min\n",
      "1905 D D Minor N  |  D:min\n",
      "1906 A A Major N  |  A\n",
      "1907 A A Major N  |  A\n",
      "1908 A A Major N  |  A\n",
      "1909 A A Major N  |  A\n",
      "1910 A A Major N  |  A\n",
      "1911 A A Major N  |  A\n",
      "1912 A A Major N  |  A\n",
      "1913 A A Major N  |  A\n",
      "1914 A A Major N  |  A\n",
      "1915 A A Major N  |  A\n",
      "1916 A A Major N  |  A\n",
      "1917 D D Minor N  |  D:min\n",
      "1918 D D Minor N  |  D:min\n",
      "1919 D D Minor N  |  D:min\n",
      "1920 D D Minor N  |  D:min\n",
      "1921 D D Minor N  |  D:min\n",
      "1922 D D Minor N  |  D:min\n",
      "1923 D D Minor N  |  D:min\n",
      "1924 D D Minor N  |  D:min\n",
      "1925 D D Minor N  |  D:min\n",
      "1926 D D Minor N  |  D:min\n",
      "1927 D D Minor N  |  D:min\n",
      "1928 D D Major N  |  E\n",
      "1929 E E Major N  |  E\n",
      "1930 E E Major N  |  E\n",
      "1931 E E Major N  |  E\n",
      "1932 E E Major N  |  E\n",
      "1933 E E Major N  |  E\n",
      "1934 E E Major N  |  E\n",
      "1935 E E Major N  |  E\n",
      "1936 E E Major N  |  E\n",
      "1937 E E Major N  |  E\n",
      "1938 E E Major N  |  E\n",
      "1939 E E Major N  |  E\n",
      "1940 E E Major N  |  E\n",
      "1941 E E Major N  |  C\n",
      "1942 E E Major N  |  C\n",
      "1943 E E Major N  |  C\n",
      "1944 E E Major N  |  C\n",
      "1945 E E Major N  |  C\n",
      "1946 E E Major N  |  C\n",
      "1947 E E Major N  |  C\n",
      "1948 E E Major N  |  C\n",
      "1949 E E Major N  |  C\n",
      "1950 E E Major N  |  C\n",
      "1951 E E Major N  |  C\n",
      "1952 E E Major N  |  G\n",
      "1953 C E Major N  |  G\n",
      "1954 C E Major N  |  G\n",
      "1955 C E Major N  |  G\n",
      "1956 C E Major N  |  G\n",
      "1957 C E Major N  |  G\n",
      "1958 C E Major N  |  G\n",
      "1959 C E Major N  |  G\n",
      "1960 C E Major N  |  G\n",
      "1961 C E Major N  |  G\n",
      "1962 C E Major N  |  G\n",
      "1963 C E Major N  |  G\n",
      "1964 E E Major N  |  G\n",
      "1965 E E Major N  |  C\n",
      "1966 E E Major N  |  C\n",
      "1967 E E Major N  |  C\n",
      "1968 E E Major N  |  C\n",
      "1969 E E Major N  |  C\n",
      "1970 E E Major N  |  C\n",
      "1971 E E Major N  |  C\n",
      "1972 E E Major N  |  C\n",
      "1973 E E Major N  |  C\n",
      "1974 E E Major N  |  C\n",
      "1975 E E Major N  |  C\n",
      "1976 E E Major N  |  C\n",
      "1977 E E Major N  |  F:min\n",
      "1978 E E Major N  |  F:min\n",
      "1979 E E Major N  |  F:min\n",
      "1980 E E Major N  |  F:min\n",
      "1981 E E Major N  |  F:min\n",
      "1982 G G Major N  |  F:min\n",
      "1983 G G Major N  |  F:min\n",
      "1984 G G Major N  |  C\n",
      "1985 G G Major N  |  C\n",
      "1986 G G Major N  |  C\n",
      "1987 G G Major N  |  C\n",
      "1988 G G Major N  |  C\n",
      "1989 G G Major N  |  C\n",
      "1990 G G Major N  |  C\n",
      "1991 G G Major N  |  C\n",
      "1992 G G Major N  |  C\n",
      "1993 G G Major N  |  C\n",
      "1994 G G Major N  |  C\n",
      "1995 G G Major N  |  F:min\n",
      "1996 G G Major N  |  F:min\n",
      "1997 G G Major N  |  F:min\n",
      "1998 G G Major N  |  F:min\n",
      "1999 G G Major N  |  F:min\n",
      "2000 G G Major N  |  F:min\n",
      "2001 G G Major N  |  F:min\n",
      "2002 G G Major N  |  F:min\n",
      "2003 G G Major N  |  F:min\n",
      "2004 G G Major N  |  F:min\n",
      "2005 G G Major N  |  G\n",
      "2006 G G Major N  |  G\n",
      "2007 G G Major N  |  G\n",
      "2008 G G Major N  |  G\n",
      "2009 G G Major N  |  G\n",
      "2010 G G Major N  |  G\n",
      "2011 G G Major N  |  G\n",
      "2012 G G Major N  |  G\n",
      "2013 G G Major N  |  G\n",
      "2014 G G Major N  |  G\n",
      "2015 G G Major N  |  G\n",
      "2016 G G Major N  |  G\n",
      "2017 G G Major N  |  G\n",
      "2018 G G Major N  |  G\n",
      "2019 G G Major N  |  G\n",
      "2020 G G Major N  |  G\n",
      "2021 G G Major N  |  G\n",
      "2022 G G Major N  |  G\n",
      "2023 G G Major N  |  G\n",
      "2024 A A Major N  |  G\n",
      "2025 A A Major N  |  A\n",
      "2026 A A Major N  |  A\n",
      "2027 A A Major N  |  A\n",
      "2028 A A Major N  |  A\n",
      "2029 A A Major N  |  A\n",
      "2030 A A Major N  |  A\n",
      "2031 A A Major N  |  A\n",
      "2032 N A Major N  |  A\n",
      "2033 N A Major N  |  A\n",
      "2034 N N Major N  |  A\n",
      "2035 N N Major N  |  A\n",
      "2036 N N Major N  |  E\n",
      "2037 N N Major N  |  E\n",
      "2038 N N Major N  |  E\n",
      "2039 A N Major N  |  E\n",
      "2040 A A Major N  |  E\n",
      "2041 A A Major N  |  E\n",
      "2042 A A Major N  |  E\n",
      "2043 A A Major N  |  E\n",
      "2044 A A Major N  |  E\n",
      "2045 A A Major N  |  A\n",
      "2046 A A Major N  |  A\n",
      "2047 A A Major N  |  A\n",
      "2048 A A Major N  |  A\n",
      "2049 A A Major N  |  A\n",
      "2050 A A Major N  |  A\n",
      "2051 A A Major N  |  A\n",
      "2052 A A Major N  |  A\n",
      "2053 A A Major N  |  A\n",
      "2054 A A Major N  |  A\n",
      "2055 A A Major N  |  D:min\n",
      "2056 A A Major N  |  D:min\n",
      "2057 A N N N  |  D:min\n",
      "2058 N N N N  |  D:min\n",
      "2059 N N N N  |  D:min\n",
      "2060 N N N N  |  D:min\n",
      "2061 N N N N  |  D:min\n",
      "2062 N N N N  |  D:min\n",
      "2063 N N N N  |  D:min\n",
      "2064 N N N N  |  A\n",
      "2065 N N N N  |  A\n",
      "2066 N N N N  |  A\n",
      "2067 N N N N  |  A\n",
      "2068 N N N N  |  A\n",
      "2069 N N N N  |  A\n",
      "2070 N N N N  |  A\n",
      "2071 N N N N  |  A\n",
      "2072 N N N N  |  A\n",
      "2073 N N N N  |  A\n",
      "2074 N N N N  |  A\n",
      "2075 N N N N  |  D:min\n",
      "2076 N N N N  |  D:min\n",
      "2077 N N N N  |  D:min\n",
      "2078 N N N N  |  D:min\n",
      "2079 N N N N  |  D:min\n",
      "2080 N N N N  |  D:min\n",
      "2081 N N N N  |  D:min\n",
      "2082 N N N N  |  D:min\n",
      "2083 N N N N  |  D:min\n",
      "2084 N N N N  |  D:min\n",
      "2085 N N N N  |  D:min\n",
      "2086 N N N N  |  D:min\n",
      "2087 N N N N  |  D:min\n",
      "2088 N N N N  |  N\n",
      "2089 N N N N  |  N\n",
      "2090 N N N N  |  N\n",
      "2091 N N N N  |  N\n",
      "2092 N N N N  |  N\n"
     ]
    }
   ],
   "source": [
    "track_no = '06'\n",
    "for i in range(0,len(segments_true_chords[track_no])):\n",
    "    print(i, estimations_root[track_no][i], estimations_bass[track_no][i], estimations_triad[track_no][i], estimations_fourth[track_no][i], \" | \", segments_true_chords[track_no][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full Chord list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimations_majmin = {}\n",
    "estimations_inversion = {}\n",
    "estimations_inversion_majmin = {}\n",
    "estimations_fullchord = {}\n",
    "\n",
    "for track_no in root_vec[album_validate].keys():\n",
    "    estimated_root_list = estimations_root[track_no]\n",
    "    estimated_bass_list = estimations_bass[track_no]\n",
    "    estimated_triad_list = estimations_triad[track_no]\n",
    "    estimated_fourth_list = estimations_fourth[track_no]\n",
    "    estimations_majmin[track_no] = []\n",
    "    estimations_fullchord[track_no] = []\n",
    "    tr = 0\n",
    "    for chord in estimated_root_list:\n",
    "        triad = estimated_triad_list[tr]\n",
    "        fourth = estimated_fourth_list[tr]\n",
    "        estimations_majmin[track_no].append(Chordify(root=chord, triad=triad))\n",
    "        estimations_fullchord[track_no].append(Chordify(root=chord, triad=triad, fourth=fourth))\n",
    "        tr += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIREX Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library for mirex metrics\n",
    "import mir_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete inversion tool for accuracy\n",
    "def delete_inversion(chord):\n",
    "    if chord.find('/') != -1:\n",
    "        chord, _ = chord.split('/')\n",
    "    return chord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the reference labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_true_chords = {}\n",
    "for track_no in root_vec[album_validate].keys():\n",
    "    times = Timestamps[Artist][album_validate][track_no]\n",
    "    df_rows = Chordlab[Artist][album_validate][track_no].itertuples()\n",
    "    index = 0\n",
    "    max_len = len(Chordlab[Artist][album_validate][track_no])\n",
    "    segments_true_chords[track_no] = []\n",
    "    row = next(df_rows)\n",
    "    for timestamp in times:\n",
    "        if ((index + 1) < max_len) & (timestamp >= row[2]):\n",
    "            index += 1\n",
    "            row = next(df_rows)\n",
    "        segments_true_chords[track_no].append(row[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Accuracy:  85.173 %\n"
     ]
    }
   ],
   "source": [
    "mir_eval_root = {}\n",
    "acc_mean = 0\n",
    "root_acc = {}\n",
    "for track_no in root_vec[album_validate].keys():\n",
    "    reference_len = len(segments_true_chords[track_no])\n",
    "    mir_eval_root[track_no] = mir_eval.chord.root(segments_true_chords[track_no], estimations_root[track_no][0:reference_len])\n",
    "    root_acc[track_no] = np.sum(mir_eval_root[track_no])/len(segments_true_chords[track_no])\n",
    "    acc_mean += root_acc[track_no]/17\n",
    "\n",
    "print(\"Root Accuracy: % 3.3f %%\" %(100*acc_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MajMin accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Accuracy:  76.736 %\n"
     ]
    }
   ],
   "source": [
    "mir_eval_majmin = {}\n",
    "acc_mean = 0\n",
    "majmin_acc = {}\n",
    "for track_no in root_vec[album_validate].keys():\n",
    "    reference_len = len(segments_true_chords[track_no])\n",
    "    mir_eval_majmin[track_no] = mir_eval.chord.majmin(segments_true_chords[track_no], estimations_majmin[track_no][0:reference_len])\n",
    "    majmin_acc[track_no] = np.sum(mir_eval_majmin[track_no])/len(segments_true_chords[track_no])\n",
    "    acc_mean += majmin_acc[track_no]/17\n",
    "\n",
    "print(\"Root Accuracy: % 3.3f %%\" %(100*acc_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sevenths accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Accuracy:  58.737 %\n"
     ]
    }
   ],
   "source": [
    "mir_eval_sevenths = {}\n",
    "acc_mean = 0\n",
    "sevenths_acc = {}\n",
    "for track_no in root_vec[album_validate].keys():\n",
    "    reference_len = len(segments_true_chords[track_no])\n",
    "    mir_eval_sevenths[track_no] = mir_eval.chord.sevenths(segments_true_chords[track_no], estimations_fullchord[track_no][0:reference_len])\n",
    "    sevenths_acc[track_no] = np.sum(mir_eval_sevenths[track_no])/len(segments_true_chords[track_no])\n",
    "    acc_mean += sevenths_acc[track_no]/17\n",
    "\n",
    "print(\"Root Accuracy: % 3.3f %%\" %(100*acc_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inversions accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MIREX accuracy\n",
    "**(at least three correct notes between reference and estimated chord)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mir_eval_overseg = mir_eval.chord.overseg(segments_true_chords, estimated_fullchord_list[0:1364])\n",
    "overseg_acc = np.sum(mir_eval_overseg)/len(segments_true_chords)\n",
    "\n",
    "print(\"Root Accuracy: % 3.3f %%\" %(100*overseg_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSR accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-309-2c71ef6633e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtotal_time_of_correct_estimation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msegments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrue_chord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegments_true_chords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mestimated_chord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChordify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimated_chord_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtriad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimated_triad_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mestimated_chord\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdelete_inversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_chord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "#CSR\n",
    "CSR = 0\n",
    "\n",
    "#segments of audio data\n",
    "segments = Timestamps[Artist][album_test_track][test_track_no]\n",
    "\n",
    "#compute total time of correct estimations\n",
    "step = 0\n",
    "total_time_of_correct_estimation = 0\n",
    "for time in segments:\n",
    "    true_chord = segments_true_chords[step]\n",
    "    estimated_chord = Chordify(root=estimated_chord_list[step], triad=estimated_triad_list[step])\n",
    "    if (estimated_chord == delete_inversion(true_chord)):\n",
    "        total_time_of_correct_estimation += 1\n",
    "    step += 1\n",
    "\n",
    "#total time of segments        \n",
    "total_time_of_segments = Timestamps[Artist][album_test_track][test_track_no].shape[0]\n",
    "\n",
    "#CSR\n",
    "CSR = total_time_of_correct_estimation / total_time_of_segments\n",
    "print (\"Accuracy Achieved by MIREX metric CSR = % 3.3f %%\" %(CSR*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
